{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fU80Ao-AGaob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f12168e-bb2e-4f4d-9468-324dc6c397f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 11:36:27--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3030::6815:5c2c, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7757958 (7.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "\rita-eng.zip           0%[                    ]       0  --.-KB/s               \rita-eng.zip         100%[===================>]   7.40M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-04-26 11:36:27 (241 MB/s) - ‘ita-eng.zip’ saved [7757958/7757958]\n",
            "\n",
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bo334ER4lTFe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7590b6b-534e-481e-87ca-e38f62158153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-26 11:36:28--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2022-04-26 11:36:28--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com/cd/0/inline/BkLuNs_PzKl6qG4_wtYOMj47f2HKZ_DOShOX4t_XuqIXZIUY73WsbiCQaLSaqdzMJKkB2NMgbHlMGVaf4Bdx6rjgXqHglrqZL-6QB5UKy537Nj-o4_8KQthcF4Tj_cJD-2RcNlpNp9IZAO_Cf-BoD0gsiHlvLh6s7gn1XGuS2u01xA/file# [following]\n",
            "--2022-04-26 11:36:29--  https://ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com/cd/0/inline/BkLuNs_PzKl6qG4_wtYOMj47f2HKZ_DOShOX4t_XuqIXZIUY73WsbiCQaLSaqdzMJKkB2NMgbHlMGVaf4Bdx6rjgXqHglrqZL-6QB5UKy537Nj-o4_8KQthcF4Tj_cJD-2RcNlpNp9IZAO_Cf-BoD0gsiHlvLh6s7gn1XGuS2u01xA/file\n",
            "Resolving ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com (ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com (ucb94a0398863626cc3a2ec08962.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  12.4MB/s    in 29s     \n",
            "\n",
            "2022-04-26 11:36:58 (11.6 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gOgfu8UHlUFs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vA0tUn_6nzFg"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "with open(\"ita.txt\" , \"r\", encoding = 'utf8') as f:\n",
        "  for i,line in enumerate(f.readlines()):    \n",
        "    data.append(tuple(line.split('\\t')[:2]))\n",
        "    \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iMjXO0F2n1C-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d9cc0925-0e32-48d2-804f-06a6aa1151e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1     Hi.     Ciao.\n",
              "2    Run!    Corri!\n",
              "3    Run!    Corra!\n",
              "4    Run!  Correte!"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-155db6a0-bb4a-45d4-8daa-7d2b2eedeeec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-155db6a0-bb4a-45d4-8daa-7d2b2eedeeec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-155db6a0-bb4a-45d4-8daa-7d2b2eedeeec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-155db6a0-bb4a-45d4-8daa-7d2b2eedeeec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = pd.DataFrame(data = data, columns=[\"english\",\"italian\"])\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1rAiyykhn3aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b9d9f0-d8a6-4a76-bb0b-be2f3b4171c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(353281, 2)\n",
            "(353281, 2)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n",
        "df.drop_duplicates()\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DqEaR7Don7QO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3df6b4a6-cb35-419f-8f8c-748d47a4ef11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a4e93eb-99aa-4606-afb1-ce88159d1983\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a4e93eb-99aa-4606-afb1-ce88159d1983')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a4e93eb-99aa-4606-afb1-ce88159d1983 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a4e93eb-99aa-4606-afb1-ce88159d1983');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#credits : applied roots reference notebook\n",
        "#has seen these codes many times and can apply easily but just for convinence have borrowed them\n",
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "df['english'] = df['english'].apply(preprocess)\n",
        "df['italian'] = df['italian'].apply(preprocess_ita)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GBKeDP1en-Wj"
      },
      "outputs": [],
      "source": [
        "ita_lengths = df['italian'].str.split().apply(len)\n",
        "eng_lengths = df['english'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nM7xM1PPoBRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c62648b-752f-409e-9247-1e9361987765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 3.0\n",
            "20 4.0\n",
            "30 4.0\n",
            "40 5.0\n",
            "50 5.0\n",
            "60 6.0\n",
            "70 6.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 92.0\n",
            "90 8.0\n",
            "91 8.0\n",
            "92 8.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 9.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 92.0\n",
            "99.1 12.0\n",
            "99.2 12.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 13.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 22.0\n",
            "100 92.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ita_lengths, i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lg76kR7ZoEYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a5dc7c-9c6b-4380-c3f5-455bcb7cffbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.0\n",
            "10 4.0\n",
            "20 4.0\n",
            "30 5.0\n",
            "40 5.0\n",
            "50 6.0\n",
            "60 6.0\n",
            "70 7.0\n",
            "80 7.0\n",
            "90 8.0\n",
            "100 101.0\n",
            "90 8.0\n",
            "91 9.0\n",
            "92 9.0\n",
            "93 9.0\n",
            "94 9.0\n",
            "95 9.0\n",
            "96 10.0\n",
            "97 10.0\n",
            "98 11.0\n",
            "99 12.0\n",
            "100 101.0\n",
            "99.1 12.0\n",
            "99.2 13.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 14.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 25.0\n",
            "100 101.0\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,101,10):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in range(90,101):\n",
        "    print(i,np.percentile(eng_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(eng_lengths, i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9QqElB_nKZos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "eb0c1ab4-8a5c-4fca-9390-890640d7cdbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1     ciao   <start> hi    hi <end>\n",
              "2    corri  <start> run   run <end>\n",
              "3    corra  <start> run   run <end>\n",
              "4  correte  <start> run   run <end>"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2813d45f-06db-4791-ae60-829bcb66427c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2813d45f-06db-4791-ae60-829bcb66427c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2813d45f-06db-4791-ae60-829bcb66427c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2813d45f-06db-4791-ae60-829bcb66427c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df['italian_len'] = df['italian'].str.split().apply(len)\n",
        "df = df[df['italian_len'] < 22]\n",
        "\n",
        "df['english_len'] = df['english'].str.split().apply(len)\n",
        "df = df[df['english_len'] < 22]\n",
        "\n",
        "df['english_inp'] = '<start> ' + df['english'].astype(str)\n",
        "df['english_out'] = df['english'].astype(str) + ' <end>'\n",
        "\n",
        "df = df.drop(['english','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyNNp3NTwyXn",
        "outputId": "2b154fc0-91a4-4fca-da89-93ecbc4a8be0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "italian        0\n",
              "english_inp    0\n",
              "english_out    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reverse = df"
      ],
      "metadata": {
        "id": "rR2d7c9lmHzD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fePiQ4t-rHDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8d3d93-5ab4-4587-80d3-e52a05bac722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(282292, 3) (70573, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(df, test_size=0.2, random_state = 42)\n",
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation, test = train_test_split(validation,test_size = 0.4, random_state=42)"
      ],
      "metadata": {
        "id": "umpz-jbuVW8o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qs1GgOz3rPN0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "2e4e8256-0eb1-4eec-fe01-eab6fc16d30a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgcZ33nv7+q6uprTkkjWbdsIYyFAWOEwSYhTjCJvYCdgySQcG52TXZhE2A3xMnmISzJLiy7IQcQFic4kIMYCInjzdqBGGMDsbEtn9iyZR3WNdYxmnumrzre/aPqra7uruPtsXrUx+/zPH6mu7qq+53W+P3W7yYhBBiGYZjBRTvfC2AYhmHOLywEDMMwAw4LAcMwzIDDQsAwDDPgsBAwDMMMOMb5XkC7rFu3TuzYseN8L4NhGKanePjhh88KISaiXus5IdixYwf27t17vpfBMAzTUxDR0bjX2DXEMAwz4LAQMAzDDDgsBAzDMAMOCwHDMMyAw0LAMAwz4LAQMAzDDDgsBAzDMAMOCwHDMMyAw0IwYHzijqfx67c+er6XwTBMF9FzlcXMC+OhIzNYrNjnexkMw3QRLAQDxtRSFRrR+V4GwzBdBLuGBgghBKYWq6jZ7vleCsMwXQQLwQCxWLVRsVxUWQgYhgnBQjBATC1WAYAtAoZhGmAhGCDOLLAQMAzTCgvBADG15AuB40IIcZ5XwzBMt8BCMEBI1xAAjhMwDBPAQjBAnFmsBI9rDgsBwzAeLAQDRNgi4DgBwzASFoIBgoWAYZgoWAh6kBs++338w6Mn2r6OYwQMw0TBQtBj2I6Lx0/M45Gjc21fO7VYxXghA4AtAoZh6rAQ9BgyyDuzXGvrOstxMb1cw+bxvPc+LAQMw/iwEPQYVcvbwM8uVVPObGR6yROOLWMFAEDNcc7twhiG6VlYCHoM6dufbtMikPEBaRFIQWEYhmEh6DGqtncn365rqGx518kYQZXrCBiG8WEh6DGkRTBbqsFuYzO3/HOLWW8EBccIGIaRsBD0GNKlIwQwW7KUr2sWAk4fZRhGwkLQY0jXENCee8hyvCZzRZMtAoZhGmEh6DHCd/LTbWQOSYtgKMdCwDBMIywEPUbFqlsEZ9uyCHwhyOoAgJrN6aMMw3iwEPQYYYtgpi2LwHMNFUyOETAM0wgLQY8RjhG0U0tgBxYBu4YYhmmEhaDHCBeCnV1q3zWUy+jQiOcRMAxTh4Wgx5AunYnhbFvB4prvGjJ1DaahsUXAMEwAC0GPIV1Dm0ZzbaWPSteQoRNMXeMYAcMwASwEPYZ0DW0ay7cVI5CuoYyuwTR0FgKGYQJYCHqMqu1C1wgbRnJtdSCVrqGMTsiya4hhmBAdFQIiupaI9hPRQSK6KeG8nyMiQUR7OrmefqBqO8gaGtYWTSxWbOUN3XZcGBqByBcCDhYzDOPTMSEgIh3A5wBcB2A3gLcT0e6I84YB/DqABzq1ln6iarvIGhoKfhpoRbEwzHJcZHTvn9s0NFQtLihjGMajkxbBFQAOCiEOCyFqAG4FcEPEeb8H4H8CqHRwLX1D1XKRNXSYOgEALEWLwHIEDP8aky0ChmFCdFIINgM4Hnp+wj8WQESXA9gqhPh/SW9ERDcS0V4i2js1NXXuV9pDVG0H2YwW3N3LiuE0LMeF6V/DMQKGYcKct2AxEWkAPg3gP6edK4S4WQixRwixZ2JiovOL62Kka8gIhEDVImhyDbEQMAzj00khmASwNfR8i39MMgzgUgD3ENERAK8FcDsHjJOpWA6yho6M7+ZRdfHYYdeQzhYBwzB1OikEDwHYRUQXEpEJ4G0AbpcvCiHmhRDrhBA7hBA7APwAwPVCiL0dXFPPIy0Cs02LoBZyDa2ksrhqO3BcNTcUwzC9RceEQAhhA/gAgG8CeBrA14QQTxHRx4no+k59br9Ttd3GGIGttjnbjgiuyRp628Hit3zm+/j8PQfbWyzDMD2B0ck3F0LcAeCOpmMfjTn36k6upV+o2g7G8hlkDG9TV93QLcdtyBpqN3306HQJB84stbdYhmF6Aq4s7jGqlrQI/PTRNlxD4WBxOxaB6wpUbbet3kYMw/QOLAQ9hhcj0NuOEXiuoXqwuJ2sIVm0NltiIWCYfoSFoMeQLSYyLyB9NJtpL1hcrvlCsGy1uVqGYXoBFoIeQ2YNyU29phgsbhAC3yIQQu3assUWAcP0MywEPYYXI9BhGu3FCKywa8horyq54gtBqeYEjxmG6R9YCHoIIcQ5cQ2ZbWYclWv189gqYJj+g4Wgh7BdAVdgRUJgu411BID6APtyyArgOAHD9B8sBD2EzPTxWkzIu3o1907Nbqwj8N5Pzc3TIARsETBM38FC0EPIIrBcJtRiQrkNdajFRBBoVnUN2cFjriVgmP6DhaCHqIQtgjaDxbYrWiyCFbmG2CJgmL6DhaCHkBZB4zwCRYvADqWPBq6hFQSLOUbAMH0HC0EPUY8RaDA02YZasY7Abew+Gn6/NKRFoBFbBAzTj7AQ9BDhYDERwdS1tuoIVuoakrUDG0ZyHCNgmD6EhaCHCFxD/kae0UkpWOy6Ak5D+mi7dQQOdI2wfiTHFgHD9CEsBD1EYBFkfCEw1CwCy/XOaa4jUG1FXbYc5DM61hQyLAQM04ewEPQQYdcQ4G3sKjEC2UqiucWEskVgOchldIwXTQ4WM0wfwkLQQ8gCMOnaUY0RSPeRtAhkoNlW7TVUc5A3NawpmBwjYJg+hIWgh6ha3oaey0iLgNpyDRm6jC20bxHkfYugbHHjOYbpN1gIeohw+ijgbehKQuDf+Zu+a0gKgapFIIVgrJABAMyX2T3EMP0EC0EPUXcNhWIECvMIbKfJNeQLgu2qWQSlmhcjqAeZ2xt8zzBMd8NC0EOsOGvIaXINae3PI8ibehBsbmfeMcMw3Q8LQQ8h78TrzePUYgTSapCuocAiaKOOIJ/R6/UHbYy5ZBim+2Eh6CGqtgNDI2ha3devIgTSBWRoza6h9mIE7fY3YhimN2Ah6CFsVwQ1AEA7dQR+jMBodg2pt5jImXrb9QcMw/QGLAQ9RM12gxoAwLcIFNw0zQVlmkbQNTW3ElB3DbU7x4BhmN6AhaCHsN16K2kAMA3FOoKmrCHAKypTSR8VQqBsOSiYemBRsEXAMP0FC0EPYdmiYTNXryNoFQLv2nQhqDkuXOEVsbFFwDD9CQtBD2G59bnDgPpm3uwaAryAsUodQcUfSpPP1GMEHCxmmP6ChaCHsBwR3JUDMli8UteQmojIoTR5ky0ChulXWAh6CNtptAhU6wiihMDUSamOIBCCTD1GwBYBw/QXLAQ9hOW4rX7+NrKGwhlHhmJ8oVSzAXCMgGH6GRaCHsIbNxkSAkM1RuBXJIdqEAydYCkUlFWiXEOKrSkYhukNWAh6CMtxgzYRQD1GIETyxmwHweKQiGiammsoIljMFgHD9BcsBD2E7YigTQRQ7x2U1iqi3nSuKWuonWBxpt50jmMEDNNfsBD0EDXHDQK2AJR7/8jMonDGkaFrSq6hetaQBkPXoBFbBAzTb3RUCIjoWiLaT0QHieimiNd/lYh+SESPEdH3iWh3J9fT69iui0xTiwnAKzRLvC4iWKyaNVSpeUIgp6KZhlrKKsMwvUPHhICIdACfA3AdgN0A3h6x0X9FCPEyIcRlAD4F4NOdWk838vDRWTxybFb5/JbKYsWWD5bjggjQw1lDmta2awiQw3BYCBimn+ikRXAFgINCiMNCiBqAWwHcED5BCLEQeloEMFDpKB//p3345B3PKJ/fXFlsKvrsLccTEKLGGIHKnb0UAmkRZNkiYJi+w+jge28GcDz0/ASA1zSfRETvB/BhACaAn4h6IyK6EcCNALBt27ZzvtDzxeRsGRPDWeXzvayh9mMEltPoUpLXqrSYkHUKZnhOMlsEDNNXnPdgsRDic0KInQB+E8DvxJxzsxBijxBiz8TExOousENUbQdnl6pBwZYKtiNaeg0BikJgNP5Tq3YflW4lGV/gGAHD9B+dFIJJAFtDz7f4x+K4FcBPd3A9XcXp+SoAYLmqLgRRlcUAUgfYS9dQGNXOpVX/M6VbSfU6hmF6h04KwUMAdhHRhURkAngbgNvDJxDRrtDTNwE40MH1dBXPz5cBAMtVR/ma5g3dNFRjBFGuIVIaVWnZjY3uTA4WM0zf0bEYgRDCJqIPAPgmAB3ALUKIp4jo4wD2CiFuB/ABIroGgAVgFsC7O7WebuOkLwRly4HjioaMnjg8i+AcuYZ0tawhy3Ebx2MaauMxGYbpHToZLIYQ4g4AdzQd+2jo8a938vO7mefnKsHjUs3GcC6Teo3d3GtIV0sf9SqSWy0C1RbWYfHJ6hpqtroVwzBM96PkGiKivyeiNxHReQ8u9wvPz5WDx6Va+sYqhPAqi6MKylLu0GtNsQVA1hGkC0HNbh6PqdbojmGY3kF1Y/9TAL8E4AARfZKILu7gmgaCk/N1i0AlYOy4rY3jzKCyOM0iaHTvAOq9hmotKavEMQKG6TOUhEAIcZcQ4pcBXA7gCIC7iOg+InovEaX7NJgWnp8rB+4alYCxDOw2tqFWLyhrdQ1psFTqCJpExDQ4WMww/Yayq4eI1gJ4D4B/B+BRAH8MTxj+pSMr63NOzlewY10RALCsUEsg/flRweI0X3+UayijahHYEcNwOH2UYfoK1RjBPwD4HoACgLcIIa4XQnxVCPGfAAx1coH9SKlmY75s4UUT3len4hqKmilgKsYIIl1DmgbbFamzDLyU1VBbC0NDlS0ChukrVC2CPxNC7BZCfEIIcRIAiCgLAEKIPR1bXZ8iM4Z2bfCFQCFYHDV3WD19NDprCEifZVBrdg2xRcAwfYeqEPx+xLH7z+VCBolTfqB4p28RlBQsgqjhMqqDYporkr33UZxlEJE1xC0mGKa/SKwjIKIL4DWPyxPRKwHIXWgEnpuIWQEyJrBhJAcAWFISAu/OvSGDR3F0ZKQQaFJE0qebNTe646ZzDNNfpBWU/RS8APEWNM4KWATw2x1aU98jfexriiYAtToCO8IiUI0RNPv5gbpbKa2WIDJriC0ChukrEoVACPFlAF8mop8TQnxjldbU91T8Hv8FU0fW0NrMGmo/RmBHZg35QpAWI4jMGvKCzOH5BgzD9C5prqF3CCH+GsAOIvpw8+tCiIGaKHaukBZBLqOjmDXazBqqb766RtBIZWZxY2sKoG5ZqA61kWRDU9Gyhp66boZhup8011DR/8kpoueQqm8RZDMailkdJYWCsqisIflcZVSl2eIa8rOGFNpTNGcNee8pkFXsVCVTVNmCYJjuJM019AX/539bneUMBoFFYOgomoaSa8gKBtA3CoGpawrD691Wi0BT71xqRmQq1WwXUByu9sk7n8HjJ+Zw641Xql3AMMyqolpQ9ikiGiGiDBF9m4imiOgdnV5cv1KxHBB5m6rnGlK3COQMAknGSM/rjx5Mo5Y11Jo+qgfHVRBC4J+eOImDZ5aUzmcYZvVRrSP4SX/Q/Jvh9Rp6EYDf6NSi+p2K5SBn6CAiFExdySKQ84WbLYKMTolCIISA5ba6huT7pM0tbp5loFq7IDk+U8bkXFkpRZZhmPODqhBIF9KbAHxdCDHfofUMBFXbRS7jffVFUy1YLMdRthsjcFwBIdDiGpKbe5JFIISA5TRNKPOvU20z8a+HzgIAKpYbdFBlGKa7UBWCfyKiZwC8CsC3iWgCQCXlGiaGiuUEGTeqriF5595cD2DqyfMBrIgeRQCCuQZJdQS1wB0VFSxWFIKDZ4PHKpYPwzCrj2ob6psAXAVgjxDCArAM4IZOLqyfabAIsjpKSsHi+KyhpEpfK0ZADIU6AisiZdVUrGYGANcVuP/QdHC9SnYUwzCrTzujKl8Cr54gfM1fnuP1DARhi6BgqgaL5TyC5mBxcoxAikRrr6F0X7+8trnFRNp1kmMzJUwv13DVzrW479A0xwkYpktREgIi+isAOwE8BkDuWgIsBCsibBEMZXXUHBc1u7VVdJiV1hHEu4bSYwRBNbPRGiNQsQgWKhYAYPvaAu47NK1k+TAMs/qoWgR7AOwWac3rGSWaLQIAKNecRCGImkcgnyfe1Uf0KAo/T4wRRFgTqsNwAO93AoB1Q17BAVsEDNOdqAaLnwRwQScXMkhUbRfZwCLwhGAp5W45bkNPDxa3uneAkIsnMUbgXZsNCVS2DYugbDUKAccIGKY7UbUI1gHYR0QPAqjKg0KI6zuyqj6nYrlYW/Qtgqz3M20mQVQbasAL5C5U4jdlO2LovbwOSLYIotxKpkLaqURaBGuHvC6rnDXEMN2JqhB8rJOLGDSqltNQRwCku00CiyBiCH3S3bl8rdU1JNtQJ8QIEl1D6Xf3zRaBSlCcYZjVR0kIhBD3EtF2ALuEEHcRUQEAt55cIVXbbagjANI3SdtxQeR1HA2T1mIi1jUkB9MkVBbXW1+vLH20xTXEFgHDdCWqvYb+PYC/A/AF/9BmALd1alH9TiVkEeQzniBU7WQhqDkCGU1r6eCZFiOIcw0FoyqTahAiCsqCpnNtuIbW+a4hDhYzTHeiGix+P4DXAVgAACHEAQDrO7WofsdLH/UEQAaN01o2eMNlWts4p/UasmJdQ+nD62sRdQRZXb3pnBSCYtZALqMpTWJjGGb1URWCqhCiJp/4RWWcSrpCvPRR76vPBr17kjdJK6KVNKCQPhpjEaiMuYyqXcgY6k3nypaDjE7I6BqKpsEWAcN0KapCcC8R/Ta8IfZvBPB1AP+3c8vqX2zHhe2KukXgxwoqVkoXULe1lTSQHiyuVxY3dx9VyRqK7zWkYhGUak7wexazRmpmFMMw5wdVIbgJwBSAHwJ4H4A7APxOpxbVz0gXUItFYKVYBHa0a8g01OoImkVED4LF8ddWI7KGdI1ACuMxAc/ykTGQgqljibOGGKYrUc0aconoNgC3CSGmOrymvkYOrm87RhBrEaTECGJcQ0SEjE5KdQThGAERwUyxQiRly0He9H7PoazBWUMM06UkWgTk8TEiOgtgP4D9/nSyj67O8vqPZotAbrJpQlBz3JaAL+Bt8LYr4Mbc2ce5hgBvOE1y99FW15Bcs0qLiVItZBFk1eYuMAyz+qS5hj4EL1vo1UKINUKINQBeA+B1RPShjq+uD2m2CAxdg6FRarDYdtyWWgAg3CoiemOOcw15n01KxWgtMxAMNYug0mAR6FjmrCGG6UrShOCdAN4uhHhOHhBCHAbwDgDv6uTC+pVmiwDwRKGaFix2RKRFkJb9I11DcdcmjaoMRKTZIlCYkwx46aP1GAEHixmmW0kTgowQ4mzzQT9OkEl7cyK6loj2E9FBIrop4vUPE9E+InqCiL7tVy/3Nc0WAeCJQppryHLc2BgBEF8YFjVTQGLolNxiIqFhncqoylLNQSEUI+D0UYbpTtKEoLbC10BEOoDPAbgOwG4Abyei3U2nPQpv6tnL4VUufyplPT1PlEWQNbRAIOKwHDeYIRCmPns4emOuj7iMEAItJeMoZk5ytg3XUC6UNVSqOeBO5gzTfaRlDb2CiBYijhOAXMq1VwA46LuSQES3whtvuU+eIIT4Tuj8H8BzOfU1csPPhi2CjK5QWSyCDKMwafMB4iabeddSomuo5jjQNWrpb6QaIyiH0keLWQO2KxqqqhmG6Q4ShUAI8UL+j90M4Hjo+Ql4geY4fgXAnS/g83oCueHnMo0WgUplsWxQFyYtRhAEfCOsCUPXEl1DliNiaxeUBtNYdddQ0f8ZLjJjGKY7UC0o6yhE9A54U9D+V8zrNxLRXiLaOzXV22UMgUVgtBsjiK8s9l6Pdw0ZGkHTotJHKXFDr9nRmUpZQ0sNbgP+pm/W00cBcAopw3QhnRSCSQBbQ8+3+McaIKJrAPxXANcLIarNrwOAEOJmIcQeIcSeiYmJjix2tZAbaKNFoJI1FN90Dohv+RCXbQR4d/aJoyqd6DnKpqGjmmIROK5AzXYD15CcxMbDaRim++ikEDwEYBcRXUhEJoC3Abg9fAIRvRJea+vrhRBnOriWrkG6gBosgky6a8h2RXTTuZRgcVy2EeBZBIkFZXb0tSqVxdLyka4h+ZMtAobpPjomBEIIG8AHAHwTwNMAviaEeIqIPk5EcsTl/wIwBODrRPQYEd0e83Z9QyXSIkh3DdXieg2l1REkCYHC4Psoi0BFuGTL6RaLgPsNMUzXoTqqckUIIe6A16AufOyjocfXdPLzu5Foi0BPTR+13Zj00ZQYgWVHB3y9aynRJVWLEZFsGxZBLlRQBvCUMobpRroiWDxIVCwXGjW2bVAOFhsJMYI4IXCTXENaYvfRmh0doFZJH5VjKsNN5wBwB1KG6UJYCFaZqu0ga+gNIyezRnodgeW4MJIsgoRgcZwQpHcfjXENKQiXdA3J2EA+SB9li4Bhug0WglWmYrkN8QFApmOm1xFEZ/CkxAhiYguAwnQzx4UZV0eQZhHUGl1DUgjSXGAMw6w+LASrTNVuLajygq/plcVGRC2AWh1BfLA4sddQTNZQ1tBTC8rkhi+DxTlfsNImsTEMs/qwEKwyFctt6DME1F1DcX14hBCJg2mA+BhBzREt3UODazWKbV8NJFshjisS3Up115AXGzB0DRmdgtgBwzDdAwvBKhNuxCaRwpDWLyg5fTTGIohx7wCeJZI4jyAmvmCmrBcIBYtDv2vOSM+OYhhm9WEhWGWqdpRFkOw2kZt8ZEFZarA43jWUFqSu2U5siwkAiamnUghyZmjugslCwDDdCAvBKlOxnIbOo0A9oBpXpCXv2nMRbppMSrA4yTVkpvQMSmo65713ghD42UHSNQR4RXQcI2CY7oOFYJVJsgjiNuVghkFE1860GEGiayil62lsjEC2vk6wJsq1VvHKZ/Qgm4hhmO6BhWCViYwRBBZBnBDIauQIi0BL7zUU7xrS4ArEBn1js4ZSLBjAcw2ZutbgzspldFRSWlMwDLP6sBCsMlGDWQKLIGaTrE81a7UINI1gaJQgBMmuofD7NxPXYkJaBEnxhfDgekmOLQKG6UpYCFaZcs1p8fVnUzZk6TKKsggAWRiW0HQuov7Ae79kS8RyWt1Y4XUkuYZKNbshYwjwLQIOFjNM18FCsMpU7NY75WBDjo0RyPGW8a0i4ucRxPcaSrJEhBAJBWXpFkHZclt+zzwHixmmK2EhWGWiYwR++ugKXEOA5+KJryOIblYX/twoEbEcAVdEWyGmgkVQjhhJmc/oXFDGMF0IC8EqIoTweg21nTUUHywGknsG1RKCxaYe7xqSnxk1X1hJCCw7aDgnadc19PW9x3H/oWnl8xmGWRksBKtIMLg+YoP0Xo+xCGSMINY1lBwjiEoBBZIFKGqATv265NgC4FkEUTGCdiyCT975DG7+7iHl8xmGWRksBKtIMKzFiMsaSqkjiHENZfT4IfR2TFEYUBeWKAGSa42qXagXlCWlj7ZmR+Uy6bOZw58/vVzDgTNLSuczDLNyWAhWkfpddkyweAV1BIBvEURcK5vVJbWYAKJdPC/YNVRrdQ3lM17XUidhGI7k9EIFAHBitswzDBimw7AQrCL1qV1NMQJ5Zx7jNqlbBPH1AFExAukuinMNJdURBKKVkD6anDUU5RqSPZXS3UPPz1WCx4fOLKeezzDMymEhWEVW7BoKYgRxrqHoGEHQrC62juAFuobSYgTNFoH/XCVOcGqhHDw+cGYx9XyGYVYOC8Eq0jzQXRJU6sZaBGmuoegYgRSC9DqCKNdQvEWgUllcjqosNtSnlJ2c9ywCQyOOEzBMhzHST2HOFZWY7B8iSpwDXLW9gfdxd/YZXcNStdWPHswxWJFrKD5GkGbBWI4LyxGtrqE2xlWenKtgrJDB+uEsDpxmIWCYTsIWwSrSPL4xTJoQNA+8D2PG1BEEFsEKWkzEBbYBT7hMPX6oTdzvKa0L2Zk0iZPzFVwwksOu9cM4yK4hhukoLASrSNJddi6jJ9QROLE1BIDMGoqPEcS6hhKC1PW1JswyiFmvbCwXFyNQ6UB6cr6MjaM5vGj9EI7NlLhHEcN0EBaCVaSSkJKZzcQPiYmaYRAmk5I1ZCTMI5Dv385a5bVxFkHUmMrwc5UOpKfmK9g4lsdFE0W4Ajg2U0q9hmGYlcFCsIpIl0i0ayh+bKR0DcWRFiyOGjcZPh61odfTR+P7G6UKQUwFddrdvSwm2ziSw3jBBADMl63EaxiGWTksBKtIkrslaVpY1XYSLYK4GIEdDL2PvpaIfBdPfEFZnEsqKaYRuIZiRnKmpY/KYrKNY3mM5jMAgPkSCwHDdAoWglUk0TVkxLdorlpueowgoo6gFgy9j3YNyc+NriNIL2KLtQhiYgS5ICaRHCyWqaMbR3MY8YVgocJCwDCdgoVgFUnaXD3XUHxlcbJrKLrFRJprqP65ERaB5VkhsZlKhhbb3yg1RpBiEZzyheCC0VzdImDXEMN0DBaCVcSbRRC9uWYThrakuYYyRnSMwE6pIwB8iyCy+2jrPIHG6+KF64XGCKaXawCAdcUshnNeqctCmfsNMUynYCFYRZI213xCr/60rKG4GIHcqJMtgug7+4rlxqaOyveMcw2VXmCMYMG/+x/KGcjoGoqmzhYBw3QQFoJVpGI5sVk4BdMINtBmqla6a8gVaOnqKd+vuQtoGNPQousI7GSLIClGUImxCHTNK0RLG1e5ULEwnDOg+4VwI/kMxwgYpoOwEKwiUXN8JcWsHttuuWqnF5QBaLEKZNA22cUTnf2TJFpJ14U/NypNNpfRUl1DC2UbI7lM8Hw0n2GLgGE6CAvBKlKx4n39eVPHcpxFkFZQ5mcFNbt4pLAkWQRxvv6qnZyplGQRxLmGAH9KWUpB2ULFCrKFAN8iYCFgmI7BQrCKJMUIiqaBmu3G+PqTXUOyeVxz5lDZd8EUzPjegtlM9IaeZhHE1R/Ia7OGBi2ix1He1FNbTCyULYzk6mseybFFwDCdpKNCQETXEtF+IjpIRDdFvP56InqEiGwiemsn19INVC038i4ZqN+1R8UJqgmWBFB3DTVbBOWaDaL4fkFAkmso2SJIqoSOakEtyRkqFoHdYBGM5jNYrHDWEMN0io4JARHpAD4H4DoAuwG8nYh2N512DMB7AHylU+voJFZ6qpcAAB3LSURBVEIIfPpb+/HsabXumGU/fTQKedcetUlW7db5v43XRotIyR8gH1cLAMTf2aenj2qoxdzZl2oOCjHX5kwdlYQ5BoC0CMKuIYMtAobpIJ20CK4AcFAIcVgIUQNwK4AbwicIIY4IIZ4AoDbRvMs4vVDFn9x9EL9z25MQIn0Ob6JrKOsdX24KGNuOC9sViRZB0ReRUrVJCCwnMT4AJMcIUrOGEgrKcjGfm89oqKRZBGULI/m6a2g0n8FS1YYd83kMw7wwOikEmwEcDz0/4R9rGyK6kYj2EtHeqampc7K4c8HxWa8j5oPPzeD+Q9Op51fs1jm+kkLMZi432yQ3TSFGRMq15Lt6IL6LqBcjSHcpRQlgpRb/e+YyyTECxxVYrDZmDcnH7B5imM7QE8FiIcTNQog9Qog9ExMT53s5Acf91sgFU8cf3XUg9fxyzY2dO1w0ozfzYF5xQuA2sAgihCDdIohrOpdiEegahABst1UISglCkE/JGlryN/vRphgBwP2GGKZTdFIIJgFsDT3f4h/rG07MegPW33nldjx4ZCY1P76aECMIBrs3bZJyk050DUmLIMI1lE/IGAJkQVm0RZBYzZwwyyAxWJxiEcjNvjl9FOB+QwzTKTopBA8B2EVEFxKRCeBtAG7v4OetOsdnSlg/nMXOiSEAwNRiNfH8pGrdYtbbsFssgpR20EDIrdRiEdixQVtJVIxACKEULAbiZhkku4aSRlXKzT6cPhpYBNxviGE6QseEQAhhA/gAgG8CeBrA14QQTxHRx4noegAgolcT0QkAPw/gC0T0VKfW0wmOz5awZTyPDSM5AMCZxUrsuXbMQHdJkPnTdFdfacM11GIRKLqGXIGGQKzlCLgiOe3U9NcTJQSlWrxFUDDjK6iBOIvA+/3YImCYzpDsN3iBCCHuAHBH07GPhh4/BM9l1JOcmC3jVdvHsWEkC8DLIopDpkzGba5xfv7AIkhw0+SD9NHWGEHchiwJ5hbbLgy/HiFtTCUQdg21unnKCdlKwzmvp5Lt1D8vzEJgEXCMgGFWi54IFncjtuPi5HwFW8cL2DDsWQRyslYUSYPrgfpm3txmoh4jSN6UTV1ruTYpaBtcq7f6+uVa4wLb3noS5h0nZCsN+xt8s/Uike6fcPqoFAW2CBimM7AQrJCT8xU4rsDWNXmMFTIwdS3ZIkgRgqyhQdeo1SKw0tNHAS+FtFRtsghU6gj89YTv7KvBvOL4zxzyffhRKZ3lhBjBsB8Libu7j3INFUwdhkbcb4hhOgQLwQqRNQRbxgsgIqwfyeLMC7AIiAgFU2+5U1ZxDQGea6nZIvBcQ8nev6igb1XBNTQSCEHj5lyzvQK4JNeQd110nGChbIEIGAqtm4gw0kYH0orl4I/vOoBP3Pm00vkMM+h0NEbQz5yY8VJHt44XAADrh7M4nRAsrijcZRdNIyF9NPnOvjkIazsuao6bahFEpYGmzSsG6i6epQgrBIgXkeGgOCzOIrAxnDVaGtaN5jNYUCgoq1gO3vyZ7+PgmSUQAR9+44tTvzuGGXTYIlghx2dL0AjYOObFBzaM5JRcQ0nB24Kpx6ePplgEhazRYE2UrPShNN77+q4hqzVGkGQRDGWj7+zTfk8Vi2C0kGk5PpLPYK5Ui12P5OCZJRw8s4Srdq6FEMCx6VLqNQwz6LAQrJCT8xWsH84FnT89IVCwCJKax2X1lsZxqjGCYpNFEAyHUUgfBRpjBCprHY5xDaVNRQuuq8bHCMIZQ5I1hQzmSumuoWN+tfebX74JAPDc2eXUaxhm0GEhWCFnl6pY76eNAsD6kSwWK3ZsjnzgMklwUxRMA8vVZotA1TXUaBEkTQkLExUjqFsEyW4sonpLCNXPHU7pGzRfjhaC8YKJmeV0i0AKwY9d7LUiYSFgmHRYCFbI1GIV64bqQiBTSM/EuIfKgcskqUJYbxnsrhwsbhp1qTKvGIiOEVTtdItA0whDWaPFby/XEBekTncN2Q2po5KxgqnkGjo2U8J4IYPNY3msLZo4Ms1CwDBpsBCskKnFKibCQjCSXEsQtE7It97tSopRFoFC4BbwLYKQW6lsJW/IkiBG0OAaSrdeAC8VtHlDl+6bsZjfM5fRYepaYvpopGuomMFyzYksYAtzfKaEbWu8AP6OdUUcnmIhYJg0WAhWgOMKTC/XMDEcFgK/ujim39C8fzc7ljdj39fL/GnNGtI1iqzCDVM0G+sIVC2CcGWxpKLQ3wjw3DzNMYI5X/DGIgK+9euMFpdScH3Jaug8KhkrmMHrSRydLmHb2iIA4MJ1RXYNMYwCLAQrYLZUg+OKBiFYL/sNxVgEcyULRVMPXDFRFLNGhBAkdwGVFLIGSpYD128LnTRAPkxUhXA91TXFIsgZLemj0n0jN+4ohnKtloS3Zhtly8HakKUlGfffbzbBPWQ7Libnyti2Jg/AE4Izi9UWK4thmEZYCFaA7DIaFoKRnIFcRot1Dc2VrcTNEfAyfJqDzSWF4TKAZxEIUb+bLytaBLLHUXhjrreYSLMIWjf02VINukYN3UOjr2u9s59e8jb5tUOt39N40bMSkgLGstp7+5q6RQBwwJhh0mAhWAFRQkBEibUEc6VapMsjTNHUYTmiIYNnrmRhPMHNIilkGzuQlhXqFgAvZqERGgKxVUstQD0U4Rqa9V07SXOSh7PRw+in/U1+XZQQKLiGjvo1A1tljMB3EXHAmGGSYSFYAYEQNLkwNgzH1xLMlaxEvzkQPVdgZrmGNcVkSwKoTziT1wYxgkxysFjXCGNNqZme9ZK8mQPRrqF5hd8zypIAgOkl73tdW2x1DcnvIMk1JFNHt6+VwWLv51EuKmOYRFgIVsDZpVaLAPBqCc7EBIvl5pqEnDQWjhPMlmrB3XAShaaZBOUgjTPdrTReyDRssNNLNaxVEJ/hXGv6qMp6o4LM8nMBRAqf/O5mE1xDx2ZKMHUtyOAqmAbWFM1gkhzDMNGwEKyAqcUqCqYeTBWTyOriqIHunkWQFiN4ARZBttUiMDRKDE5L1hazDRbB2aVqZMC2mZFcBjXbbUjpnC1ZsamjkjiL4OyybxFEuIayho6CqWM2wTV0fMYbFKSH+hRtHstjco6FgGGSYCFYAVNL1RZrAPBSSEs1p8VdIoTAfLmWukEGA+z9u3ohBGZLakIQWAS+NZE0JayZ8WIGs8v1DXZmWc0iiOo3NF+qpQreSM7AUs0OMpyCz12qoWDqwe/Sss6CmWgRnJgtYfN4vuHY5rE8JmfZNcQwSbAQrIDmYjJJvais0T1UqjmwHNFGjMDbzBerNixHtGcR+CJUVhhKI1lTNDETdg0t1yLvypuRVcLhmoBZheD2cC4DIYClpgyptM8dL2YSYwSTc2Vs8bvBSjaP5/H8XLSVxjCMBwvBCmhuLyFZPxw9u3hWoZgMaHXvyLtflRhBsckiUBlKI5F32kII2I6L2VItMmDbTHPfoIrloGw5GE8RrigBATyX1JqEzx0vmJiJcQ2Vaw7OLtWwpcki2DSWR9lyEl1KYf7wX57Fl/71OaVzGaZfYCFYAUmuIaC135BMeYxqrxxGulpkOwrpt1dzDbXGCNLaS0jWFE3YrsBCxcZsyYIQ0SmczTR3IJXrTkuTjWs8N7Ncw7qE33U8od/Q5JwcFNTqGgKASYWA8fGZEj5z9wF84s5nWsScYfoZFoI2qdoO5kpWpBCsj+k3JDfItDv7jaPepnVy3rteWhJpd9gAgsB1vY7AbssiADwLZDoI2KZbBEGMwHdHBetN+T2HYlpYTy+luIYKmdgYwXF/o28WAvlcCkUSX7rvCDQi2K7AF+49nHo+w/QLLARtImsI1kcIwVDWQNHUW2IEQSO2FIsgb+pYUzSDLJeg0lZBCLKGBo0aLQJVIZAWx0yp1tZnjjTd2cuAc3qMoDXILITA9HJyttJ40cRCxYbtuC2vnQiEoDFGsElaBHPJd/iLFQtffeg43vTyjbjhsk34mweOBmnCDNPvsBC0iSxO2ra2EPn6hpFcy8jKubKMEaRXCG8ay+F5XwjasQiIyO9e6lkE86XoLp5RBMVay7Vg81OxCJpdQ9Jtk+YCk+0nwh1IFypeYDxJgILq4ojZxSdmvRqC5iD+eCGDfEZPdQ39y77TWKraeNeVO/Ceq3agYrn414NnE69hmH6BhaBNZLsC2b6gmagh9tIiSGpBLdk0mg+EYGbZgqlrQVppGoWsjuWqDctxcWymFPTaSSOwCJZrQVxCJUYw1HRnP6foAouKEcjPTc4aqgtWM5OzZWwez7fMOiYibB7Pp7qG9h6dxXDWwCu3jmH3xhEUTB0PH51NvIZh+gUWgjY5Ol1C1tBwgR8PaCaq39BcqYZ8RldqHrd5PI/J2bJXQ7Bcw3gxvdWDZP1wDpNzZRydLsF2BXauVxOC8VD7humlGgyNlKyJjK4hl9GCugnVGIEMJoc39KT2EhIpTlH9nE7MloPAcDMqRWWPHJ3FZdvGoPktvy/bOoZHjrEQMIMBC0GbPHd2GdvXFlruPCVR1cUqfYYkm8fyWK45WKjYmFFsLyHZvXEE+04u4OCZJQDAzokhpeuKpjcsZmbZwvRyFeNFM/b3aybcLmKuZME0tMQRl4A3nOaCkRyeCzWDO5vQeVRy0Trv9zl8dqnltROz5ZZAsWTTmFdLEMdixcL+04t41fbx4Nirto/j6ZOL3MKaGQhYCNrk6PQytse4hQBvI6/abkPPIZUW1JJNoXTHGcXCLsnuTSOYWa7h/kOeb1vVNUREfnVxDWcV+wxJwv2G5ko1jCs0qwOAneuLOBSaHha4hhIsgg0jWQxlDRw60ygEFcvB2aVqrBBcuK7Q4PZq5vHj8xACuHxbXQgu3z4OxxV4/MRc6u/CML0OC0EbuK7A0elk3/vuTSMAgKeenw+OzSv035FIIXh+ruy5htqwCF7qf/b/++FJbBjJBr54FbxirRqml6KL5eLYOJrDEb/fv1dVrLbenRNDOHxmKbCcjs4sw9S1ROEjIuycaBQQoB7Ab84Ykrx00yiAxn+TMI8cmwURcNm2seDY5Vs9UXhEMU6w7/kF3PvsFJ49vah0PsN0EywEbXBqoYKq7QZtjqO4ZOMIiICnJheCY3PlmrJraNOYF3t4fr6MGcU+Q5KXbPSE4OxSTdktJFlTNP06gvaskMu3jeOZU4so1WycmC0ri8hF64pYrNqY8mMDTxyfxyUbh5FJGcm5c/1Q4PqSyLv2SzePRl4jBfLJ0L9JmIePzuLF64cb4iKjhQx2rR/CXgUhOHB6EW/+zPfw7lsexJv/5Ps4PsO9jZjegoWgDdIyhgCvluDCtUU86d99Vm0HR6ZLsYHMZtYVszANDcemS5gvq99hy8/e4YtUu0IwXjRxZrGKs4tVpfYSksu3eS6Uu585g6dPLuC1F61Rum7nem99h84sw3UFnpycx8u2RG/kDddNDOHUQqWhsd+jx+YwkjNwUYylNlYwsWU8H/ybhKnZLh4+Oos9O8ZbXrty51o8cHimobtqFH9417PIZ3R88d17AAI+c/eB1N+DYboJFoI2kC6IHSm+992bRoK7zydOzKNmu3j1hWobpKYRNo3m8P2DZyFEcvA0CukG2TmhFh+QbBrN4dhMCcs1J7JqOo5X+u6Uz3z7IADg9S+eULpOCtWhqSUcmV7GYtXGyzePpVxVv+7wVN0qePTYLC7bNp4Y4L500yiemmwVgr1HZ7BUtXH1xetbXnv9rgmULQcPH4m3Cp6cnMcdPzyFX/mRC/GGSzbgl1+zDd94ZLJhfQzT7bAQtMGRs8swDQ0bY1JHJZduHsXkXBlzpRoefG4GAPDqHWpCAHhxgmdOLWLzWB7XvvSCttYoYxTyjluVX3vDLvyfd1yO//EzL8Mvvnqr8nVjBRM7J4rYf3oRa4omLt2UflcPABeM5JDP6Dg0tYQnTngbtIpF8CL/95LuoaWqjWdPL+KVW5NF5NLNIzgyXWooYgOAe/ZPwdQ1XLVzbcs1V+5ci4xOuPfAVOz7fvbugxjJGfiVH70IAPAfr34RTF3Dn95zKPV3YZhugYWgDR48MoMXbxhKTa18aRAwXsCDz3nXtOPr371xBJtGc/jKv39N0L9IlTdcsh6XbR3Dy7ek312HGc5lcO2lG/FLr9nW1lqBerbNj7xonXLaqaYRLpoo4vDUMp44MY9cRsMuBfHavrYAQyMc8u+4nzg+B1d4WT5JvNSPH+x7vjFOcPczZ/Cai9a0DBkCvP5Nr9o+jnv3RwvB0ellfHPfKbzjtduD2oiJ4Sx+fs8W/ONjky2FhVE8d3YZH/m7x/Fbf/8ETs1zozvm/DDwQjBftvDpb+3HT/3hd/GuWx7E0yejA4pHzi7j0WNzeMvLN6W+p3TPPHRkBg8fnW3LGgCA3/43l+A7v3F1YppqHC+5YAS3vf91qR1AzyVyE1Z1C0l2TgzhmVMLeOC5abx00yiMlEAx4BWxbVtbwP5TnhA8etwLFF+WInzSUnn8eD0d9PhMCQfPLEW6hSQ/9uL1eObUYuQs6lu+/xwMjfDuq3Y0HP+3r7sQtivw5fuPJK7pjh+exDWfvhf/9/GT+MYjk3jDH9yD+7itBXMeGGghOLNYwS9+4X589jsHMVrI4IkTc3jTn3wPX9t7vOXcf3h0EkTA9ZelC8Gaook928fxR3cdwFLVxhWK8QGJphGyhlpbiW7guksvwHuu2oFrL23PjbVnxzhOL1Tx1PMLeEUbFsyPvXgCdz9zGj84PI3bHp3ErvVDqf2NJoazePmWUfzl/UdRsbzg71cePAYA+PGL4wXsmks8kbilaUbB5FwZX9t7Ate/YnMwkEiyY10RP7l7A/76B8eCJoXNPHRkBh/86mO4bOsYvvuRH8ddH/oxbB7P431//bBSCurUYhWf/tZ+/O4/Pokv3HuoZSoew7RDR4WAiK4lov1EdJCIbop4PUtEX/Vff4CIdnRyPWGePrmAn/3T+3BspoQvvfcKfO19V+Ke/3I1XveidfjI3z2B/3PvoWCUohACtz02iat2rg1aRafxF+99Na65ZD1yGQ1XXtTqf+4nxgomPnb9S4O21Kq868oduPc3rsZnf+mVeP+P71S+7oPXvBjrhrL45T9/AIemlvA7b96tdN1vXvsSTM6V8dc/OIonTszh5u8exltftQUXJWRY7dowjJ9/1RZ88XvP4eAZb4Ou2S7e/zePQNcIv/aGF0Ve9+E3XoyK5eCDX30UTtNIzh8cnsZ7/+IhbB7L48/ftQcTw1lsW1vALe95NXIZHe/48wdiax5qtovP3n0Ar//Ud/DZ7xzEbY89j0/c+Qx+4n/fg9senVSaxFazXRyfKeH4TKllXCgzmFCnRvgRkQ7gWQBvBHACwEMA3i6E2Bc65z8CeLkQ4leJ6G0AfkYI8YtJ77tnzx6xd+/eFa2pYjk4Ol3C7Y9P4pbvH8FI3sDN79yDV4QCjVXbwQdvfQx3PnkKV1y4Bm962Ubc9fRpfO/AWXz6F16Bn718i/LnCeENe1lNN82g8M9PnsR/+JtH8FvXvQQ3vl5dRN75xQdw36Fp6BphTcHENz/0+tR/n7NLVfzE/74Ha4eyeOurtuCe/Wfw0JFZfP6XL8d1L9sYe91XHzqG3/zGD/GGl6zHe193IXIZDd/adxpfuu8Itq0p4K9+5YqWG4tnTy/i3bc8iMWKjfe9/iJce+kFWFM0Mb1cw30Hz+Ivf3AUh6eWcd2lF+Aj174EF64r4tFjs/jY7U/h8RPzuHzbGN5+xTa89qK1mBjOQiPCXLmG56aWcd+hafzrwbN47PgcbF8AiqaOy7eP48qda3HlRWuxY20RwzkDjhCwHYGlqo2j0yXsP7WAfScXsO/kIqqWg+GcgYsvGMbLNo/iko0j2DJewHDOgE4ETSNULAfTyzXMLNVwcr6M5+fKgdUyWjAxXshgLG9irJDBaD6DsUIGQ1kDRATbcVFzXCxXHSxWLCxVbRAIuYyGXEZH3tRRNA3kMlpkFbvjCliOi6rtwnJcOK6ArhF0Iui6/1Pz/jM0Ct7DdQUs14XliGANjitgaBpMQ4Opez91xThYt0FEDwsh9kS+1kEhuBLAx4QQP+U//y0AEEJ8InTON/1z7iciA8ApABMiYVErFYIv3HsIn7jzGQCARsA1l2zA7//0pZHBWCEEvrb3OD71z/sxvVxD0dTxGz91Md515Q7lYCjTeaaXkucXRHFqvoK/uO85VC0XP79nSxDPSePeZ6fwP+98BvtOLmDzWB6/evVOvPO12xOvEULg8/cewufvORR0WtU1wrWXXoDfu+HS2KD8yfkyPvJ3T+B7B1rjBS/bPIoPXrMLb7hkQ8Nx1xX4+sPH8dnvHMTxmegGexoBL9syhisvWouL1hVhu8KL0RyewX4Fd9RYIYPdG0cwnDMwu2xh38mFc+qSkhtsswUVBxGQ0TQICAgBCHjfebtGDhGgESl/rq4RMjpBU2wGeS753bfsxi++etuKrj1fQvBWANcKIf6d//ydAF4jhPhA6Jwn/XNO+M8P+eecbXqvGwHc6D+9GMD+hI9eB4Ajbsnwd5QMfz/J8PeTTjd+R9uFEJEBsfacuucJIcTNAG5WOZeI9sapHuPB31Ey/P0kw99POr32HXUyWDwJIFyZtMU/FnmO7xoaBTDdwTUxDMMwTXRSCB4CsIuILiQiE8DbANzedM7tAN7tP34rgLuT4gMMwzDMuadjriEhhE1EHwDwTQA6gFuEEE8R0ccB7BVC3A7giwD+iogOApiBJxYvFCUX0oDD31Ey/P0kw99POj31HXUsWMwwDMP0BgNdWcwwDMOwEDAMwww8fSUEaS0tBh0iOkJEPySix4hoZeXZfQYR3UJEZ/yaFnlsDRH9CxEd8H8mtzbtY2K+n48R0aT/d/QYEf2b87nG8wkRbSWi7xDRPiJ6ioh+3T/eU39DfSMEfkuLzwG4DsBuAG8nIrUmNIPFjwshLuulHOcO8yUA1zYduwnAt4UQuwB8238+qHwJrd8PAPyh/3d0mRDijlVeUzdhA/jPQojdAF4L4P3+vtNTf0N9IwQArgBwUAhxWAhRA3ArgBvO85qYLkcI8V14GWthbgDwZf/xlwH89KouqouI+X4YHyHESSHEI/7jRQBPA9iMHvsb6ich2Awg3D/6hH+MqSMAfIuIHvbbdjDRbBBCnPQfnwKwIenkAeUDRPSE7zrqarfHauF3T34lgAfQY39D/SQETDo/IoS4HJ777P1E9PrzvaBuxy9w5BzrRj4PYCeAywCcBPAH53c55x8iGgLwDQAfFEI0TLfqhb+hfhIClZYWA40QYtL/eQbAP8BzpzGtnCaijQDg/zxzntfTVQghTgshHCGEC+DPMOB/R0SUgScCfyOE+Hv/cE/9DfWTEKi0tBhYiKhIRMPyMYCfBPBk8lUDS7j1ybsB/ON5XEvXITc4n5/BAP8dkTfM4IsAnhZCfDr0Uk/9DfVVZbGfxvZHqLe0+O/neUldAxFdBM8KALzWIl/h7wcgor8FcDW8tsGnAfwugNsAfA3ANgBHAfyCEGIgA6Yx38/V8NxCAsARAO8L+cMHCiL6EQDfA/BDAK5/+LfhxQl65m+or4SAYRiGaZ9+cg0xDMMwK4CFgGEYZsBhIWAYhhlwWAgYhmEGHBYChmGYAYeFgGGaIKL7/J87iOiXFM7fIbtzEtEeIvqTTq+RYc4lLAQM04QQ4ir/4Q4AqULQdO1eIcSvnfNFMUwHYSFgmCaIaMl/+EkAP+r33P+Qf+f/PSJ6xP/vqohrryaif/IfX0FE9xPRo0R0HxFd7B9/DxH9PRH9s9+v/lOr99sxTCsdG17PMH3ATQD+ixDizQBARAUAbxRCVIhoF4C/BZA01+EZAD8qhLCJ6BoA/wPAz/mvXQavU2UVwH4i+owQ4njM+zBMR2EhYBh1MgA+S0SXAXAAvDjl/FEAX/ZFQ/jXS74thJgHACLaB2A7GtuoM8yqwa4hhlHnQ/D67bwCniVgppz/ewC+I4S4FMBbAORCr1VDjx3wTRlzHmEhYJh4FgEMh56PAjjpt19+J7zmhkmMot4K/T3nfHUMc45gIWCYeJ4A4BDR40T0IQB/CuDdRPQ4gJcAWE65/lMAPkFEj4Lv+JkuhruPMgzDDDhsETAMwww4LAQMwzADDgsBwzDMgMNCwDAMM+CwEDAMwww4LAQMwzADDgsBwzDMgPP/AUOo/lCnDVLuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RfyHdzlnrdyl"
      },
      "outputs": [],
      "source": [
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Vrf-iN7ErjMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76d1a09-f489-446a-f482-f7acd9d6cc01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size of english 13107\n",
            "vocab size of italian 26596\n"
          ]
        }
      ],
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(\"vocab size of english\",vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(\"vocab size of italian\",vocab_size_ita)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "y1uPOS3prvTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e3604e-726a-4644-a33c-3e192e5de9f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10319)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#check the tokenized numerical value of <end> and <start>\n",
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EqbMa_2YsPEz"
      },
      "outputs": [],
      "source": [
        "#embedding the tokenised texts\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_eng.word_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTbGo0eCs6L9",
        "outputId": "01e94569-2ec3-4c76-e128-7f5d96b7988f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('<start>', 1), ('i', 2), ('you', 3), ('tom', 4), ('to', 5), ('is', 6), ('not', 7), ('the', 8), ('do', 9), ('a', 10), ('are', 11), ('have', 12), ('it', 13), ('that', 14), ('he', 15), ('was', 16), ('am', 17), ('in', 18), ('we', 19), ('me', 20), ('will', 21), ('did', 22), ('of', 23), ('this', 24), ('be', 25), ('what', 26), ('can', 27), ('for', 28), ('my', 29), ('your', 30), ('want', 31), ('mary', 32), ('with', 33), ('like', 34), ('why', 35), ('know', 36), ('think', 37), ('go', 38), ('she', 39), ('his', 40), ('here', 41), ('at', 42), ('they', 43), ('would', 44), ('very', 45), ('on', 46), ('and', 47), ('how', 48), ('has', 49), ('there', 50), ('does', 51), ('about', 52), ('now', 53), ('were', 54), ('all', 55), ('going', 56), ('so', 57), ('should', 58), ('need', 59), ('get', 60), ('as', 61), ('boston', 62), ('help', 63), ('time', 64), ('us', 65), ('him', 66), ('an', 67), ('good', 68), ('tell', 69), ('who', 70), ('one', 71), ('had', 72), ('really', 73), ('never', 74), ('still', 75), ('where', 76), ('too', 77), ('come', 78), ('see', 79), ('been', 80), ('up', 81), ('her', 82), ('got', 83), ('just', 84), ('no', 85), ('anything', 86), ('french', 87), ('please', 88), ('from', 89), ('home', 90), ('much', 91), ('out', 92), ('by', 93), ('said', 94), ('when', 95), ('could', 96), ('work', 97), ('lot', 98), ('let', 99), ('told', 100), ('something', 101), ('car', 102), ('some', 103), ('give', 104), ('busy', 105), ('money', 106), ('back', 107), ('went', 108), ('today', 109), ('if', 110), ('eat', 111), ('always', 112), ('love', 113), ('more', 114), ('take', 115), ('than', 116), ('last', 117), ('sure', 118), ('happy', 119), ('talk', 120), ('look', 121), ('must', 122), ('only', 123), ('leave', 124), ('right', 125), ('wanted', 126), ('day', 127), ('say', 128), ('book', 129), ('three', 130), ('new', 131), ('buy', 132), ('tomorrow', 133), ('many', 134), ('make', 135), ('live', 136), ('school', 137), ('thought', 138), ('any', 139), ('stay', 140), ('play', 141), ('ever', 142), ('friends', 143), ('our', 144), ('well', 145), ('made', 146), ('people', 147), ('everything', 148), ('find', 149), ('doing', 150), ('them', 151), ('room', 152), ('house', 153), ('read', 154), ('but', 155), ('yet', 156), ('yesterday', 157), ('better', 158), ('speak', 159), ('nothing', 160), ('feel', 161), ('wants', 162), ('stop', 163), ('asked', 164), ('job', 165), ('australia', 166), ('every', 167), ('used', 168), ('call', 169), ('hate', 170), ('little', 171), ('saw', 172), ('tired', 173), ('already', 174), ('problem', 175), ('ready', 176), ('these', 177), ('ask', 178), ('next', 179), ('alone', 180), ('done', 181), ('try', 182), ('teacher', 183), ('lost', 184), ('again', 185), ('old', 186), ('left', 187), ('may', 188), ('hope', 189), ('friend', 190), ('late', 191), ('father', 192), ('everyone', 193), ('seen', 194), ('two', 195), ('believe', 196), ('or', 197), ('before', 198), ('night', 199), ('long', 200), ('understand', 201), ('dog', 202), ('wrong', 203), ('down', 204), ('put', 205), ('name', 206), ('morning', 207), ('married', 208), ('things', 209), ('wait', 210), ('gave', 211), ('often', 212), ('study', 213), ('afraid', 214), ('anymore', 215), ('knows', 216), ('man', 217), ('both', 218), ('years', 219), ('party', 220), ('knew', 221), ('bought', 222), ('use', 223), ('drink', 224), ('tonight', 225), ('into', 226), ('off', 227), ('found', 228), ('came', 229), ('coffee', 230), ('looks', 231), ('happened', 232), ('way', 233), ('tried', 234), ('angry', 235), ('took', 236), ('children', 237), ('life', 238), ('proud', 239), ('seems', 240), ('week', 241), ('even', 242), ('first', 243), ('soon', 244), ('mother', 245), ('being', 246), ('open', 247), ('together', 248), ('answer', 249), ('early', 250), ('keep', 251), ('idea', 252), ('heard', 253), ('same', 254), ('looking', 255), ('hard', 256), ('away', 257), ('worried', 258), ('might', 259), ('without', 260), ('anyone', 261), ('seem', 262), ('plan', 263), ('enough', 264), ('fun', 265), ('year', 266), ('thing', 267), ('pretty', 268), ('waiting', 269), ('almost', 270), ('working', 271), ('christmas', 272), ('after', 273), ('likes', 274), ('other', 275), ('hear', 276), ('best', 277), ('door', 278), ('kind', 279), ('able', 280), ('happen', 281), ('pay', 282), ('says', 283), ('family', 284), ('another', 285), ('dinner', 286), ('over', 287), ('bad', 288), ('favorite', 289), ('english', 290), ('talking', 291), ('write', 292), ('which', 293), ('true', 294), ('sleep', 295), ('died', 296), ('hurt', 297), ('books', 298), ('surprised', 299), ('water', 300), ('remember', 301), ('learn', 302), ('person', 303), ('change', 304), ('truth', 305), ('sorry', 306), ('parents', 307), ('someone', 308), ('wish', 309), ('question', 310), ('food', 311), ('coming', 312), ('watch', 313), ('met', 314), ('stupid', 315), ('lunch', 316), ('everybody', 317), ('looked', 318), ('win', 319), ('walk', 320), ('big', 321), ('interested', 322), ('started', 323), ('those', 324), ('nice', 325), ('lives', 326), ('young', 327), ('brother', 328), ('else', 329), ('phone', 330), ('turn', 331), ('such', 332), ('bed', 333), ('sick', 334), ('letter', 335), ('cold', 336), ('beautiful', 337), ('trying', 338), ('their', 339), ('forget', 340), ('listen', 341), ('girlfriend', 342), ('getting', 343), ('drive', 344), ('care', 345), ('sister', 346), ('called', 347), ('place', 348), ('doctor', 349), ('hungry', 350), ('playing', 351), ('worry', 352), ('meet', 353), ('sing', 354), ('arrived', 355), ('train', 356), ('rich', 357), ('mine', 358), ('decided', 359), ('quite', 360), ('nobody', 361), ('start', 362), ('needs', 363), ('swim', 364), ('days', 365), ('killed', 366), ('bus', 367), ('show', 368), ('myself', 369), ('few', 370), ('trust', 371), ('ate', 372), ('once', 373), ('free', 374), ('yours', 375), ('different', 376), ('mistake', 377), ('drunk', 378), ('reading', 379), ('music', 380), ('because', 381), ('important', 382), ('probably', 383), ('summer', 384), ('himself', 385), ('easy', 386), ('usually', 387), ('tv', 388), ('son', 389), ('great', 390), ('finished', 391), ('mind', 392), ('studying', 393), ('beer', 394), ('lucky', 395), ('bit', 396), ('paid', 397), ('far', 398), ('ok', 399), ('eating', 400), ('wife', 401), ('story', 402), ('cat', 403), ('bring', 404), ('movie', 405), ('while', 406), ('ago', 407), ('around', 408), ('questions', 409), ('dance', 410), ('maybe', 411), ('difficult', 412), ('having', 413), ('die', 414), ('forgot', 415), ('thank', 416), ('tennis', 417), ('girl', 418), ('park', 419), ('visit', 420), ('red', 421), ('hand', 422), ('spent', 423), ('serious', 424), ('interesting', 425), ('office', 426), ('teach', 427), ('picture', 428), ('kill', 429), ('wonder', 430), ('boy', 431), ('meeting', 432), ('nervous', 433), ('afternoon', 434), ('helped', 435), ('tea', 436), ('living', 437), ('hours', 438), ('police', 439), ('accident', 440), ('times', 441), ('child', 442), ('agree', 443), ('safe', 444), ('hair', 445), ('later', 446), ('wine', 447), ('broke', 448), ('homework', 449), ('anybody', 450), ('became', 451), ('shoes', 452), ('changed', 453), ('monday', 454), ('trouble', 455), ('scared', 456), ('gone', 457), ('hotel', 458), ('wrote', 459), ('sit', 460), ('exactly', 461), ('japan', 462), ('city', 463), ('window', 464), ('students', 465), ('works', 466), ('bicycle', 467), ('thinks', 468), ('born', 469), ('hot', 470), ('small', 471), ('word', 472), ('station', 473), ('watching', 474), ('lose', 475), ('breakfast', 476), ('eaten', 477), ('perfect', 478), ('miss', 479), ('explain', 480), ('longer', 481), ('boyfriend', 482), ('fell', 483), ('milk', 484), ('invited', 485), ('wearing', 486), ('yourself', 487), ('team', 488), ('each', 489), ('liked', 490), ('world', 491), ('kept', 492), ('near', 493), ('fish', 494), ('swimming', 495), ('minutes', 496), ('game', 497), ('evening', 498), ('country', 499), ('hands', 500), ('pen', 501), ('song', 502), ('seemed', 503), ('supposed', 504), ('since', 505), ('began', 506), ('key', 507), ('thirty', 508), ('won', 509), ('felt', 510), ('lie', 511), ('touch', 512), ('spend', 513), ('ten', 514), ('close', 515), ('rain', 516), ('pizza', 517), ('older', 518), ('clean', 519), ('played', 520), ('most', 521), ('problems', 522), ('town', 523), ('news', 524), ('enjoy', 525), ('jealous', 526), ('price', 527), ('230', 528), ('lived', 529), ('strange', 530), ('real', 531), ('mad', 532), ('weekend', 533), ('age', 534), ('worked', 535), ('high', 536), ('month', 537), ('smoking', 538), ('run', 539), ('mean', 540), ('number', 541), ('advice', 542), ('possible', 543), ('thinking', 544), ('golf', 545), ('honest', 546), ('talked', 547), ('asleep', 548), ('dead', 549), ('cook', 550), ('sound', 551), ('table', 552), ('john', 553), ('making', 554), ('expensive', 555), ('fire', 556), ('fast', 557), ('hurry', 558), ('student', 559), ('fine', 560), ('funny', 561), ('kiss', 562), ('against', 563), ('stopped', 564), ('eyes', 565), ('umbrella', 566), ('guy', 567), ('crazy', 568), ('secret', 569), ('finish', 570), ('woman', 571), ('outside', 572), ('canadian', 573), ('own', 574), ('send', 575), ('computer', 576), ('dangerous', 577), ('rather', 578), ('stayed', 579), ('makes', 580), ('tall', 581), ('sunday', 582), ('river', 583), ('apple', 584), ('loves', 585), ('library', 586), ('likely', 587), ('goes', 588), ('missed', 589), ('weather', 590), ('turned', 591), ('hour', 592), ('cut', 593), ('sad', 594), ('willing', 595), ('learned', 596), ('prepared', 597), ('lying', 598), ('fix', 599), ('japanese', 600), ('taking', 601), ('become', 602), ('until', 603), ('sometimes', 604), ('dogs', 605), ('appreciate', 606), ('plans', 607), ('five', 608), ('box', 609), ('blame', 610), ('glad', 611), ('mistakes', 612), ('test', 613), ('matter', 614), ('dream', 615), ('actually', 616), ('restaurant', 617), ('under', 618), ('message', 619), ('clothes', 620), ('part', 621), ('class', 622), ('tree', 623), ('hat', 624), ('order', 625), ('needed', 626), ('promise', 627), ('present', 628), ('dollars', 629), ('careful', 630), ('opinion', 631), ('basketball', 632), ('information', 633), ('glasses', 634), ('inside', 635), ('cost', 636), ('somebody', 637), ('daughter', 638), ('moment', 639), ('wake', 640), ('reason', 641), ('famous', 642), ('light', 643), ('hospital', 644), ('piano', 645), ('behind', 646), ('follow', 647), ('guess', 648), ('prefer', 649), ('flowers', 650), ('curious', 651), ('thanks', 652), ('church', 653), ('accept', 654), ('studied', 655), ('welcome', 656), ('feeling', 657), ('fat', 658), ('drinking', 659), ('move', 660), ('full', 661), ('lied', 662), ('expect', 663), ('quickly', 664), ('break', 665), ('sell', 666), ('speaking', 667), ('apologize', 668), ('chance', 669), ('store', 670), ('large', 671), ('death', 672), ('cry', 673), ('weight', 674), ('satisfied', 675), ('wear', 676), ('save', 677), ('waited', 678), ('uncle', 679), ('birthday', 680), ('cup', 681), ('confused', 682), ('dress', 683), ('saying', 684), ('ran', 685), ('showed', 686), ('baseball', 687), ('loved', 688), ('leaving', 689), ('strong', 690), ('sent', 691), ('smoke', 692), ('then', 693), ('quit', 694), ('attention', 695), ('vacation', 696), ('war', 697), ('cannot', 698), ('short', 699), ('owe', 700), ('pass', 701), ('telling', 702), ('kissed', 703), ('whole', 704), ('decision', 705), ('comes', 706), ('caught', 707), ('writing', 708), ('ride', 709), ('bored', 710), ('check', 711), ('minute', 712), ('terrible', 713), ('gets', 714), ('list', 715), ('rest', 716), ('taught', 717), ('desk', 718), ('blue', 719), ('six', 720), ('closed', 721), ('sugar', 722), ('black', 723), ('garden', 724), ('protect', 725), ('guitar', 726), ('knife', 727), ('cats', 728), ('second', 729), ('language', 730), ('disappointed', 731), ('decide', 732), ('excuse', 733), ('cake', 734), ('company', 735), ('sign', 736), ('alive', 737), ('lawyer', 738), ('through', 739), ('white', 740), ('report', 741), ('several', 742), ('waste', 743), ('business', 744), ('others', 745), ('bag', 746), ('happens', 747), ('movies', 748), ('crying', 749), ('shy', 750), ('dark', 751), ('listening', 752), ('hit', 753), ('broken', 754), ('trip', 755), ('rules', 756), ('hated', 757), ('catch', 758), ('brought', 759), ('drank', 760), ('glass', 761), ('offer', 762), ('street', 763), ('plane', 764), ('between', 765), ('join', 766), ('smart', 767), ('keys', 768), ('jail', 769), ('paper', 770), ('convinced', 771), ('meat', 772), ('choice', 773), ('borrow', 774), ('sat', 775), ('dictionary', 776), ('walking', 777), ('happening', 778), ('ice', 779), ('opened', 780), ('wash', 781), ('singing', 782), ('patient', 783), ('address', 784), ('learning', 785), ('special', 786), ('sleeping', 787), ('concert', 788), ('abroad', 789), ('heart', 790), ('promised', 791), ('radio', 792), ('player', 793), ('younger', 794), ('unhappy', 795), ('hide', 796), ('fault', 797), ('recently', 798), ('beach', 799), ('end', 800), ('refused', 801), ('arrive', 802), ('fishing', 803), ('return', 804), ('tokyo', 805), ('travel', 806), ('during', 807), ('awake', 808), ('situation', 809), ('shopping', 810), ('guilty', 811), ('months', 812), ('begin', 813), ('afford', 814), ('also', 815), ('camera', 816), ('dancing', 817), ('arrested', 818), ('horse', 819), ('bread', 820), ('running', 821), ('planning', 822), ('smile', 823), ('husband', 824), ('zoo', 825), ('gun', 826), ('laughing', 827), ('somewhere', 828), ('advised', 829), ('bank', 830), ('taken', 831), ('speaks', 832), ('women', 833), ('laughed', 834), ('favor', 835), ('men', 836), ('translate', 837), ('correct', 838), ('poor', 839), ('snow', 840), ('control', 841), ('soccer', 842), ('stand', 843), ('joke', 844), ('soup', 845), ('grew', 846), ('ticket', 847), ('front', 848), ('road', 849), ('stole', 850), ('fired', 851), ('visited', 852), ('face', 853), ('medicine', 854), ('plays', 855), ('brave', 856), ('respect', 857), ('fight', 858), ('spoke', 859), ('solve', 860), ('noise', 861), ('along', 862), ('baby', 863), ('twice', 864), ('walked', 865), ('pain', 866), ('apartment', 867), ('sandwich', 868), ('annoying', 869), ('excited', 870), ('eggs', 871), ('anywhere', 872), ('oclock', 873), ('apples', 874), ('helping', 875), ('upset', 876), ('telephone', 877), ('extremely', 878), ('worse', 879), ('driver', 880), ('college', 881), ('half', 882), ('cooking', 883), ('common', 884), ('shot', 885), ('cars', 886), ('exam', 887), ('surprise', 888), ('count', 889), ('written', 890), ('lots', 891), ('stolen', 892), ('asking', 893), ('known', 894), ('prison', 895), ('hates', 896), ('sense', 897), ('fruit', 898), ('taxi', 899), ('whose', 900), ('wonderful', 901), ('choose', 902), ('sleepy', 903), ('languages', 904), ('tie', 905), ('hiding', 906), ('returned', 907), ('words', 908), ('whether', 909), ('finally', 910), ('gift', 911), ('bill', 912), ('raining', 913), ('innocent', 914), ('voice', 915), ('allowed', 916), ('building', 917), ('impressed', 918), ('dressed', 919), ('shut', 920), ('shop', 921), ('quiet', 922), ('stuff', 923), ('girls', 924), ('necessary', 925), ('recognize', 926), ('popular', 927), ('head', 928), ('slow', 929), ('boss', 930), ('depressed', 931), ('america', 932), ('sounds', 933), ('airport', 934), ('deserve', 935), ('vote', 936), ('sold', 937), ('calm', 938), ('received', 939), ('laugh', 940), ('ship', 941), ('passed', 942), ('eats', 943), ('forgive', 944), ('sitting', 945), ('thirsty', 946), ('rice', 947), ('risk', 948), ('bottle', 949), ('color', 950), ('hey', 951), ('yes', 952), ('moved', 953), ('future', 954), ('project', 955), ('kitchen', 956), ('kids', 957), ('carefully', 958), ('marry', 959), ('wedding', 960), ('fly', 961), ('october', 962), ('floor', 963), ('slowly', 964), ('driving', 965), ('four', 966), ('football', 967), ('lend', 968), ('doubt', 969), ('teeth', 970), ('boring', 971), ('least', 972), ('bridge', 973), ('staying', 974), ('novel', 975), ('seven', 976), ('clear', 977), ('takes', 978), ('ideas', 979), ('simple', 980), ('accepted', 981), ('brothers', 982), ('coat', 983), ('boys', 984), ('empty', 985), ('embarrassed', 986), ('lazy', 987), ('obviously', 988), ('built', 989), ('immediately', 990), ('throw', 991), ('less', 992), ('hold', 993), ('2013', 994), ('consider', 995), ('normal', 996), ('blind', 997), ('leg', 998), ('danger', 999), ('wall', 1000), ('couple', 1001), ('neighbor', 1002), ('certain', 1003), ('truck', 1004), ('either', 1005), ('calling', 1006), ('aware', 1007), ('paris', 1008), ('handsome', 1009), ('traffic', 1010), ('certainly', 1011), ('impossible', 1012), ('ordered', 1013), ('air', 1014), ('public', 1015), ('completely', 1016), ('deal', 1017), ('denied', 1018), ('worth', 1019), ('letters', 1020), ('weird', 1021), ('winter', 1022), ('washed', 1023), ('ring', 1024), ('punished', 1025), ('lake', 1026), ('bath', 1027), ('drinks', 1028), ('answered', 1029), ('noticed', 1030), ('share', 1031), ('support', 1032), ('jackson', 1033), ('suspect', 1034), ('pictures', 1035), ('sports', 1036), ('shirt', 1037), ('weeks', 1038), ('continue', 1039), ('enjoyed', 1040), ('fall', 1041), ('shower', 1042), ('hid', 1043), ('saved', 1044), ('liar', 1045), ('smell', 1046), ('perhaps', 1047), ('tickets', 1048), ('watched', 1049), ('alibi', 1050), ('dishes', 1051), ('chess', 1052), ('law', 1053), ('bother', 1054), ('slept', 1055), ('prices', 1056), ('sentence', 1057), ('side', 1058), ('rent', 1059), ('dirty', 1060), ('entered', 1061), ('details', 1062), ('television', 1063), ('forgotten', 1064), ('wet', 1065), ('faster', 1066), ('neighbors', 1067), ('absent', 1068), ('europe', 1069), ('health', 1070), ('point', 1071), ('history', 1072), ('threw', 1073), ('sisters', 1074), ('unlucky', 1075), ('explanation', 1076), ('chair', 1077), ('beat', 1078), ('across', 1079), ('shoot', 1080), ('pencil', 1081), ('easily', 1082), ('speech', 1083), ('ill', 1084), ('bike', 1085), ('given', 1086), ('success', 1087), ('its', 1088), ('involved', 1089), ('difference', 1090), ('grateful', 1091), ('expected', 1092), ('obvious', 1093), ('singer', 1094), ('complaining', 1095), ('solution', 1096), ('named', 1097), ('expecting', 1098), ('foreign', 1099), ('heavy', 1100), ('polite', 1101), ('sun', 1102), ('fighting', 1103), ('seat', 1104), ('suspicious', 1105), ('grandfather', 1106), ('york', 1107), ('license', 1108), ('followed', 1109), ('failed', 1110), ('bird', 1111), ('animals', 1112), ('duty', 1113), ('traveling', 1114), ('add', 1115), ('permission', 1116), ('copy', 1117), ('upstairs', 1118), ('experience', 1119), ('newspaper', 1120), ('till', 1121), ('songs', 1122), ('cream', 1123), ('worst', 1124), ('village', 1125), ('beginning', 1126), ('cute', 1127), ('buying', 1128), ('hundred', 1129), ('mouth', 1130), ('notice', 1131), ('grow', 1132), ('woke', 1133), ('intend', 1134), ('halloween', 1135), ('guys', 1136), ('annoyed', 1137), ('spaghetti', 1138), ('boat', 1139), ('feelings', 1140), ('excellent', 1141), ('map', 1142), ('taller', 1143), ('ignore', 1144), ('dying', 1145), ('piece', 1146), ('crime', 1147), ('rude', 1148), ('cards', 1149), ('invite', 1150), ('luck', 1151), ('sky', 1152), ('blood', 1153), ('single', 1154), ('attacked', 1155), ('chinese', 1156), ('explained', 1157), ('contact', 1158), ('god', 1159), ('spoken', 1160), ('wise', 1161), ('locked', 1162), ('regret', 1163), ('hired', 1164), ('bet', 1165), ('relax', 1166), ('selfish', 1167), ('aggressive', 1168), ('american', 1169), ('unusual', 1170), ('poker', 1171), ('subject', 1172), ('pick', 1173), ('lock', 1174), ('plenty', 1175), ('allergic', 1176), ('case', 1177), ('taste', 1178), ('optimistic', 1179), ('hug', 1180), ('pleased', 1181), ('seriously', 1182), ('admitted', 1183), ('stuck', 1184), ('china', 1185), ('perfectly', 1186), ('survive', 1187), ('group', 1188), ('ignored', 1189), ('discuss', 1190), ('ball', 1191), ('absolutely', 1192), ('reply', 1193), ('painting', 1194), ('trees', 1195), ('enemies', 1196), ('suicide', 1197), ('dad', 1198), ('invitation', 1199), ('proposal', 1200), ('idiot', 1201), ('attend', 1202), ('canadians', 1203), ('starting', 1204), ('teachers', 1205), ('raise', 1206), ('delicious', 1207), ('accused', 1208), ('eight', 1209), ('button', 1210), ('enemy', 1211), ('butter', 1212), ('keeps', 1213), ('headache', 1214), ('painted', 1215), ('offered', 1216), ('responsible', 1217), ('healthy', 1218), ('fixed', 1219), ('ugly', 1220), ('means', 1221), ('thirteen', 1222), ('talks', 1223), ('deep', 1224), ('smiled', 1225), ('cried', 1226), ('warm', 1227), ('arm', 1228), ('set', 1229), ('math', 1230), ('pool', 1231), ('cousin', 1232), ('teaching', 1233), ('handle', 1234), ('grandmother', 1235), ('recommend', 1236), ('secrets', 1237), ('cheap', 1238), ('fed', 1239), ('handed', 1240), ('admit', 1241), ('attended', 1242), ('reasonable', 1243), ('italy', 1244), ('raised', 1245), ('answers', 1246), ('past', 1247), ('complain', 1248), ('listened', 1249), ('london', 1250), ('continued', 1251), ('neither', 1252), ('using', 1253), ('salt', 1254), ('wears', 1255), ('abandoned', 1256), ('wallet', 1257), ('harder', 1258), ('forever', 1259), ('chicken', 1260), ('lights', 1261), ('university', 1262), ('moving', 1263), ('enter', 1264), ('imagine', 1265), ('yen', 1266), ('seldom', 1267), ('giving', 1268), ('believed', 1269), ('france', 1270), ('attack', 1271), ('president', 1272), ('horrible', 1273), ('leaves', 1274), ('remained', 1275), ('united', 1276), ('huge', 1277), ('page', 1278), ('none', 1279), ('understood', 1280), ('rarely', 1281), ('interest', 1282), ('generous', 1283), ('dreams', 1284), ('states', 1285), ('feet', 1286), ('forced', 1287), ('mail', 1288), ('birds', 1289), ('earlier', 1290), ('assistant', 1291), ('joking', 1292), ('friendly', 1293), ('seeing', 1294), ('desperate', 1295), ('cancer', 1296), ('smiling', 1297), ('losing', 1298), ('naive', 1299), ('judge', 1300), ('rid', 1301), ('weak', 1302), ('sooner', 1303), ('eye', 1304), ('missing', 1305), ('agreed', 1306), ('retired', 1307), ('pale', 1308), ('washing', 1309), ('frightened', 1310), ('complicated', 1311), ('suggest', 1312), ('exhausted', 1313), ('nearly', 1314), ('concerned', 1315), ('fridge', 1316), ('pair', 1317), ('jokes', 1318), ('chocolate', 1319), ('quick', 1320), ('race', 1321), ('suitcase', 1322), ('mom', 1323), ('lately', 1324), ('prove', 1325), ('herself', 1326), ('green', 1327), ('betrayed', 1328), ('similar', 1329), ('silent', 1330), ('musician', 1331), ('intelligent', 1332), ('useful', 1333), ('policeman', 1334), ('patience', 1335), ('example', 1336), ('someday', 1337), ('mood', 1338), ('heat', 1339), ('scary', 1340), ('photo', 1341), ('smarter', 1342), ('picked', 1343), ('caused', 1344), ('drove', 1345), ('private', 1346), ('30', 1347), ('flower', 1348), ('sundays', 1349), ('harvard', 1350), ('fan', 1351), ('poem', 1352), ('fact', 1353), ('passport', 1354), ('course', 1355), ('apologized', 1356), ('warn', 1357), ('practice', 1358), ('spring', 1359), ('noon', 1360), ('admire', 1361), ('jacket', 1362), ('cash', 1363), ('everywhere', 1364), ('romantic', 1365), ('totally', 1366), ('understands', 1367), ('area', 1368), ('sight', 1369), ('borrowed', 1370), ('kidding', 1371), ('kindness', 1372), ('ashamed', 1373), ('behavior', 1374), ('artist', 1375), ('mountain', 1376), ('breath', 1377), ('except', 1378), ('roof', 1379), ('believes', 1380), ('murder', 1381), ('meant', 1382), ('crossed', 1383), ('article', 1384), ('committed', 1385), ('trusted', 1386), ('nine', 1387), ('following', 1388), ('hero', 1389), ('allow', 1390), ('covered', 1391), ('neighborhood', 1392), ('lonely', 1393), ('potatoes', 1394), ('ended', 1395), ('anyway', 1396), ('wasting', 1397), ('banana', 1398), ('cross', 1399), ('politics', 1400), ('prize', 1401), ('nose', 1402), ('fair', 1403), ('options', 1404), ('stubborn', 1405), ('windows', 1406), ('escaped', 1407), ('theory', 1408), ('stone', 1409), ('stronger', 1410), ('appears', 1411), ('line', 1412), ('body', 1413), ('injured', 1414), ('purpose', 1415), ('approve', 1416), ('sushi', 1417), ('suddenly', 1418), ('whatever', 1419), ('available', 1420), ('cheese', 1421), ('holiday', 1422), ('saturday', 1423), ('rains', 1424), ('personal', 1425), ('calls', 1426), ('request', 1427), ('novels', 1428), ('bigger', 1429), ('brush', 1430), ('band', 1431), ('impatient', 1432), ('instead', 1433), ('poison', 1434), ('relaxed', 1435), ('cafeteria', 1436), ('result', 1437), ('succeed', 1438), ('anxious', 1439), ('results', 1440), ('midnight', 1441), ('government', 1442), ('captain', 1443), ('games', 1444), ('shocked', 1445), ('wounded', 1446), ('feels', 1447), ('remain', 1448), ('warned', 1449), ('legs', 1450), ('clearly', 1451), ('definitely', 1452), ('signed', 1453), ('earth', 1454), ('escape', 1455), ('lift', 1456), ('smells', 1457), ('engine', 1458), ('adopted', 1459), ('divorced', 1460), ('horses', 1461), ('solved', 1462), ('pretended', 1463), ('museum', 1464), ('pie', 1465), ('sea', 1466), ('machine', 1467), ('supermarket', 1468), ('skeptical', 1469), ('classroom', 1470), ('rock', 1471), ('ought', 1472), ('furious', 1473), ('active', 1474), ('goal', 1475), ('vegetables', 1476), ('bright', 1477), ('bothering', 1478), ('fever', 1479), ('becoming', 1480), ('gives', 1481), ('loud', 1482), ('reach', 1483), ('chicago', 1484), ('date', 1485), ('privacy', 1486), ('themselves', 1487), ('smaller', 1488), ('deaf', 1489), ('burned', 1490), ('skiing', 1491), ('gym', 1492), ('entire', 1493), ('paying', 1494), ('feed', 1495), ('foot', 1496), ('thief', 1497), ('elevator', 1498), ('pray', 1499), ('orange', 1500), ('deceived', 1501), ('arguing', 1502), ('steal', 1503), ('expert', 1504), ('fear', 1505), ('names', 1506), ('sweater', 1507), ('amazing', 1508), ('hobby', 1509), ('bear', 1510), ('art', 1511), ('belongs', 1512), ('standing', 1513), ('coward', 1514), ('recognized', 1515), ('lottery', 1516), ('hello', 1517), ('chose', 1518), ('elected', 1519), ('repeat', 1520), ('obey', 1521), ('native', 1522), ('friday', 1523), ('sang', 1524), ('stranger', 1525), ('moon', 1526), ('power', 1527), ('cool', 1528), ('club', 1529), ('low', 1530), ('middle', 1531), ('gotten', 1532), ('traveled', 1533), ('stamps', 1534), ('checked', 1535), ('flight', 1536), ('space', 1537), ('fantastic', 1538), ('gold', 1539), ('cleaned', 1540), ('accustomed', 1541), ('storm', 1542), ('push', 1543), ('unable', 1544), ('top', 1545), ('germany', 1546), ('actor', 1547), ('challenge', 1548), ('classes', 1549), ('contract', 1550), ('within', 1551), ('filled', 1552), ('belong', 1553), ('staring', 1554), ('easier', 1555), ('kid', 1556), ('sincere', 1557), ('exciting', 1558), ('introduced', 1559), ('cookies', 1560), ('ruined', 1561), ('ambitious', 1562), ('overweight', 1563), ('juice', 1564), ('sons', 1565), ('science', 1566), ('deserves', 1567), ('internet', 1568), ('energy', 1569), ('diary', 1570), ('examination', 1571), ('repair', 1572), ('fallen', 1573), ('usual', 1574), ('illegal', 1575), ('changes', 1576), ('attractive', 1577), ('tough', 1578), ('meals', 1579), ('orders', 1580), ('writer', 1581), ('disagree', 1582), ('discreet', 1583), ('fail', 1584), ('wondered', 1585), ('progress', 1586), ('funeral', 1587), ('rule', 1588), ('sweet', 1589), ('silence', 1590), ('loss', 1591), ('destroyed', 1592), ('coach', 1593), ('suggested', 1594), ('parties', 1595), ('thin', 1596), ('market', 1597), ('doors', 1598), ('video', 1599), ('tells', 1600), ('screaming', 1601), ('bedroom', 1602), ('mondays', 1603), ('soldiers', 1604), ('aunt', 1605), ('nurse', 1606), ('embarrassing', 1607), ('size', 1608), ('complete', 1609), ('avoid', 1610), ('threatened', 1611), ('innocence', 1612), ('strict', 1613), ('motivated', 1614), ('paint', 1615), ('motel', 1616), ('teaches', 1617), ('starts', 1618), ('record', 1619), ('program', 1620), ('army', 1621), ('bathroom', 1622), ('fresh', 1623), ('poured', 1624), ('awful', 1625), ('land', 1626), ('shall', 1627), ('cooked', 1628), ('spending', 1629), ('fond', 1630), ('bar', 1631), ('appointment', 1632), ('facts', 1633), ('thankful', 1634), ('third', 1635), ('sharp', 1636), ('treat', 1637), ('studies', 1638), ('hardly', 1639), ('chef', 1640), ('guests', 1641), ('selling', 1642), ('gas', 1643), ('forest', 1644), ('magazine', 1645), ('ridiculous', 1646), ('frustrated', 1647), ('argue', 1648), ('meaning', 1649), ('disappeared', 1650), ('bench', 1651), ('charge', 1652), ('homesick', 1653), ('ahead', 1654), ('modest', 1655), ('hang', 1656), ('held', 1657), ('kyoto', 1658), ('runs', 1659), ('tastes', 1660), ('voted', 1661), ('celebrate', 1662), ('capital', 1663), ('rome', 1664), ('leader', 1665), ('interfere', 1666), ('computers', 1667), ('type', 1668), ('greedy', 1669), ('successful', 1670), ('distance', 1671), ('mistaken', 1672), ('fortune', 1673), ('oranges', 1674), ('kinds', 1675), ('cause', 1676), ('creative', 1677), ('owner', 1678), ('closer', 1679), ('candles', 1680), ('decisions', 1681), ('comfortable', 1682), ('woods', 1683), ('card', 1684), ('towel', 1685), ('king', 1686), ('shape', 1687), ('amused', 1688), ('wind', 1689), ('mathematics', 1690), ('twenty', 1691), ('canceled', 1692), ('exercise', 1693), ('jazz', 1694), ('link', 1695), ('toilet', 1696), ('invented', 1697), ('hockey', 1698), ('unlikely', 1699), ('wore', 1700), ('canada', 1701), ('bush', 1702), ('20', 1703), ('peace', 1704), ('dentist', 1705), ('downstairs', 1706), ('careless', 1707), ('countries', 1708), ('considered', 1709), ('grown', 1710), ('corner', 1711), ('carrots', 1712), ('managed', 1713), ('translated', 1714), ('clock', 1715), ('barely', 1716), ('memory', 1717), ('courage', 1718), ('natural', 1719), ('happiness', 1720), ('instructions', 1721), ('religious', 1722), ('theater', 1723), ('salary', 1724), ('bananas', 1725), ('yellow', 1726), ('offended', 1727), ('pity', 1728), ('costs', 1729), ('speaker', 1730), ('garage', 1731), ('hurts', 1732), ('ketchup', 1733), ('wealthy', 1734), ('diet', 1735), ('realized', 1736), ('prepare', 1737), ('babysitter', 1738), ('helps', 1739), ('schedule', 1740), ('naked', 1741), ('dating', 1742), ('photogenic', 1743), ('pens', 1744), ('mess', 1745), ('costume', 1746), ('hopes', 1747), ('step', 1748), ('failure', 1749), ('acting', 1750), ('begins', 1751), ('improve', 1752), ('nearby', 1753), ('nearest', 1754), ('gullible', 1755), ('grumpy', 1756), ('direct', 1757), ('touched', 1758), ('island', 1759), ('sunglasses', 1760), ('act', 1761), ('conversation', 1762), ('discovered', 1763), ('prude', 1764), ('refuse', 1765), ('risks', 1766), ('member', 1767), ('talented', 1768), ('trapped', 1769), ('helpful', 1770), ('hoping', 1771), ('stealing', 1772), ('german', 1773), ('match', 1774), ('faith', 1775), ('reached', 1776), ('familiar', 1777), ('forward', 1778), ('criminal', 1779), ('among', 1780), ('dessert', 1781), ('cancel', 1782), ('discussed', 1783), ('imagination', 1784), ('carry', 1785), ('hire', 1786), ('lent', 1787), ('website', 1788), ('incredible', 1789), ('convince', 1790), ('animal', 1791), ('irritated', 1792), ('picky', 1793), ('hearing', 1794), ('difficulty', 1795), ('persistent', 1796), ('presents', 1797), ('password', 1798), ('supper', 1799), ('thanked', 1800), ('figure', 1801), ('system', 1802), ('rang', 1803), ('describe', 1804), ('worrying', 1805), ('spends', 1806), ('gate', 1807), ('dumb', 1808), ('suffer', 1809), ('suppose', 1810), ('farm', 1811), ('kicked', 1812), ('danced', 1813), ('rooms', 1814), ('deeply', 1815), ('writes', 1816), ('castle', 1817), ('beard', 1818), ('oh', 1819), ('kissing', 1820), ('daughters', 1821), ('sounded', 1822), ('pushed', 1823), ('pants', 1824), ('picnic', 1825), ('lies', 1826), ('vegetarian', 1827), ('meal', 1828), ('betray', 1829), ('generally', 1830), ('begun', 1831), ('twin', 1832), ('interrupt', 1833), ('twins', 1834), ('gloves', 1835), ('file', 1836), ('blackboard', 1837), ('season', 1838), ('winning', 1839), ('energetic', 1840), ('depends', 1841), ('cares', 1842), ('jobs', 1843), ('fully', 1844), ('advance', 1845), ('aspirin', 1846), ('positive', 1847), ('moody', 1848), ('resign', 1849), ('modern', 1850), ('fill', 1851), ('hammer', 1852), ('reservation', 1853), ('distracted', 1854), ('tattoo', 1855), ('separated', 1856), ('opportunity', 1857), ('100', 1858), ('hurting', 1859), ('rained', 1860), ('pessimistic', 1861), ('understanding', 1862), ('10', 1863), ('attentive', 1864), ('violin', 1865), ('pulled', 1866), ('package', 1867), ('complaints', 1868), ('genius', 1869), ('dedicated', 1870), ('survived', 1871), ('tallest', 1872), ('advantage', 1873), ('view', 1874), ('realistic', 1875), ('stood', 1876), ('spoon', 1877), ('banjo', 1878), ('iron', 1879), ('fit', 1880), ('yourselves', 1881), ('cleaning', 1882), ('holidays', 1883), ('messages', 1884), ('comment', 1885), ('stories', 1886), ('relieved', 1887), ('santa', 1888), ('rope', 1889), ('carried', 1890), ('mall', 1891), ('bite', 1892), ('snakes', 1893), ('priest', 1894), ('prisoner', 1895), ('impolite', 1896), ('professional', 1897), ('couch', 1898), ('account', 1899), ('beauty', 1900), ('hiking', 1901), ('socks', 1902), ('credit', 1903), ('candy', 1904), ('secretary', 1905), ('straight', 1906), ('wood', 1907), ('ski', 1908), ('refrigerator', 1909), ('pieces', 1910), ('stars', 1911), ('skinny', 1912), ('motorcycle', 1913), ('organized', 1914), ('film', 1915), ('particular', 1916), ('climbed', 1917), ('cab', 1918), ('scissors', 1919), ('doll', 1920), ('pathetic', 1921), ('introduce', 1922), ('reliable', 1923), ('bags', 1924), ('counting', 1925), ('document', 1926), ('habit', 1927), ('mystery', 1928), ('cousins', 1929), ('unambitious', 1930), ('dropped', 1931), ('crowd', 1932), ('cities', 1933), ('throat', 1934), ('text', 1935), ('truthful', 1936), ('album', 1937), ('sarcastic', 1938), ('ears', 1939), ('hugged', 1940), ('doubts', 1941), ('americans', 1942), ('spinach', 1943), ('stabbed', 1944), ('appeared', 1945), ('pretend', 1946), ('chaperone', 1947), ('lady', 1948), ('pork', 1949), ('players', 1950), ('confident', 1951), ('retire', 1952), ('pretending', 1953), ('sort', 1954), ('egg', 1955), ('shelf', 1956), ('competitive', 1957), ('fearless', 1958), ('arms', 1959), ('remind', 1960), ('condition', 1961), ('insurance', 1962), ('commit', 1963), ('stew', 1964), ('encouraged', 1965), ('though', 1966), ('mahjong', 1967), ('damage', 1968), ('tears', 1969), ('election', 1970), ('sale', 1971), ('africa', 1972), ('prisoners', 1973), ('human', 1974), ('handwriting', 1975), ('salad', 1976), ('million', 1977), ('spicy', 1978), ('fbi', 1979), ('humor', 1980), ('armed', 1981), ('ours', 1982), ('subway', 1983), ('served', 1984), ('ghosts', 1985), ('finding', 1986), ('repaired', 1987), ('skip', 1988), ('draw', 1989), ('concentrate', 1990), ('engaged', 1991), ('notes', 1992), ('snowing', 1993), ('lasted', 1994), ('disease', 1995), ('shook', 1996), ('scare', 1997), ('adventurous', 1998), ('emergency', 1999), ('larger', 2000), ('5', 2001), ('complained', 2002), ('grab', 2003), ('visiting', 2004), ('relationship', 2005), ('unfortunately', 2006), ('lower', 2007), ('keeping', 2008), ('india', 2009), ('authority', 2010), ('thousand', 2011), ('oven', 2012), ('hill', 2013), ('buried', 2014), ('apparently', 2015), ('ourselves', 2016), ('awesome', 2017), ('terribly', 2018), ('drives', 2019), ('dry', 2020), ('assume', 2021), ('essay', 2022), ('responsibility', 2023), ('asks', 2024), ('sensitive', 2025), ('audience', 2026), ('battle', 2027), ('burst', 2028), ('evidence', 2029), ('enjoys', 2030), ('confessed', 2031), ('impress', 2032), ('immature', 2033), ('lesson', 2034), ('south', 2035), ('bowl', 2036), ('defend', 2037), ('laptop', 2038), ('rumor', 2039), ('actress', 2040), ('waiter', 2041), ('junk', 2042), ('online', 2043), ('acted', 2044), ('form', 2045), ('fairly', 2046), ('scene', 2047), ('apart', 2048), ('doctors', 2049), ('harm', 2050), ('3', 2051), ('parked', 2052), ('explosion', 2053), ('nature', 2054), ('methodical', 2055), ('fake', 2056), ('hole', 2057), ('arrest', 2058), ('cookie', 2059), ('realize', 2060), ('informed', 2061), ('prevented', 2062), ('further', 2063), ('screwdriver', 2064), ('graduated', 2065), ('hunting', 2066), ('chosen', 2067), ('service', 2068), ('eve', 2069), ('houses', 2070), ('ruthless', 2071), ('suggestion', 2072), ('furniture', 2073), ('eventually', 2074), ('nor', 2075), ('dependable', 2076), ('silly', 2077), ('exist', 2078), ('ones', 2079), ('search', 2080), ('efforts', 2081), ('joined', 2082), ('cheated', 2083), ('cell', 2084), ('beating', 2085), ('receipt', 2086), ('post', 2087), ('england', 2088), ('dishonest', 2089), ('walks', 2090), ('ignoring', 2091), ('grass', 2092), ('finger', 2093), ('ocean', 2094), ('microwave', 2095), ('email', 2096), ('sandwiches', 2097), ('difficulties', 2098), ('evil', 2099), ('wasted', 2100), ('dreamed', 2101), ('odd', 2102), ('foolish', 2103), ('owns', 2104), ('confidence', 2105), ('pond', 2106), ('agreement', 2107), ('uses', 2108), ('sofa', 2109), ('reckless', 2110), ('beef', 2111), ('matters', 2112), ('oil', 2113), ('childhood', 2114), ('objective', 2115), ('adult', 2116), ('farmer', 2117), ('deny', 2118), ('useless', 2119), ('toy', 2120), ('cops', 2121), ('breathe', 2122), ('sometime', 2123), ('shorter', 2124), ('scream', 2125), ('marriage', 2126), ('coincidence', 2127), ('alarm', 2128), ('exams', 2129), ('schizophrenic', 2130), ('jump', 2131), ('confirm', 2132), ('friendship', 2133), ('charming', 2134), ('oldest', 2135), ('pleasure', 2136), ('local', 2137), ('ground', 2138), ('concern', 2139), ('shock', 2140), ('behave', 2141), ('jumped', 2142), ('tidy', 2143), ('silver', 2144), ('unfair', 2145), ('clever', 2146), ('swear', 2147), ('urgent', 2148), ('curry', 2149), ('bribe', 2150), ('force', 2151), ('conservative', 2152), ('reasons', 2153), ('field', 2154), ('hall', 2155), ('documents', 2156), ('above', 2157), ('blamed', 2158), ('double', 2159), ('bleeding', 2160), ('menu', 2161), ('workers', 2162), ('fool', 2163), ('pays', 2164), ('worries', 2165), ('strength', 2166), ('timid', 2167), ('regrets', 2168), ('decisive', 2169), ('drums', 2170), ('cheaper', 2171), ('basket', 2172), ('pepper', 2173), ('drug', 2174), ('aboard', 2175), ('legal', 2176), ('hidden', 2177), ('connection', 2178), ('original', 2179), ('answering', 2180), ('largest', 2181), ('scientist', 2182), ('due', 2183), ('cigarette', 2184), ('determined', 2185), ('factory', 2186), ('appreciated', 2187), ('disgusted', 2188), ('issue', 2189), ('tower', 2190), ('peanuts', 2191), ('recovered', 2192), ('hi', 2193), ('places', 2194), ('suspended', 2195), ('receive', 2196), ('saving', 2197), ('citizen', 2198), ('nowhere', 2199), ('contagious', 2200), ('flying', 2201), ('ghost', 2202), ('quicker', 2203), ('fortunate', 2204), ('stick', 2205), ('buddhism', 2206), ('gifts', 2207), ('conference', 2208), ('poems', 2209), ('forgiven', 2210), ('paintings', 2211), ('tense', 2212), ('toward', 2213), ('stairs', 2214), ('achieved', 2215), ('rescued', 2216), ('drop', 2217), ('model', 2218), ('oboe', 2219), ('suffered', 2220), ('vodka', 2221), ('princess', 2222), ('earthquake', 2223), ('diamond', 2224), ('accent', 2225), ('journalist', 2226), ('butcher', 2227), ('lessons', 2228), ('500', 2229), ('restaurants', 2230), ('lit', 2231), ('treatment', 2232), ('removed', 2233), ('swimmer', 2234), ('error', 2235), ('trains', 2236), ('mashed', 2237), ('changing', 2238), ('passengers', 2239), ('newspapers', 2240), ('build', 2241), ('spanish', 2242), ('persuaded', 2243), ('italian', 2244), ('weapon', 2245), ('gorgeous', 2246), ('rented', 2247), ('automobile', 2248), ('promotion', 2249), ('driven', 2250), ('plants', 2251), ('trustworthy', 2252), ('trombone', 2253), ('skin', 2254), ('fifteen', 2255), ('parking', 2256), ('dare', 2257), ('magazines', 2258), ('planted', 2259), ('allergies', 2260), ('specific', 2261), ('sells', 2262), ('disgusting', 2263), ('neck', 2264), ('published', 2265), ('pronounce', 2266), ('papers', 2267), ('spain', 2268), ('intended', 2269), ('participate', 2270), ('dawn', 2271), ('coma', 2272), ('approved', 2273), ('press', 2274), ('surrounded', 2275), ('respond', 2276), ('spy', 2277), ('enjoying', 2278), ('unnecessary', 2279), ('avoiding', 2280), ('classical', 2281), ('peel', 2282), ('clumsy', 2283), ('exaggerating', 2284), ('vase', 2285), ('note', 2286), ('lovely', 2287), ('fascinating', 2288), ('data', 2289), ('extraordinary', 2290), ('risky', 2291), ('headed', 2292), ('strangers', 2293), ('fries', 2294), ('graduate', 2295), ('suffering', 2296), ('succeeded', 2297), ('cellphone', 2298), ('crowded', 2299), ('acceptable', 2300), ('mostly', 2301), ('sport', 2302), ('fasten', 2303), ('ladder', 2304), ('pianist', 2305), ('fashion', 2306), ('research', 2307), ('climb', 2308), ('roses', 2309), ('brilliant', 2310), ('cow', 2311), ('laundry', 2312), ('drowned', 2313), ('translation', 2314), ('yelling', 2315), ('classmates', 2316), ('advise', 2317), ('direction', 2318), ('champagne', 2319), ('action', 2320), ('punctual', 2321), ('facebook', 2322), ('stays', 2323), ('unconscious', 2324), ('cap', 2325), ('accompanied', 2326), ('rescue', 2327), ('anger', 2328), ('shake', 2329), ('intrigued', 2330), ('luggage', 2331), ('brown', 2332), ('illness', 2333), ('airplane', 2334), ('temperature', 2335), ('ear', 2336), ('personally', 2337), ('damaged', 2338), ('claus', 2339), ('ipad', 2340), ('absurd', 2341), ('sneaky', 2342), ('happier', 2343), ('karate', 2344), ('belt', 2345), ('preparing', 2346), ('according', 2347), ('sympathetic', 2348), ('whenever', 2349), ('incredibly', 2350), ('forgetting', 2351), ('300', 2352), ('pleasant', 2353), ('cheat', 2354), ('connected', 2355), ('bible', 2356), ('freedom', 2357), ('suggestions', 2358), ('chairs', 2359), ('option', 2360), ('impulsive', 2361), ('fifty', 2362), ('wins', 2363), ('cooperating', 2364), ('rejected', 2365), ('resigned', 2366), ('shouting', 2367), ('taxes', 2368), ('mt', 2369), ('seats', 2370), ('threaten', 2371), ('introverted', 2372), ('sophisticated', 2373), ('contacted', 2374), ('planet', 2375), ('pink', 2376), ('promoted', 2377), ('painter', 2378), ('treated', 2379), ('mission', 2380), ('misses', 2381), ('twelve', 2382), ('particularly', 2383), ('shallow', 2384), ('deceive', 2385), ('collecting', 2386), ('soft', 2387), ('roommate', 2388), ('cave', 2389), ('stomach', 2390), ('capable', 2391), ('breaking', 2392), ('hardworking', 2393), ('shared', 2394), ('compared', 2395), ('assistance', 2396), ('stare', 2397), ('complex', 2398), ('mature', 2399), ('frequently', 2400), ('reads', 2401), ('alternative', 2402), ('misunderstood', 2403), ('possibility', 2404), ('meetings', 2405), ('murdered', 2406), ('effort', 2407), ('disturbing', 2408), ('tore', 2409), ('incident', 2410), ('tourists', 2411), ('visitors', 2412), ('remains', 2413), ('improving', 2414), ('disturb', 2415), ('fence', 2416), ('dislike', 2417), ('ashtray', 2418), ('position', 2419), ('proof', 2420), ('impression', 2421), ('sings', 2422), ('safety', 2423), ('checking', 2424), ('voices', 2425), ('relatives', 2426), ('artistic', 2427), ('metal', 2428), ('crossing', 2429), ('appetite', 2430), ('photos', 2431), ('hesitated', 2432), ('weigh', 2433), ('mountains', 2434), ('spot', 2435), ('dozen', 2436), ('although', 2437), ('acquainted', 2438), ('north', 2439), ('rugby', 2440), ('growing', 2441), ('crashed', 2442), ('shaken', 2443), ('noisy', 2444), ('surgeon', 2445), ('promises', 2446), ('clouds', 2447), ('pigeons', 2448), ('bottom', 2449), ('released', 2450), ('slipped', 2451), ('hanging', 2452), ('thorough', 2453), ('honeymoon', 2454), ('sore', 2455), ('lead', 2456), ('stock', 2457), ('blog', 2458), ('deserved', 2459), ('insulted', 2460), ('opening', 2461), ('owes', 2462), ('disorganized', 2463), ('copies', 2464), ('required', 2465), ('causing', 2466), ('watches', 2467), ('total', 2468), ('6', 2469), ('fingers', 2470), ('filthy', 2471), ('forgave', 2472), ('prom', 2473), ('pillow', 2474), ('groups', 2475), ('simply', 2476), ('illiterate', 2477), ('dna', 2478), ('stingy', 2479), ('nerd', 2480), ('rifle', 2481), ('mentioned', 2482), ('nights', 2483), ('shave', 2484), ('surprising', 2485), ('easygoing', 2486), ('foreigner', 2487), ('remembered', 2488), ('tasted', 2489), ('average', 2490), ('screamed', 2491), ('partner', 2492), ('correctly', 2493), ('hawaii', 2494), ('underestimate', 2495), ('apply', 2496), ('troubled', 2497), ('earned', 2498), ('addict', 2499), ('violent', 2500), ('burn', 2501), ('sweat', 2502), ('misunderstanding', 2503), ('temper', 2504), ('tourist', 2505), ('cocaine', 2506), ('violence', 2507), ('cover', 2508), ('pandas', 2509), ('pocket', 2510), ('mouse', 2511), ('decorated', 2512), ('hunter', 2513), ('wild', 2514), ('objection', 2515), ('weighs', 2516), ('phoned', 2517), ('final', 2518), ('loser', 2519), ('barking', 2520), ('latin', 2521), ('conscientious', 2522), ('fuji', 2523), ('bitter', 2524), ('pressure', 2525), ('wow', 2526), ('blanket', 2527), ('attracted', 2528), ('insects', 2529), ('colors', 2530), ('bookstore', 2531), ('declined', 2532), ('miserable', 2533), ('express', 2534), ('general', 2535), ('schools', 2536), ('compromise', 2537), ('skirt', 2538), ('cop', 2539), ('remembers', 2540), ('efficient', 2541), ('slightly', 2542), ('bell', 2543), ('tshirt', 2544), ('korean', 2545), ('influence', 2546), ('reserved', 2547), ('recommended', 2548), ('term', 2549), ('scarf', 2550), ('savings', 2551), ('goodbye', 2552), ('biggest', 2553), ('medal', 2554), ('rainy', 2555), ('powerful', 2556), ('soldier', 2557), ('trusts', 2558), ('uniform', 2559), ('birth', 2560), ('earns', 2561), ('rights', 2562), ('musical', 2563), ('yacht', 2564), ('drawer', 2565), ('trap', 2566), ('intention', 2567), ('bound', 2568), ('beginner', 2569), ('mexico', 2570), ('ends', 2571), ('disturbed', 2572), ('corrected', 2573), ('sheet', 2574), ('collect', 2575), ('ignorance', 2576), ('materialistic', 2577), ('bald', 2578), ('mirror', 2579), ('circle', 2580), ('dyed', 2581), ('eleven', 2582), ('badly', 2583), ('security', 2584), ('patients', 2585), ('weirdo', 2586), ('higher', 2587), ('spiders', 2588), ('talent', 2589), ('main', 2590), ('prayed', 2591), ('assist', 2592), ('parttime', 2593), ('event', 2594), ('drugs', 2595), ('grandparents', 2596), ('courageous', 2597), ('fox', 2598), ('improved', 2599), ('attic', 2600), ('ringing', 2601), ('members', 2602), ('pasta', 2603), ('ability', 2604), ('wherever', 2605), ('warning', 2606), ('garbage', 2607), ('national', 2608), ('secretive', 2609), ('physics', 2610), ('unless', 2611), ('confirmed', 2612), ('earn', 2613), ('pushy', 2614), ('boots', 2615), ('department', 2616), ('miles', 2617), ('popcorn', 2618), ('refund', 2619), ('embarrass', 2620), ('alcoholic', 2621), ('round', 2622), ('listens', 2623), ('flew', 2624), ('robbed', 2625), ('camping', 2626), ('bitten', 2627), ('replaced', 2628), ('provided', 2629), ('los', 2630), ('angeles', 2631), ('incorrect', 2632), ('ancient', 2633), ('star', 2634), ('located', 2635), ('whoever', 2636), ('loudly', 2637), ('honey', 2638), ('sensible', 2639), ('shampoo', 2640), ('divorce', 2641), ('bee', 2642), ('racket', 2643), ('spoiled', 2644), ('designed', 2645), ('swam', 2646), ('wisely', 2647), ('dreaming', 2648), ('bomb', 2649), ('spare', 2650), ('catholic', 2651), ('terrified', 2652), ('poet', 2653), ('assumed', 2654), ('absence', 2655), ('fax', 2656), ('unmarried', 2657), ('unkind', 2658), ('various', 2659), ('unpredictable', 2660), ('toys', 2661), ('replace', 2662), ('kobe', 2663), ('falling', 2664), ('forty', 2665), ('memorize', 2666), ('prejudiced', 2667), ('professor', 2668), ('wooden', 2669), ('helpless', 2670), ('adults', 2671), ('interpreter', 2672), ('respected', 2673), ('border', 2674), ('highly', 2675), ('amusing', 2676), ('entirely', 2677), ('carrying', 2678), ('mayor', 2679), ('cooperative', 2680), ('prohibited', 2681), ('population', 2682), ('pharmacy', 2683), ('persuade', 2684), ('protection', 2685), ('mobile', 2686), ('skipped', 2687), ('fooled', 2688), ('accurate', 2689), ('inevitable', 2690), ('permit', 2691), ('author', 2692), ('instrument', 2693), ('directly', 2694), ('volleyball', 2695), ('exception', 2696), ('envelope', 2697), ('knee', 2698), ('jogging', 2699), ('owned', 2700), ('creepy', 2701), ('manage', 2702), ('east', 2703), ('agrees', 2704), ('character', 2705), ('kilograms', 2706), ('rose', 2707), ('false', 2708), ('suspected', 2709), ('contented', 2710), ('microscope', 2711), ('holding', 2712), ('added', 2713), ('exit', 2714), ('athletic', 2715), ('stopping', 2716), ('brandy', 2717), ('spell', 2718), ('cd', 2719), ('considering', 2720), ('medical', 2721), ('rising', 2722), ('comments', 2723), ('1000', 2724), ('20th', 2725), ('queen', 2726), ('gained', 2727), ('lay', 2728), ('mention', 2729), ('method', 2730), ('ceremony', 2731), ('greeted', 2732), ('education', 2733), ('imagined', 2734), ('calculator', 2735), ('experienced', 2736), ('boxes', 2737), ('apology', 2738), ('cups', 2739), ('treaty', 2740), ('political', 2741), ('postponed', 2742), ('criticism', 2743), ('chat', 2744), ('alcohol', 2745), ('babbling', 2746), ('fascinated', 2747), ('center', 2748), ('rare', 2749), ('arrogant', 2750), ('grades', 2751), ('shoulder', 2752), ('biased', 2753), ('electricity', 2754), ('desert', 2755), ('blaming', 2756), ('disappoint', 2757), ('created', 2758), ('west', 2759), ('10000', 2760), ('related', 2761), ('nephew', 2762), ('tied', 2763), ('dissatisfied', 2764), ('searched', 2765), ('employees', 2766), ('goods', 2767), ('magic', 2768), ('detail', 2769), ('april', 2770), ('killing', 2771), ('flexible', 2772), ('awkward', 2773), ('cooperation', 2774), ('gentleman', 2775), ('uninteresting', 2776), ('exchanged', 2777), ('numbers', 2778), ('fabulous', 2779), ('lines', 2780), ('limited', 2781), ('cleared', 2782), ('opposite', 2783), ('manager', 2784), ('extroverted', 2785), ('donated', 2786), ('conscious', 2787), ('brain', 2788), ('entrance', 2789), ('gambling', 2790), ('turkey', 2791), ('suit', 2792), ('50', 2793), ('volunteered', 2794), ('degrees', 2795), ('desire', 2796), ('cruel', 2797), ('ambulance', 2798), ('sees', 2799), ('enthusiastic', 2800), ('demand', 2801), ('designer', 2802), ('destiny', 2803), ('pilot', 2804), ('basement', 2805), ('worn', 2806), ('nowadays', 2807), ('focused', 2808), ('fork', 2809), ('abandon', 2810), ('explaining', 2811), ('distract', 2812), ('nauseous', 2813), ('badminton', 2814), ('reacted', 2815), ('bacon', 2816), ('frank', 2817), ('justify', 2818), ('century', 2819), ('disneyland', 2820), ('split', 2821), ('selected', 2822), ('trick', 2823), ('tricked', 2824), ('napoleon', 2825), ('stating', 2826), ('accusing', 2827), ('battery', 2828), ('ridden', 2829), ('mozart', 2830), ('irresponsible', 2831), ('critical', 2832), ('forehead', 2833), ('pointed', 2834), ('sleeps', 2835), ('worker', 2836), ('planned', 2837), ('celebrating', 2838), ('fought', 2839), ('reminds', 2840), ('exhausting', 2841), ('spread', 2842), ('insult', 2843), ('truly', 2844), ('quality', 2845), ('greatest', 2846), ('dumped', 2847), ('appear', 2848), ('discouraged', 2849), ('pencils', 2850), ('brazil', 2851), ('fluently', 2852), ('presence', 2853), ('leftovers', 2854), ('safely', 2855), ('shirts', 2856), ('guide', 2857), ('diplomatic', 2858), ('opinions', 2859), ('disappointment', 2860), ('flabby', 2861), ('surprises', 2862), ('pet', 2863), ('differently', 2864), ('conditioning', 2865), ('cashier', 2866), ('pot', 2867), ('suits', 2868), ('currently', 2869), ('lips', 2870), ('snowman', 2871), ('laws', 2872), ('raw', 2873), ('jeans', 2874), ('evicted', 2875), ('nation', 2876), ('coin', 2877), ('robot', 2878), ('necklace', 2879), ('stands', 2880), ('style', 2881), ('stroke', 2882), ('precious', 2883), ('shout', 2884), ('choices', 2885), ('obstinate', 2886), ('debt', 2887), ('closet', 2888), ('reputation', 2889), ('insisted', 2890), ('autumn', 2891), ('blackmailed', 2892), ('breathing', 2893), ('mud', 2894), ('slight', 2895), ('argument', 2896), ('errors', 2897), ('wrestling', 2898), ('vague', 2899), ('value', 2900), ('youngest', 2901), ('rush', 2902), ('economy', 2903), ('drawing', 2904), ('defeated', 2905), ('treats', 2906), ('educated', 2907), ('client', 2908), ('okay', 2909), ('cheating', 2910), ('shade', 2911), ('sand', 2912), ('sheep', 2913), ('speed', 2914), ('politician', 2915), ('investigation', 2916), ('tofu', 2917), ('practical', 2918), ('ruin', 2919), ('contribute', 2920), ('hamburger', 2921), ('carpet', 2922), ('turning', 2923), ('accidents', 2924), ('maid', 2925), ('discount', 2926), ('riding', 2927), ('packed', 2928), ('climate', 2929), ('charges', 2930), ('osaka', 2931), ('bottles', 2932), ('permitting', 2933), ('switch', 2934), ('forgetful', 2935), ('em', 2936), ('identify', 2937), ('guns', 2938), ('pull', 2939), ('converted', 2940), ('official', 2941), ('smokes', 2942), ('poetry', 2943), ('tuesday', 2944), ('cows', 2945), ('major', 2946), ('sentenced', 2947), ('independent', 2948), ('loan', 2949), ('hunt', 2950), ('mr', 2951), ('bothered', 2952), ('chimney', 2953), ('painful', 2954), ('reality', 2955), ('broccoli', 2956), ('sank', 2957), ('obnoxious', 2958), ('tongue', 2959), ('impressive', 2960), ('warehouse', 2961), ('engineer', 2962), ('spontaneous', 2963), ('quote', 2964), ('resourceful', 2965), ('leather', 2966), ('soap', 2967), ('provide', 2968), ('response', 2969), ('suitcases', 2970), ('access', 2971), ('puzzle', 2972), ('confuse', 2973), ('proved', 2974), ('911', 2975), ('cough', 2976), ('merry', 2977), ('aid', 2978), ('coughing', 2979), ('destroy', 2980), ('honor', 2981), ('points', 2982), ('charged', 2983), ('smoker', 2984), ('admirer', 2985), ('strike', 2986), ('heartbroken', 2987), ('obedient', 2988), ('hotels', 2989), ('snake', 2990), ('buys', 2991), ('camp', 2992), ('balance', 2993), ('construction', 2994), ('hers', 2995), ('considerate', 2996), ('led', 2997), ('whistle', 2998), ('nuts', 2999), ('burning', 3000), ('ambidextrous', 3001), ('strawberries', 3002), ('grammar', 3003), ('unsure', 3004), ('horror', 3005), ('shoulders', 3006), ('pairs', 3007), ('vegetarians', 3008), ('depend', 3009), ('crash', 3010), ('valuable', 3011), ('poverty', 3012), ('prefers', 3013), ('lack', 3014), ('confusing', 3015), ('officer', 3016), ('fate', 3017), ('walls', 3018), ('tattoos', 3019), ('agitated', 3020), ('attitude', 3021), ('click', 3022), ('surgery', 3023), ('paranoid', 3024), ('compare', 3025), ('hunger', 3026), ('persuasive', 3027), ('bowed', 3028), ('court', 3029), ('photographer', 3030), ('arranged', 3031), ('experiment', 3032), ('figured', 3033), ('peaceful', 3034), ('stops', 3035), ('pony', 3036), ('dizzy', 3037), ('weapons', 3038), ('astonished', 3039), ('swims', 3040), ('scares', 3041), ('plate', 3042), ('sociable', 3043), ('amount', 3044), ('goals', 3045), ('blew', 3046), ('trade', 3047), ('equal', 3048), ('nails', 3049), ('admired', 3050), ('spying', 3051), ('millionaire', 3052), ('guitarist', 3053), ('stunned', 3054), ('content', 3055), ('faithful', 3056), ('drew', 3057), ('assure', 3058), ('tolerate', 3059), ('ranch', 3060), ('resist', 3061), ('attempt', 3062), ('crush', 3063), ('pm', 3064), ('charismatic', 3065), ('causes', 3066), ('revenge', 3067), ('discussion', 3068), ('yard', 3069), ('nerves', 3070), ('remarkable', 3071), ('outraged', 3072), ('obliged', 3073), ('elusive', 3074), ('detective', 3075), ('bone', 3076), ('lung', 3077), ('consult', 3078), ('potato', 3079), ('defeat', 3080), ('hobbies', 3081), ('mysterious', 3082), ('finicky', 3083), ('envy', 3084), ('pulse', 3085), ('tempted', 3086), ('grouchy', 3087), ('international', 3088), ('flute', 3089), ('devastated', 3090), ('grows', 3091), ('russian', 3092), ('resources', 3093), ('semester', 3094), ('seventeen', 3095), ('frankly', 3096), ('ii', 3097), ('percent', 3098), ('inviting', 3099), ('remove', 3100), ('diligent', 3101), ('knock', 3102), ('pounds', 3103), ('bat', 3104), ('alice', 3105), ('speechless', 3106), ('cranky', 3107), ('volunteers', 3108), ('captured', 3109), ('chickens', 3110), ('release', 3111), ('bartender', 3112), ('flat', 3113), ('splendid', 3114), ('religion', 3115), ('travels', 3116), ('puzzled', 3117), ('honored', 3118), ('process', 3119), ('adapted', 3120), ('extra', 3121), ('winner', 3122), ('files', 3123), ('code', 3124), ('committee', 3125), ('yell', 3126), ('complains', 3127), ('mansion', 3128), ('arabic', 3129), ('biology', 3130), ('hollywood', 3131), ('fixing', 3132), ('struck', 3133), ('fluent', 3134), ('opera', 3135), ('shooting', 3136), ('disrespectful', 3137), ('collection', 3138), ('omelet', 3139), ('eager', 3140), ('turns', 3141), ('awfully', 3142), ('prudent', 3143), ('poisoned', 3144), ('coins', 3145), ('ways', 3146), ('praying', 3147), ('proceed', 3148), ('reluctant', 3149), ('washes', 3150), ('loses', 3151), ('detectives', 3152), ('vain', 3153), ('pregnant', 3154), ('dug', 3155), ('falls', 3156), ('confess', 3157), ('proposition', 3158), ('overworked', 3159), ('packing', 3160), ('practicing', 3161), ('nickname', 3162), ('stamp', 3163), ('pronunciation', 3164), ('peeled', 3165), ('plant', 3166), ('uneasy', 3167), ('bears', 3168), ('training', 3169), ('haircut', 3170), ('carpenter', 3171), ('starved', 3172), ('lecture', 3173), ('grabbed', 3174), ('register', 3175), ('heading', 3176), ('former', 3177), ('steak', 3178), ('topic', 3179), ('aloud', 3180), ('spite', 3181), ('translating', 3182), ('delete', 3183), ('object', 3184), ('untalented', 3185), ('ink', 3186), ('cowards', 3187), ('tow', 3188), ('organic', 3189), ('bucks', 3190), ('shoe', 3191), ('baked', 3192), ('principal', 3193), ('embassy', 3194), ('comb', 3195), ('foster', 3196), ('unreliable', 3197), ('granted', 3198), ('mustache', 3199), ('scolded', 3200), ('stink', 3201), ('defenseless', 3202), ('penalty', 3203), ('appropriate', 3204), ('universe', 3205), ('barber', 3206), ('laid', 3207), ('productive', 3208), ('bluffing', 3209), ('conclusion', 3210), ('skating', 3211), ('financial', 3212), ('slower', 3213), ('track', 3214), ('ages', 3215), ('sentences', 3216), ('roosevelt', 3217), ('breaks', 3218), ('refuses', 3219), ('criminals', 3220), ('excuses', 3221), ('lamp', 3222), ('kimono', 3223), ('knocked', 3224), ('mistook', 3225), ('requested', 3226), ('inflexible', 3227), ('tools', 3228), ('qualified', 3229), ('terms', 3230), ('debate', 3231), ('tip', 3232), ('jittery', 3233), ('master', 3234), ('unlocked', 3235), ('witness', 3236), ('fifth', 3237), ('buffalo', 3238), ('logical', 3239), ('seconds', 3240), ('trash', 3241), ('granola', 3242), ('witty', 3243), ('sauce', 3244), ('chances', 3245), ('climbing', 3246), ('hopeless', 3247), ('incompetent', 3248), ('hanged', 3249), ('hundreds', 3250), ('wolf', 3251), ('scored', 3252), ('registered', 3253), ('wishes', 3254), ('stones', 3255), ('thoughts', 3256), ('offend', 3257), ('avoided', 3258), ('reluctantly', 3259), ('sake', 3260), ('25', 3261), ('victim', 3262), ('rabbits', 3263), ('buildings', 3264), ('deals', 3265), ('bossy', 3266), ('resembles', 3267), ('increase', 3268), ('unexpected', 3269), ('traitor', 3270), ('purse', 3271), ('trunk', 3272), ('shown', 3273), ('slippery', 3274), ('surfing', 3275), ('twitter', 3276), ('recipe', 3277), ('flood', 3278), ('lion', 3279), ('september', 3280), ('ongoing', 3281), ('haunted', 3282), ('cakes', 3283), ('competent', 3284), ('tries', 3285), ('criticized', 3286), ('shameless', 3287), ('announced', 3288), ('rewrite', 3289), ('anytime', 3290), ('solving', 3291), ('flag', 3292), ('closest', 3293), ('ease', 3294), ('pressed', 3295), ('believable', 3296), ('bucket', 3297), ('competition', 3298), ('unbelievable', 3299), ('possibilities', 3300), ('pushing', 3301), ('career', 3302), ('fog', 3303), ('smoked', 3304), ('shaking', 3305), ('source', 3306), ('dreamer', 3307), ('snowed', 3308), ('knowledge', 3309), ('apt', 3310), ('photograph', 3311), ('below', 3312), ('aim', 3313), ('tequila', 3314), ('tail', 3315), ('wished', 3316), ('completed', 3317), ('bakery', 3318), ('murderer', 3319), ('blow', 3320), ('detailed', 3321), ('skills', 3322), ('basic', 3323), ('bulb', 3324), ('brand', 3325), ('narrow', 3326), ('golfer', 3327), ('meters', 3328), ('tires', 3329), ('discussing', 3330), ('shame', 3331), ('programmer', 3332), ('downtown', 3333), ('delay', 3334), ('unfriendly', 3335), ('pig', 3336), ('tragic', 3337), ('nodded', 3338), ('kick', 3339), ('erased', 3340), ('tigers', 3341), ('shanghai', 3342), ('likable', 3343), ('demanded', 3344), ('actions', 3345), ('accompany', 3346), ('drugged', 3347), ('bees', 3348), ('steady', 3349), ('pedestrians', 3350), ('reduce', 3351), ('section', 3352), ('british', 3353), ('claustrophobic', 3354), ('experts', 3355), ('height', 3356), ('target', 3357), ('shoelaces', 3358), ('propose', 3359), ('mechanic', 3360), ('load', 3361), ('bicycles', 3362), ('humiliated', 3363), ('wink', 3364), ('permitted', 3365), ('react', 3366), ('interrupting', 3367), ('hokkaido', 3368), ('mosquitoes', 3369), ('honesty', 3370), ('horrified', 3371), ('snob', 3372), ('nasty', 3373), ('miracle', 3374), ('documentary', 3375), ('uncomfortable', 3376), ('homeless', 3377), ('frantic', 3378), ('searching', 3379), ('pies', 3380), ('discovery', 3381), ('tiger', 3382), ('blindfolded', 3383), ('guest', 3384), ('massage', 3385), ('roads', 3386), ('brings', 3387), ('server', 3388), ('surrendered', 3389), ('jam', 3390), ('warming', 3391), ('cattle', 3392), ('cheered', 3393), ('medication', 3394), ('limit', 3395), ('procedure', 3396), ('squirrel', 3397), ('duck', 3398), ('shaved', 3399), ('emotions', 3400), ('customers', 3401), ('insecure', 3402), ('knives', 3403), ('darker', 3404), ('feedback', 3405), ('rely', 3406), ('brushed', 3407), ('whispered', 3408), ('exaggerate', 3409), ('organize', 3410), ('tripped', 3411), ('helicopter', 3412), ('mix', 3413), ('surrender', 3414), ('washington', 3415), ('departure', 3416), ('fiction', 3417), ('bars', 3418), ('judging', 3419), ('overreacting', 3420), ('alert', 3421), ('disk', 3422), ('parrot', 3423), ('whining', 3424), ('operation', 3425), ('troublemaker', 3426), ('attempted', 3427), ('irrelevant', 3428), ('yogurt', 3429), ('balls', 3430), ('interview', 3431), ('insane', 3432), ('delivered', 3433), ('tuxedo', 3434), ('shocking', 3435), ('stared', 3436), ('trial', 3437), ('examined', 3438), ('occurred', 3439), ('daydreaming', 3440), ('wide', 3441), ('talkative', 3442), ('fussy', 3443), ('stressed', 3444), ('cloudy', 3445), ('importance', 3446), ('dinosaurs', 3447), ('closely', 3448), ('june', 3449), ('tortured', 3450), ('hats', 3451), ('exceptions', 3452), ('tent', 3453), ('frustrating', 3454), ('13', 3455), ('despise', 3456), ('lacks', 3457), ('plastic', 3458), ('grapes', 3459), ('sung', 3460), ('focus', 3461), ('dictionaries', 3462), ('predict', 3463), ('helmet', 3464), ('declared', 3465), ('candidate', 3466), ('sunscreen', 3467), ('web', 3468), ('hostages', 3469), ('degree', 3470), ('towns', 3471), ('harmless', 3472), ('slob', 3473), ('demands', 3474), ('examine', 3475), ('intimidate', 3476), ('per', 3477), ('pure', 3478), ('suggesting', 3479), ('sweden', 3480), ('delicate', 3481), ('drummer', 3482), ('starving', 3483), ('tooth', 3484), ('deer', 3485), ('hectic', 3486), ('pride', 3487), ('leak', 3488), ('teased', 3489), ('hypocrite', 3490), ('identity', 3491), ('obese', 3492), ('investigating', 3493), ('unemployed', 3494), ('reaction', 3495), ('hiring', 3496), ('tunnel', 3497), ('virus', 3498), ('excused', 3499), ('touching', 3500), ('dried', 3501), ('imaginative', 3502), ('august', 3503), ('greatly', 3504), ('rotten', 3505), ('shakespeare', 3506), ('pajamas', 3507), ('candle', 3508), ('towels', 3509), ('shortcut', 3510), ('quietly', 3511), ('flabbergasted', 3512), ('somehow', 3513), ('russia', 3514), ('terrorists', 3515), ('scientists', 3516), ('rational', 3517), ('jerk', 3518), ('orphanage', 3519), ('angel', 3520), ('motion', 3521), ('pompous', 3522), ('usa', 3523), ('sharing', 3524), ('mask', 3525), ('hamburgers', 3526), ('recovery', 3527), ('thai', 3528), ('outrageous', 3529), ('texas', 3530), ('spotted', 3531), ('blonde', 3532), ('follows', 3533), ('vivid', 3534), ('performance', 3535), ('knees', 3536), ('childish', 3537), ('claims', 3538), ('comic', 3539), ('festival', 3540), ('agent', 3541), ('ambassador', 3542), ('warmer', 3543), ('workaholic', 3544), ('museums', 3545), ('technology', 3546), ('adapt', 3547), ('ballistic', 3548), ('infected', 3549), ('onions', 3550), ('heavier', 3551), ('negative', 3552), ('cultured', 3553), ('blank', 3554), ('annoy', 3555), ('monkey', 3556), ('guarantee', 3557), ('freezer', 3558), ('families', 3559), ('resignation', 3560), ('inconsiderate', 3561), ('clarinet', 3562), ('knowing', 3563), ('lipstick', 3564), ('instantly', 3565), ('talents', 3566), ('constantly', 3567), ('interests', 3568), ('smiles', 3569), ('bones', 3570), ('demanding', 3571), ('brief', 3572), ('dresses', 3573), ('grandchildren', 3574), ('exact', 3575), ('sewing', 3576), ('courteous', 3577), ('hesitate', 3578), ('lightning', 3579), ('drought', 3580), ('colder', 3581), ('affair', 3582), ('peanut', 3583), ('environment', 3584), ('laughter', 3585), ('kidnapped', 3586), ('parks', 3587), ('inspiration', 3588), ('ambition', 3589), ('sir', 3590), ('postpone', 3591), ('scandal', 3592), ('minor', 3593), ('allegations', 3594), ('chainsaw', 3595), ('hopeful', 3596), ('hoped', 3597), ('heavily', 3598), ('louder', 3599), ('differences', 3600), ('politely', 3601), ('inform', 3602), ('formed', 3603), ('sue', 3604), ('decent', 3605), ('miller', 3606), ('identical', 3607), ('tight', 3608), ('untrustworthy', 3609), ('ham', 3610), ('elephants', 3611), ('mars', 3612), ('shortly', 3613), ('facing', 3614), ('elephant', 3615), ('novelist', 3616), ('areas', 3617), ('rash', 3618), ('privately', 3619), ('eccentric', 3620), ('dramatic', 3621), ('speeches', 3622), ('itself', 3623), ('emotional', 3624), ('afterwards', 3625), ('glum', 3626), ('thick', 3627), ('approval', 3628), ('temporary', 3629), ('faces', 3630), ('application', 3631), ('loaded', 3632), ('mice', 3633), ('acts', 3634), ('sailed', 3635), ('wrist', 3636), ('sudden', 3637), ('typical', 3638), ('pockets', 3639), ('literature', 3640), ('repeated', 3641), ('choked', 3642), ('disappointing', 3643), ('chairman', 3644), ('delusional', 3645), ('tomatoes', 3646), ('fighter', 3647), ('humble', 3648), ('exchange', 3649), ('income', 3650), ('bare', 3651), ('harsh', 3652), ('koala', 3653), ('lawyers', 3654), ('magnificent', 3655), ('minister', 3656), ('curiosity', 3657), ('guinness', 3658), ('pistol', 3659), ('global', 3660), ('volume', 3661), ('laughs', 3662), ('300000', 3663), ('society', 3664), ('trained', 3665), ('rapidly', 3666), ('interrupted', 3667), ('unbiased', 3668), ('organ', 3669), ('bullet', 3670), ('humid', 3671), ('observant', 3672), ('prettier', 3673), ('citizens', 3674), ('instruments', 3675), ('oppose', 3676), ('inexperienced', 3677), ('plastered', 3678), ('meets', 3679), ('inexpensive', 3680), ('marathon', 3681), ('affairs', 3682), ('hesitant', 3683), ('outdoors', 3684), ('pour', 3685), ('avatar', 3686), ('tests', 3687), ('stressful', 3688), ('unreasonable', 3689), ('foreigners', 3690), ('rested', 3691), ('interfering', 3692), ('dancer', 3693), ('ivy', 3694), ('site', 3695), ('crown', 3696), ('version', 3697), ('based', 3698), ('disoriented', 3699), ('remote', 3700), ('repeating', 3701), ('merciless', 3702), ('tolerant', 3703), ('supporting', 3704), ('slapped', 3705), ('tricks', 3706), ('sip', 3707), ('cigarettes', 3708), ('board', 3709), ('claimed', 3710), ('symptoms', 3711), ('chest', 3712), ('wreck', 3713), ('putting', 3714), ('servants', 3715), ('transportation', 3716), ('blessing', 3717), ('sliced', 3718), ('delighted', 3719), ('slave', 3720), ('addressed', 3721), ('visa', 3722), ('sumo', 3723), ('deliver', 3724), ('moral', 3725), ('parts', 3726), ('neat', 3727), ('convenient', 3728), ('foods', 3729), ('valid', 3730), ('jury', 3731), ('priorities', 3732), ('memories', 3733), ('astronomy', 3734), ('arriving', 3735), ('slice', 3736), ('pharmacist', 3737), ('diplomat', 3738), ('nicer', 3739), ('stress', 3740), ('comfort', 3741), ('pirate', 3742), ('applauded', 3743), ('state', 3744), ('protected', 3745), ('electric', 3746), ('shovel', 3747), ('athlete', 3748), ('gain', 3749), ('classified', 3750), ('pardon', 3751), ('understandable', 3752), ('singapore', 3753), ('stirred', 3754), ('policy', 3755), ('sane', 3756), ('manipulative', 3757), ('jumping', 3758), ('obscene', 3759), ('cautious', 3760), ('dances', 3761), ('calendar', 3762), ('scratched', 3763), ('personality', 3764), ('social', 3765), ('champion', 3766), ('capitals', 3767), ('deserted', 3768), ('ripe', 3769), ('cantankerous', 3770), ('salty', 3771), ('influenced', 3772), ('hysterically', 3773), ('uniforms', 3774), ('mexican', 3775), ('yokohama', 3776), ('tease', 3777), ('theft', 3778), ('snore', 3779), ('justice', 3780), ('thoughtful', 3781), ('loving', 3782), ('toes', 3783), ('pulling', 3784), ('executed', 3785), ('quarrel', 3786), ('precise', 3787), ('subjects', 3788), ('majority', 3789), ('sword', 3790), ('doorbell', 3791), ('fry', 3792), ('18', 3793), ('asthma', 3794), ('temple', 3795), ('graduation', 3796), ('overlooked', 3797), ('satisfactory', 3798), ('punish', 3799), ('arrival', 3800), ('uninsured', 3801), ('grave', 3802), ('christianity', 3803), ('ammunition', 3804), ('absolute', 3805), ('surely', 3806), ('suffers', 3807), ('existence', 3808), ('olives', 3809), ('batteries', 3810), ('vulnerable', 3811), ('sailing', 3812), ('b', 3813), ('returning', 3814), ('outgoing', 3815), ('concerts', 3816), ('apologies', 3817), ('sober', 3818), ('optimist', 3819), ('cloud', 3820), ('phones', 3821), ('instincts', 3822), ('pages', 3823), ('lover', 3824), ('microphone', 3825), ('conditions', 3826), ('reporter', 3827), ('seafood', 3828), ('cracked', 3829), ('hood', 3830), ('guilt', 3831), ('browser', 3832), ('intelligence', 3833), ('zealand', 3834), ('opposed', 3835), ('loosen', 3836), ('teenager', 3837), ('clicked', 3838), ('respectful', 3839), ('previous', 3840), ('rabbit', 3841), ('torture', 3842), ('honestly', 3843), ('communicate', 3844), ('director', 3845), ('row', 3846), ('wednesday', 3847), ('dust', 3848), ('addicted', 3849), ('upon', 3850), ('suspects', 3851), ('celebrated', 3852), ('journalism', 3853), ('bug', 3854), ('throwing', 3855), ('wondering', 3856), ('threat', 3857), ('shuttlecock', 3858), ('questioned', 3859), ('impartial', 3860), ('pepperoni', 3861), ('manners', 3862), ('200', 3863), ('needy', 3864), ('wings', 3865), ('tonguetied', 3866), ('dish', 3867), ('hong', 3868), ('kong', 3869), ('unethical', 3870), ('guard', 3871), ('lincoln', 3872), ('loyal', 3873), ('cheerful', 3874), ('architect', 3875), ('enthusiasm', 3876), ('regretted', 3877), ('drowning', 3878), ('shows', 3879), ('tornado', 3880), ('ideal', 3881), ('assembled', 3882), ('bankrupt', 3883), ('july', 3884), ('recent', 3885), ('finds', 3886), ('debts', 3887), ('wellknown', 3888), ('plates', 3889), ('faint', 3890), ('exboyfriend', 3891), ('shift', 3892), ('tap', 3893), ('orphan', 3894), ('hung', 3895), ('roger', 3896), ('eyesight', 3897), ('headphones', 3898), ('lacrosse', 3899), ('eclipse', 3900), ('predictable', 3901), ('cooks', 3902), ('smartphone', 3903), ('panic', 3904), ('rise', 3905), ('sec', 3906), ('intentionally', 3907), ('grandma', 3908), ('4', 3909), ('linux', 3910), ('lions', 3911), ('someplace', 3912), ('sipped', 3913), ('rings', 3914), ('path', 3915), ('moves', 3916), ('miracles', 3917), ('accuracy', 3918), ('mustard', 3919), ('quitting', 3920), ('showered', 3921), ('saturdays', 3922), ('farmers', 3923), ('devoted', 3924), ('berlin', 3925), ('relaxing', 3926), ('nagoya', 3927), ('waist', 3928), ('collected', 3929), ('coughed', 3930), ('swallow', 3931), ('blouse', 3932), ('textbook', 3933), ('approach', 3934), ('outspoken', 3935), ('formal', 3936), ('crisis', 3937), ('magician', 3938), ('2003', 3939), ('landing', 3940), ('bills', 3941), ('vanished', 3942), ('google', 3943), ('notified', 3944), ('awoke', 3945), ('doubtful', 3946), ('european', 3947), ('barefoot', 3948), ('smelled', 3949), ('ceiling', 3950), ('ufo', 3951), ('wealth', 3952), ('unsociable', 3953), ('pills', 3954), ('threatening', 3955), ('alien', 3956), ('rough', 3957), ('shares', 3958), ('imitating', 3959), ('lab', 3960), ('630', 3961), ('properly', 3962), ('tiny', 3963), ('random', 3964), ('unprejudiced', 3965), ('leading', 3966), ('effective', 3967), ('unscrupulous', 3968), ('tape', 3969), ('signal', 3970), ('rural', 3971), ('region', 3972), ('punk', 3973), ('puts', 3974), ('cane', 3975), ('tin', 3976), ('irresistible', 3977), ('cries', 3978), ('shibuya', 3979), ('sending', 3980), ('expression', 3981), ('reservations', 3982), ('dj', 3983), ('strongminded', 3984), ('folk', 3985), ('app', 3986), ('celsius', 3987), ('settle', 3988), ('detained', 3989), ('races', 3990), ('january', 3991), ('storage', 3992), ('jesus', 3993), ('tends', 3994), ('blocks', 3995), ('pancakes', 3996), ('rookie', 3997), ('community', 3998), ('sunny', 3999), ('kindly', 4000), ('guts', 4001), ('witnessed', 4002), ('van', 4003), ('intentions', 4004), ('vienna', 4005), ('import', 4006), ('voting', 4007), ('shops', 4008), ('unacceptable', 4009), ('ants', 4010), ('bury', 4011), ('compliments', 4012), ('nonsense', 4013), ('install', 4014), ('brainwashed', 4015), ('slammed', 4016), ('abused', 4017), ('oxygen', 4018), ('rewrote', 4019), ('referred', 4020), ('reserve', 4021), ('imitate', 4022), ('gonna', 4023), ('busier', 4024), ('amazed', 4025), ('envious', 4026), ('leads', 4027), ('kindergarten', 4028), ('campus', 4029), ('behaving', 4030), ('forklift', 4031), ('memorized', 4032), ('bookkeeping', 4033), ('freshman', 4034), ('shivering', 4035), ('tune', 4036), ('accidentally', 4037), ('contains', 4038), ('distinguish', 4039), ('inherited', 4040), ('proactive', 4041), ('reported', 4042), ('economics', 4043), ('inappropriate', 4044), ('property', 4045), ('pier', 4046), ('relied', 4047), ('exonerated', 4048), ('dated', 4049), ('buses', 4050), ('briefcase', 4051), ('possessive', 4052), ('telescope', 4053), ('nap', 4054), ('protest', 4055), ('flu', 4056), ('overslept', 4057), ('ai', 4058), ('irreplaceable', 4059), ('denies', 4060), ('california', 4061), ('delayed', 4062), ('enormous', 4063), ('connect', 4064), ('winked', 4065), ('circumstances', 4066), ('temptation', 4067), ('uncertain', 4068), ('postcard', 4069), ('fastest', 4070), ('margarine', 4071), ('filed', 4072), ('stalling', 4073), ('aimed', 4074), ('product', 4075), ('immoral', 4076), ('culture', 4077), ('dike', 4078), ('statement', 4079), ('theirs', 4080), ('develop', 4081), ('plot', 4082), ('objected', 4083), ('appearance', 4084), ('referring', 4085), ('opportunities', 4086), ('cds', 4087), ('cheek', 4088), ('predicted', 4089), ('licked', 4090), ('undecided', 4091), ('pipe', 4092), ('veteran', 4093), ('intends', 4094), ('stable', 4095), ('730', 4096), ('normally', 4097), ('swedish', 4098), ('pledged', 4099), ('titanic', 4100), ('digging', 4101), ('cubicle', 4102), ('dies', 4103), ('intimidated', 4104), ('root', 4105), ('thermometer', 4106), ('milton', 4107), ('clothing', 4108), ('millions', 4109), ('heartburn', 4110), ('veterinarian', 4111), ('distraught', 4112), ('giggled', 4113), ('behalf', 4114), ('prime', 4115), ('representative', 4116), ('riddle', 4117), ('sexy', 4118), ('limping', 4119), ('signature', 4120), ('baloney', 4121), ('passionate', 4122), ('hairstyle', 4123), ('increasing', 4124), ('matches', 4125), ('greece', 4126), ('arrives', 4127), ('worthy', 4128), ('disliked', 4129), ('screenshot', 4130), ('concentrating', 4131), ('freeze', 4132), ('joy', 4133), ('fewer', 4134), ('safer', 4135), ('doable', 4136), ('lyrics', 4137), ('desired', 4138), ('adore', 4139), ('tax', 4140), ('escaping', 4141), ('blush', 4142), ('fatter', 4143), ('produces', 4144), ('cheerleader', 4145), ('dislikes', 4146), ('trousers', 4147), ('wound', 4148), ('tahiti', 4149), ('customer', 4150), ('typing', 4151), ('rolled', 4152), ('tool', 4153), ('tend', 4154), ('frogs', 4155), ('cared', 4156), ('deadline', 4157), ('keyboards', 4158), ('seminar', 4159), ('grandpa', 4160), ('britain', 4161), ('create', 4162), ('intense', 4163), ('unpleasant', 4164), ('skill', 4165), ('ironic', 4166), ('yoga', 4167), ('wheat', 4168), ('cautiously', 4169), ('tossed', 4170), ('ordinary', 4171), ('smashed', 4172), ('absorbed', 4173), ('distant', 4174), ('robbery', 4175), ('sissy', 4176), ('products', 4177), ('score', 4178), ('software', 4179), ('ginger', 4180), ('engagement', 4181), ('framed', 4182), ('muddy', 4183), ('opens', 4184), ('destination', 4185), ('rug', 4186), ('merciful', 4187), ('flashlight', 4188), ('800', 4189), ('humiliate', 4190), ('toothache', 4191), ('shrieked', 4192), ('leaned', 4193), ('watered', 4194), ('apologizing', 4195), ('wolves', 4196), ('terrific', 4197), ('handcuffed', 4198), ('chuckled', 4199), ('elaborate', 4200), ('gentle', 4201), ('immigrants', 4202), ('backyard', 4203), ('souvenir', 4204), ('welcomed', 4205), ('technique', 4206), ('troubles', 4207), ('ships', 4208), ('windy', 4209), ('begged', 4210), ('role', 4211), ('baggage', 4212), ('sacrificed', 4213), ('fanatic', 4214), ('lean', 4215), ('violinist', 4216), ('treasure', 4217), ('unimaginative', 4218), ('respects', 4219), ('flies', 4220), ('dollar', 4221), ('sour', 4222), ('delegates', 4223), ('voucher', 4224), ('adorable', 4225), ('borrows', 4226), ('custody', 4227), ('hospitality', 4228), ('operate', 4229), ('backing', 4230), ('bleach', 4231), ('brightened', 4232), ('mutual', 4233), ('soul', 4234), ('rebel', 4235), ('fulltime', 4236), ('victory', 4237), ('practically', 4238), ('astronaut', 4239), ('unbearable', 4240), ('bathtub', 4241), ('anonymous', 4242), ('reward', 4243), ('wire', 4244), ('onto', 4245), ('gathered', 4246), ('overtime', 4247), ('ripped', 4248), ('sunset', 4249), ('expense', 4250), ('translator', 4251), ('articles', 4252), ('watermelon', 4253), ('towards', 4254), ('richest', 4255), ('dyslexic', 4256), ('cure', 4257), ('dozens', 4258), ('traditional', 4259), ('fainted', 4260), ('dilemma', 4261), ('incorrigible', 4262), ('earthquakes', 4263), ('3000', 4264), ('nagasaki', 4265), ('disaster', 4266), ('voyage', 4267), ('indian', 4268), ('san', 4269), ('elbow', 4270), ('likeable', 4271), ('insist', 4272), ('disco', 4273), ('grumbling', 4274), ('deepest', 4275), ('snack', 4276), ('24', 4277), ('behaved', 4278), ('allegation', 4279), ('joining', 4280), ('crew', 4281), ('signs', 4282), ('chopin', 4283), ('puppy', 4284), ('sharpened', 4285), ('cherry', 4286), ('burns', 4287), ('title', 4288), ('umbrellas', 4289), ('colorblind', 4290), ('organization', 4291), ('1939', 4292), ('webpage', 4293), ('opponent', 4294), ('aside', 4295), ('influential', 4296), ('gloomy', 4297), ('weaknesses', 4298), ('grade', 4299), ('survivors', 4300), ('possibly', 4301), ('boarding', 4302), ('font', 4303), ('punishment', 4304), ('humans', 4305), ('shine', 4306), ('chemistry', 4307), ('zombie', 4308), ('policemen', 4309), ('7', 4310), ('weekends', 4311), ('genuinely', 4312), ('teammates', 4313), ('distressed', 4314), ('applied', 4315), ('nerve', 4316), ('indoors', 4317), ('shawl', 4318), ('freelance', 4319), ('exercising', 4320), ('skier', 4321), ('composition', 4322), ('braille', 4323), ('manual', 4324), ('marketing', 4325), ('rescheduled', 4326), ('nightmares', 4327), ('command', 4328), ('ninja', 4329), ('teenagers', 4330), ('entering', 4331), ('punched', 4332), ('trips', 4333), ('budget', 4334), ('nail', 4335), ('casino', 4336), ('severe', 4337), ('sonata', 4338), ('wifi', 4339), ('nervously', 4340), ('majored', 4341), ('chew', 4342), ('turkish', 4343), ('addition', 4344), ('relief', 4345), ('chased', 4346), ('appointed', 4347), ('needing', 4348), ('opportunistic', 4349), ('prudence', 4350), ('nationality', 4351), ('8', 4352), ('blowing', 4353), ('consideration', 4354), ('dining', 4355), ('plagiarism', 4356), ('twentieth', 4357), ('2', 4358), ('super', 4359), ('landlord', 4360), ('expelled', 4361), ('bandage', 4362), ('sponge', 4363), ('brushing', 4364), ('ticklish', 4365), ('besides', 4366), ('especially', 4367), ('occupied', 4368), ('notebook', 4369), ('conceited', 4370), ('nosey', 4371), ('1960', 4372), ('mosquito', 4373), ('founded', 4374), ('diabetic', 4375), ('argued', 4376), ('tuned', 4377), ('anniversary', 4378), ('collapsed', 4379), ('sailor', 4380), ('assigned', 4381), ('ammo', 4382), ('longhaired', 4383), ('numerous', 4384), ('clown', 4385), ('observe', 4386), ('sympathy', 4387), ('unknown', 4388), ('switzerland', 4389), ('guards', 4390), ('bracelet', 4391), ('spider', 4392), ('exists', 4393), ('tissue', 4394), ('moron', 4395), ('figures', 4396), ('tendency', 4397), ('silk', 4398), ('reminded', 4399), ('advantages', 4400), ('divided', 4401), ('protecting', 4402), ('union', 4403), ('comics', 4404), ('independence', 4405), ('deprived', 4406), ('material', 4407), ('greek', 4408), ('picasso', 4409), ('tattletale', 4410), ('eighteen', 4411), ('edison', 4412), ('sued', 4413), ('statistics', 4414), ('bunch', 4415), ('makeup', 4416), ('coast', 4417), ('rudeness', 4418), ('grounded', 4419), ('persevering', 4420), ('automobiles', 4421), ('kilos', 4422), ('boxer', 4423), ('hurried', 4424), ('philosophy', 4425), ('roll', 4426), ('dolls', 4427), ('thrilled', 4428), ('disappear', 4429), ('dusty', 4430), ('inspired', 4431), ('resting', 4432), ('cotton', 4433), ('bringing', 4434), ('crushed', 4435), ('tag', 4436), ('recess', 4437), ('contributed', 4438), ('update', 4439), ('famished', 4440), ('mattress', 4441), ('parent', 4442), ('clapped', 4443), ('cereal', 4444), ('freak', 4445), ('earrings', 4446), ('forms', 4447), ('wrapped', 4448), ('narrowminded', 4449), ('events', 4450), ('acknowledged', 4451), ('testing', 4452), ('vitamins', 4453), ('numb', 4454), ('audiobooks', 4455), ('throbbing', 4456), ('napkin', 4457), ('cameras', 4458), ('plain', 4459), ('panicked', 4460), ('thousands', 4461), ('happiest', 4462), ('unimpressed', 4463), ('delivery', 4464), ('meter', 4465), ('announcement', 4466), ('responded', 4467), ('becomes', 4468), ('measured', 4469), ('adaptable', 4470), ('beijing', 4471), ('esperanto', 4472), ('ankle', 4473), ('mark', 4474), ('jacksons', 4475), ('bilingual', 4476), ('complaint', 4477), ('accomplished', 4478), ('provoke', 4479), ('base', 4480), ('noises', 4481), ('poster', 4482), ('obeyed', 4483), ('feverish', 4484), ('weed', 4485), ('wheel', 4486), ('dazzled', 4487), ('coal', 4488), ('infection', 4489), ('olympics', 4490), ('burnt', 4491), ('wisdom', 4492), ('emotion', 4493), ('firing', 4494), ('streets', 4495), ('tailor', 4496), ('swearing', 4497), ('beatles', 4498), ('egotistical', 4499), ('crowbar', 4500), ('retiring', 4501), ('richer', 4502), ('confiscated', 4503), ('disney', 4504), ('intersection', 4505), ('doubted', 4506), ('archaeology', 4507), ('polish', 4508), ('francisco', 4509), ('flown', 4510), ('typhoon', 4511), ('christian', 4512), ('suv', 4513), ('hitler', 4514), ('pleaded', 4515), ('rocket', 4516), ('barbaric', 4517), ('tire', 4518), ('heights', 4519), ('12000', 4520), ('exaggerated', 4521), ('accumulated', 4522), ('badge', 4523), ('panda', 4524), ('statue', 4525), ('leadership', 4526), ('electrician', 4527), ('hitting', 4528), ('confession', 4529), ('unapproachable', 4530), ('dialed', 4531), ('unenthusiastic', 4532), ('matsuyama', 4533), ('reveal', 4534), ('cricket', 4535), ('closing', 4536), ('recession', 4537), ('dr', 4538), ('separate', 4539), ('lefthanded', 4540), ('applies', 4541), ('stomachache', 4542), ('odds', 4543), ('thursday', 4544), ('loyalty', 4545), ('lifter', 4546), ('dear', 4547), ('straw', 4548), ('exceptionally', 4549), ('gray', 4550), ('loose', 4551), ('butterfly', 4552), ('bigot', 4553), ('offensive', 4554), ('aquarium', 4555), ('specialist', 4556), ('darwin', 4557), ('forgets', 4558), ('perplexed', 4559), ('mug', 4560), ('acquaintance', 4561), ('rewarded', 4562), ('cheeseburger', 4563), ('hydrogen', 4564), ('consequences', 4565), ('rate', 4566), ('expressed', 4567), ('passion', 4568), ('buttons', 4569), ('cathedral', 4570), ('notify', 4571), ('tour', 4572), ('ache', 4573), ('convenience', 4574), ('awaiting', 4575), ('examples', 4576), ('waved', 4577), ('sink', 4578), ('bothers', 4579), ('atmosphere', 4580), ('proofread', 4581), ('conform', 4582), ('contest', 4583), ('visitor', 4584), ('giants', 4585), ('stylish', 4586), ('teresa', 4587), ('references', 4588), ('minimum', 4589), ('phrase', 4590), ('disloyal', 4591), ('consulted', 4592), ('shouted', 4593), ('shoreline', 4594), ('effect', 4595), ('asia', 4596), ('heating', 4597), ('australian', 4598), ('dreadful', 4599), ('egypt', 4600), ('envied', 4601), ('negotiator', 4602), ('stepfather', 4603), ('flooded', 4604), ('blocking', 4605), ('concerns', 4606), ('regards', 4607), ('bless', 4608), ('drinker', 4609), ('cocktail', 4610), ('innovative', 4611), ('texting', 4612), ('interviewed', 4613), ('abacus', 4614), ('anticipated', 4615), ('winners', 4616), ('breakdown', 4617), ('flour', 4618), ('fishy', 4619), ('strongly', 4620), ('icy', 4621), ('hint', 4622), ('supplied', 4623), ('congratulated', 4624), ('fools', 4625), ('shining', 4626), ('pushups', 4627), ('rap', 4628), ('require', 4629), ('sweets', 4630), ('denying', 4631), ('ladies', 4632), ('ashtrays', 4633), ('bun', 4634), ('outstanding', 4635), ('fourth', 4636), ('float', 4637), ('vacant', 4638), ('harassing', 4639), ('tomato', 4640), ('essentially', 4641), ('pollution', 4642), ('statues', 4643), ('dejected', 4644), ('cooperate', 4645), ('adjusted', 4646), ('idiots', 4647), ('existed', 4648), ('coup', 4649), ('mat', 4650), ('frugally', 4651), ('worthless', 4652), ('attentively', 4653), ('tsunami', 4654), ('differs', 4655), ('bent', 4656), ('horn', 4657), ('cynical', 4658), ('sticks', 4659), ('witnesses', 4660), ('thickheaded', 4661), ('undamaged', 4662), ('bystander', 4663), ('buyer', 4664), ('cleaner', 4665), ('stuffed', 4666), ('moaned', 4667), ('approached', 4668), ('insensitive', 4669), ('branches', 4670), ('shotgun', 4671), ('partly', 4672), ('revealed', 4673), ('ford', 4674), ('visibly', 4675), ('handled', 4676), ('squinted', 4677), ('yelled', 4678), ('methods', 4679), ('biologist', 4680), ('railway', 4681), ('selfishness', 4682), ('pattern', 4683), ('easter', 4684), ('closes', 4685), ('journey', 4686), ('landed', 4687), ('unemotional', 4688), ('heroes', 4689), ('secretly', 4690), ('lovable', 4691), ('melted', 4692), ('cia', 4693), ('expectations', 4694), ('heated', 4695), ('handrail', 4696), ('riot', 4697), ('toothpick', 4698), ('stadium', 4699), ('plugged', 4700), ('potential', 4701), ('denmark', 4702), ('fried', 4703), ('barbecue', 4704), ('shuttle', 4705), ('tiresome', 4706), ('lowered', 4707), ('palace', 4708), ('spilled', 4709), ('unreal', 4710), ('steps', 4711), ('humming', 4712), ('motor', 4713), ('donut', 4714), ('articulate', 4715), ('shaky', 4716), ('restless', 4717), ('bribes', 4718), ('actual', 4719), ('fined', 4720), ('strategy', 4721), ('telegram', 4722), ('beaten', 4723), ('serve', 4724), ('discover', 4725), ('pal', 4726), ('rage', 4727), ('partners', 4728), ('nuclear', 4729), ('heater', 4730), ('branch', 4731), ('inconvenience', 4732), ('banned', 4733), ('harbor', 4734), ('judgment', 4735), ('rat', 4736), ('popularity', 4737), ('admission', 4738), ('pigs', 4739), ('discontented', 4740), ('inefficient', 4741), ('troops', 4742), ('stretched', 4743), ('series', 4744), ('sins', 4745), ('pointing', 4746), ('yawning', 4747), ('airplanes', 4748), ('dull', 4749), ('70', 4750), ('reggae', 4751), ('cuter', 4752), ('parrots', 4753), ('happily', 4754), ('upside', 4755), ('embraced', 4756), ('consciousness', 4757), ('drivers', 4758), ('2000', 4759), ('expired', 4760), ('sixty', 4761), ('coerced', 4762), ('log', 4763), ('graduating', 4764), ('choir', 4765), ('attributed', 4766), ('arrow', 4767), ('telephoned', 4768), ('unbelievably', 4769), ('admits', 4770), ('negotiate', 4771), ('patiently', 4772), ('hardheaded', 4773), ('boarded', 4774), ('babies', 4775), ('investing', 4776), ('starve', 4777), ('cockroaches', 4778), ('square', 4779), ('astrology', 4780), ('counter', 4781), ('hypocrisy', 4782), ('philosopher', 4783), ('lobby', 4784), ('angels', 4785), ('floss', 4786), ('repulsive', 4787), ('mosque', 4788), ('secure', 4789), ('eggnog', 4790), ('precautions', 4791), ('evident', 4792), ('lemon', 4793), ('evolution', 4794), ('jewelry', 4795), ('african', 4796), ('stickler', 4797), ('untidy', 4798), ('cage', 4799), ('controlled', 4800), ('solid', 4801), ('lemonade', 4802), ('democracy', 4803), ('demented', 4804), ('overcome', 4805), ('iceberg', 4806), ('colds', 4807), ('guessed', 4808), ('locker', 4809), ('spilt', 4810), ('affected', 4811), ('quarter', 4812), ('spoons', 4813), ('blushing', 4814), ('tags', 4815), ('frozen', 4816), ('beyond', 4817), ('lethargic', 4818), ('nightmare', 4819), ('hypothesis', 4820), ('flinched', 4821), ('steel', 4822), ('appreciation', 4823), ('glue', 4824), ('peeling', 4825), ('goofed', 4826), ('shark', 4827), ('intoxicated', 4828), ('handbag', 4829), ('assumption', 4830), ('mile', 4831), ('chairperson', 4832), ('compete', 4833), ('shortage', 4834), ('gross', 4835), ('funds', 4836), ('tested', 4837), ('credible', 4838), ('flickering', 4839), ('dumbfounded', 4840), ('communist', 4841), ('camped', 4842), ('prescription', 4843), ('gentlemen', 4844), ('kite', 4845), ('mercy', 4846), ('mule', 4847), ('sacred', 4848), ('flows', 4849), ('agatha', 4850), ('christie', 4851), ('materials', 4852), ('substitute', 4853), ('holes', 4854), ('risked', 4855), ('harajuku', 4856), ('cartwheel', 4857), ('inventive', 4858), ('savvy', 4859), ('trailer', 4860), ('insulting', 4861), ('design', 4862), ('obama', 4863), ('lip', 4864), ('trembling', 4865), ('posted', 4866), ('beside', 4867), ('sweated', 4868), ('imports', 4869), ('switched', 4870), ('xylophone', 4871), ('mailbox', 4872), ('faults', 4873), ('isolated', 4874), ('lighter', 4875), ('monkeys', 4876), ('chopsticks', 4877), ('tactful', 4878), ('attract', 4879), ('kilometers', 4880), ('folded', 4881), ('boil', 4882), ('temperamental', 4883), ('latest', 4884), ('bethlehem', 4885), ('purchase', 4886), ('lighten', 4887), ('dealing', 4888), ('spelling', 4889), ('habits', 4890), ('freezing', 4891), ('warmly', 4892), ('competed', 4893), ('masks', 4894), ('1945', 4895), ('bully', 4896), ('tasty', 4897), ('dozed', 4898), ('psychologist', 4899), ('c', 4900), ('peaches', 4901), ('luxury', 4902), ('killer', 4903), ('rumors', 4904), ('verge', 4905), ('stinks', 4906), ('assumptions', 4907), ('escort', 4908), ('attorney', 4909), ('lasts', 4910), ('printed', 4911), ('analytical', 4912), ('stores', 4913), ('sidewalk', 4914), ('greasy', 4915), ('canoe', 4916), ('custom', 4917), ('coke', 4918), ('chatting', 4919), ('lobster', 4920), ('vampire', 4921), ('condolences', 4922), ('blankets', 4923), ('ex', 4924), ('authorized', 4925), ('reports', 4926), ('invisible', 4927), ('task', 4928), ('insect', 4929), ('jingle', 4930), ('bells', 4931), ('conflict', 4932), ('relationships', 4933), ('incorrectly', 4934), ('listless', 4935), ('supplies', 4936), ('treating', 4937), ('hideous', 4938), ('korea', 4939), ('pointless', 4940), ('uturn', 4941), ('estate', 4942), ('blames', 4943), ('overheard', 4944), ('drawn', 4945), ('versatile', 4946), ('sneezing', 4947), ('eighty', 4948), ('updated', 4949), ('retarded', 4950), ('toothpaste', 4951), ('cowboy', 4952), ('assessment', 4953), ('fiber', 4954), ('beers', 4955), ('scotland', 4956), ('forbidden', 4957), ('relatively', 4958), ('rio', 4959), ('workaholics', 4960), ('limits', 4961), ('performed', 4962), ('logic', 4963), ('jet', 4964), ('jelly', 4965), ('errands', 4966), ('whale', 4967), ('grouch', 4968), ('regularly', 4969), ('zero', 4970), ('baffled', 4971), ('maniac', 4972), ('stung', 4973), ('goat', 4974), ('described', 4975), ('developed', 4976), ('daily', 4977), ('boiling', 4978), ('situations', 4979), ('sharks', 4980), ('gamble', 4981), ('sickness', 4982), ('preach', 4983), ('crack', 4984), ('sobbing', 4985), ('unfounded', 4986), ('specifics', 4987), ('nations', 4988), ('earring', 4989), ('represent', 4990), ('ireland', 4991), ('witch', 4992), ('strictly', 4993), ('stage', 4994), ('seventy', 4995), ('approaching', 4996), ('iceland', 4997), ('necessarily', 4998), ('scratch', 4999), ('cutie', 5000), ('snows', 5001), ('owners', 5002), ('fluency', 5003), ('strawberry', 5004), ('counted', 5005), ('asian', 5006), ('motivation', 5007), ('unconvinced', 5008), ('snoring', 5009), ('equipment', 5010), ('dolphins', 5011), ('hut', 5012), ('injuries', 5013), ('lumberjack', 5014), ('vietnam', 5015), ('recycle', 5016), ('16', 5017), ('psychic', 5018), ('speeding', 5019), ('shots', 5020), ('cast', 5021), ('119', 5022), ('golden', 5023), ('sales', 5024), ('insistent', 5025), ('sorrow', 5026), ('advanced', 5027), ('skate', 5028), ('clients', 5029), ('dangers', 5030), ('goodlooking', 5031), ('scar', 5032), ('injury', 5033), ('atheist', 5034), ('soninlaw', 5035), ('tan', 5036), ('skirts', 5037), ('description', 5038), ('define', 5039), ('belonged', 5040), ('offering', 5041), ('fashioned', 5042), ('loosened', 5043), ('weakness', 5044), ('barbershop', 5045), ('originally', 5046), ('pitch', 5047), ('loner', 5048), ('spooky', 5049), ('1980', 5050), ('instructor', 5051), ('subpoena', 5052), ('increased', 5053), ('valve', 5054), ('dropping', 5055), ('labor', 5056), ('dragged', 5057), ('violently', 5058), ('central', 5059), ('decorate', 5060), ('hometown', 5061), ('unwilling', 5062), ('photographs', 5063), ('accusation', 5064), ('sizes', 5065), ('lasagna', 5066), ('authors', 5067), ('spark', 5068), ('plugs', 5069), ('bloom', 5070), ('stepped', 5071), ('officially', 5072), ('terrifying', 5073), ('texts', 5074), ('verify', 5075), ('unarmed', 5076), ('combination', 5077), ('robber', 5078), ('screams', 5079), ('gangster', 5080), ('writers', 5081), ('questioning', 5082), ('fastball', 5083), ('demonstration', 5084), ('irregular', 5085), ('beginners', 5086), ('tables', 5087), ('billion', 5088), ('hunch', 5089), ('columbus', 5090), ('march', 5091), ('requires', 5092), ('bounty', 5093), ('wizard', 5094), ('production', 5095), ('obligated', 5096), ('sydney', 5097), ('seated', 5098), ('businessman', 5099), ('investment', 5100), ('external', 5101), ('prevent', 5102), ('adventure', 5103), ('protective', 5104), ('eloquent', 5105), ('exhibit', 5106), ('monroe', 5107), ('barked', 5108), ('brake', 5109), ('liquor', 5110), ('conditioner', 5111), ('ironed', 5112), ('solutions', 5113), ('interpret', 5114), ('protested', 5115), ('directed', 5116), ('marked', 5117), ('asylum', 5118), ('powerless', 5119), ('undependable', 5120), ('garlic', 5121), ('exgirlfriend', 5122), ('adopt', 5123), ('grandson', 5124), ('congratulations', 5125), ('crook', 5126), ('aches', 5127), ('bullets', 5128), ('rapid', 5129), ('insists', 5130), ('development', 5131), ('appointments', 5132), ('george', 5133), ('cigar', 5134), ('weddings', 5135), ('foggy', 5136), ('walnut', 5137), ('waitress', 5138), ('wanna', 5139), ('identified', 5140), ('invest', 5141), ('february', 5142), ('hacked', 5143), ('cpr', 5144), ('bumped', 5145), ('luckily', 5146), ('fahrenheit', 5147), ('exhusband', 5148), ('spectacular', 5149), ('monogamy', 5150), ('documentaries', 5151), ('lifeguard', 5152), ('certificate', 5153), ('bombed', 5154), ('doghouse', 5155), ('dealt', 5156), ('experimented', 5157), ('december', 5158), ('counts', 5159), ('apprentice', 5160), ('massachusetts', 5161), ('overconfident', 5162), ('fashionable', 5163), ('scheduled', 5164), ('whisky', 5165), ('cease', 5166), ('unstable', 5167), ('plead', 5168), ('scout', 5169), ('placed', 5170), ('postcards', 5171), ('itch', 5172), ('vice', 5173), ('slightest', 5174), ('paused', 5175), ('carelessness', 5176), ('gardening', 5177), ('recall', 5178), ('channel', 5179), ('cushions', 5180), ('crackers', 5181), ('adores', 5182), ('swore', 5183), ('cuts', 5184), ('registration', 5185), ('anchovies', 5186), ('items', 5187), ('pierced', 5188), ('illegible', 5189), ('disc', 5190), ('65', 5191), ('gratitude', 5192), ('darkness', 5193), ('thrown', 5194), ('somewhat', 5195), ('naughty', 5196), ('trainee', 5197), ('mysteries', 5198), ('jamaica', 5199), ('involve', 5200), ('crimes', 5201), ('fold', 5202), ('violated', 5203), ('economic', 5204), ('expenses', 5205), ('croatia', 5206), ('southeastern', 5207), ('euros', 5208), ('quotes', 5209), ('vampires', 5210), ('rises', 5211), ('calculates', 5212), ('thanksgiving', 5213), ('launched', 5214), ('booked', 5215), ('partially', 5216), ('challenges', 5217), ('lump', 5218), ('dieting', 5219), ('composer', 5220), ('orchestra', 5221), ('labels', 5222), ('separately', 5223), ('ballet', 5224), ('catching', 5225), ('bargain', 5226), ('withdraw', 5227), ('enlisted', 5228), ('pineapple', 5229), ('mushrooms', 5230), ('pacific', 5231), ('instinct', 5232), ('warrant', 5233), ('slugged', 5234), ('prayer', 5235), ('shyly', 5236), ('assistants', 5237), ('madrid', 5238), ('trace', 5239), ('ammonia', 5240), ('threats', 5241), ('mandatory', 5242), ('slaves', 5243), ('guitars', 5244), ('contain', 5245), ('apprehensive', 5246), ('seeds', 5247), ('sox', 5248), ('furnished', 5249), ('feared', 5250), ('professors', 5251), ('porch', 5252), ('bravery', 5253), ('supportive', 5254), ('analysis', 5255), ('remarks', 5256), ('charm', 5257), ('obsessed', 5258), ('unemployment', 5259), ('colleague', 5260), ('originated', 5261), ('expects', 5262), ('newton', 5263), ('ethnic', 5264), ('encourage', 5265), ('catches', 5266), ('wept', 5267), ('picking', 5268), ('curtains', 5269), ('grocery', 5270), ('outskirts', 5271), ('hypocritical', 5272), ('gang', 5273), ('grant', 5274), ('opener', 5275), ('misery', 5276), ('satisfy', 5277), ('oily', 5278), ('unforgettable', 5279), ('romance', 5280), ('turtles', 5281), ('rides', 5282), ('insure', 5283), ('brakes', 5284), ('gasped', 5285), ('paleontologist', 5286), ('youth', 5287), ('machines', 5288), ('overdose', 5289), ('messy', 5290), ('crocodile', 5291), ('perfume', 5292), ('assertive', 5293), ('vulgar', 5294), ('reflect', 5295), ('serum', 5296), ('concept', 5297), ('id', 5298), ('autistic', 5299), ('tehran', 5300), ('louis', 5301), ('navy', 5302), ('judgement', 5303), ('lifestyle', 5304), ('playful', 5305), ('insomnia', 5306), ('hardware', 5307), ('dependent', 5308), ('cycling', 5309), ('intervene', 5310), ('harvest', 5311), ('antidote', 5312), ('filling', 5313), ('hysterical', 5314), ('cheer', 5315), ('supported', 5316), ('dam', 5317), ('include', 5318), ('skis', 5319), ('uncles', 5320), ('15', 5321), ('backwards', 5322), ('cursed', 5323), ('continent', 5324), ('homes', 5325), ('asap', 5326), ('citizenship', 5327), ('accounts', 5328), ('lemons', 5329), ('rode', 5330), ('beg', 5331), ('sketched', 5332), ('elsewhere', 5333), ('superman', 5334), ('flattered', 5335), ('responsibilities', 5336), ('determination', 5337), ('dial', 5338), ('household', 5339), ('pursued', 5340), ('belgium', 5341), ('amended', 5342), ('implying', 5343), ('squirrels', 5344), ('harp', 5345), ('location', 5346), ('paperwork', 5347), ('underestimated', 5348), ('appearances', 5349), ('woozy', 5350), ('complication', 5351), ('longest', 5352), ('widely', 5353), ('donate', 5354), ('enlighten', 5355), ('surf', 5356), ('tracked', 5357), ('websites', 5358), ('devoured', 5359), ('flights', 5360), ('abducted', 5361), ('autograph', 5362), ('paralyzed', 5363), ('distraction', 5364), ('trainees', 5365), ('resentful', 5366), ('messenger', 5367), ('print', 5368), ('hallucinations', 5369), ('nuisance', 5370), ('mainly', 5371), ('significant', 5372), ('letting', 5373), ('rolling', 5374), ('dragon', 5375), ('elementary', 5376), ('consented', 5377), ('reader', 5378), ('clerk', 5379), ('domineering', 5380), ('jog', 5381), ('invention', 5382), ('simpler', 5383), ('triathlon', 5384), ('cottage', 5385), ('meantime', 5386), ('ignorant', 5387), ('platform', 5388), ('clue', 5389), ('ruins', 5390), ('unnatural', 5391), ('girlfriends', 5392), ('bodyguard', 5393), ('rhythm', 5394), ('conduct', 5395), ('yawn', 5396), ('flavor', 5397), ('austria', 5398), ('clutch', 5399), ('skype', 5400), ('differ', 5401), ('40', 5402), ('whiskey', 5403), ('purple', 5404), ('skips', 5405), ('thomas', 5406), ('transferred', 5407), ('devious', 5408), ('curse', 5409), ('sophomores', 5410), ('raising', 5411), ('staff', 5412), ('civil', 5413), ('flunk', 5414), ('imported', 5415), ('subscribe', 5416), ('exhibition', 5417), ('painless', 5418), ('terrorist', 5419), ('granddaughter', 5420), ('models', 5421), ('servant', 5422), ('disgruntled', 5423), ('neutral', 5424), ('unintelligent', 5425), ('waterloo', 5426), ('included', 5427), ('prince', 5428), ('linguistics', 5429), ('investigate', 5430), ('mass', 5431), ('economically', 5432), ('picnics', 5433), ('impatiently', 5434), ('employee', 5435), ('ukulele', 5436), ('poland', 5437), ('receiving', 5438), ('unfortunate', 5439), ('eliminated', 5440), ('melody', 5441), ('interruption', 5442), ('advertise', 5443), ('teams', 5444), ('ale', 5445), ('chewed', 5446), ('crybaby', 5447), ('okinawa', 5448), ('diamonds', 5449), ('artists', 5450), ('vacuum', 5451), ('crops', 5452), ('restart', 5453), ('goats', 5454), ('floors', 5455), ('airconditioned', 5456), ('farther', 5457), ('cucumbers', 5458), ('brains', 5459), ('sends', 5460), ('kicking', 5461), ('cartoonist', 5462), ('critic', 5463), ('proposed', 5464), ('woebegone', 5465), ('transfusion', 5466), ('condemned', 5467), ('proverb', 5468), ('melbourne', 5469), ('locks', 5470), ('brothersinlaw', 5471), ('tenants', 5472), ('honk', 5473), ('siblings', 5474), ('whales', 5475), ('97', 5476), ('atomic', 5477), ('sandstone', 5478), ('extent', 5479), ('wool', 5480), ('stoned', 5481), ('indispensable', 5482), ('impressions', 5483), ('recycled', 5484), ('liars', 5485), ('attempting', 5486), ('historical', 5487), ('wig', 5488), ('hammered', 5489), ('franklin', 5490), ('continues', 5491), ('serving', 5492), ('bribed', 5493), ('safest', 5494), ('charisma', 5495), ('boats', 5496), ('millionaires', 5497), ('untied', 5498), ('klutz', 5499), ('reduced', 5500), ('passes', 5501), ('complicate', 5502), ('tatami', 5503), ('vehicle', 5504), ('whichever', 5505), ('sheets', 5506), ('delirious', 5507), ('hospitals', 5508), ('snap', 5509), ('panting', 5510), ('juvenile', 5511), ('benefits', 5512), ('resilient', 5513), ('roleplaying', 5514), ('tipsy', 5515), ('losers', 5516), ('1950s', 5517), ('gardeners', 5518), ('swears', 5519), ('singers', 5520), ('visits', 5521), ('orleans', 5522), ('achieve', 5523), ('unsophisticated', 5524), ('exposed', 5525), ('condominium', 5526), ('ipod', 5527), ('bronze', 5528), ('sock', 5529), ('proves', 5530), ('purchased', 5531), ('frugal', 5532), ('signaled', 5533), ('naples', 5534), ('unconcerned', 5535), ('toaster', 5536), ('extinct', 5537), ('pacifist', 5538), ('contributing', 5539), ('evidently', 5540), ('bamboo', 5541), ('exiled', 5542), ('abuse', 5543), ('guessing', 5544), ('consumption', 5545), ('buckingham', 5546), ('sets', 5547), ('pear', 5548), ('believing', 5549), ('testify', 5550), ('aids', 5551), ('vegetable', 5552), ('funerals', 5553), ('credibility', 5554), ('struggle', 5555), ('owls', 5556), ('irritable', 5557), ('applying', 5558), ('de', 5559), ('janeiro', 5560), ('boils', 5561), ('parcel', 5562), ('gradually', 5563), ('onion', 5564), ('amusement', 5565), ('dishwasher', 5566), ('forecast', 5567), ('slavery', 5568), ('lag', 5569), ('liberty', 5570), ('sacrifice', 5571), ('affirmed', 5572), ('affects', 5573), ('freaky', 5574), ('poisonous', 5575), ('refreshing', 5576), ('petition', 5577), ('bake', 5578), ('learner', 5579), ('challenged', 5580), ('pessimist', 5581), ('rats', 5582), ('struggled', 5583), ('shoved', 5584), ('ratted', 5585), ('pox', 5586), ('extreme', 5587), ('croissant', 5588), ('negotiated', 5589), ('giant', 5590), ('constant', 5591), ('chaotic', 5592), ('consequence', 5593), ('wardrobe', 5594), ('firefighter', 5595), ('admirable', 5596), ('karaoke', 5597), ('arguments', 5598), ('symbol', 5599), ('disagreed', 5600), ('centimeters', 5601), ('highest', 5602), ('drain', 5603), ('relieve', 5604), ('mixed', 5605), ('sunflowers', 5606), ('soaking', 5607), ('supervisor', 5608), ('reform', 5609), ('gardener', 5610), ('established', 5611), ('cork', 5612), ('cnn', 5613), ('quarreled', 5614), ('recite', 5615), ('generosity', 5616), ('bow', 5617), ('bouquet', 5618), ('runner', 5619), ('relented', 5620), ('inclined', 5621), ('consent', 5622), ('recommendation', 5623), ('raisins', 5624), ('biting', 5625), ('heroin', 5626), ('shaves', 5627), ('lovers', 5628), ('retirement', 5629), ('recording', 5630), ('exercised', 5631), ('growth', 5632), ('exwife', 5633), ('superior', 5634), ('alike', 5635), ('reconsidered', 5636), ('melts', 5637), ('electrical', 5638), ('archery', 5639), ('intriguing', 5640), ('deported', 5641), ('imitation', 5642), ('depressing', 5643), ('primary', 5644), ('restroom', 5645), ('kansas', 5646), ('votes', 5647), ('grasped', 5648), ('anxiously', 5649), ('collections', 5650), ('pampered', 5651), ('victorious', 5652), ('mp3', 5653), ('gambler', 5654), ('ludicrous', 5655), ('selfemployed', 5656), ('status', 5657), ('subtitles', 5658), ('compliment', 5659), ('suburbs', 5660), ('prognosis', 5661), ('serves', 5662), ('80', 5663), ('hardest', 5664), ('therapist', 5665), ('stake', 5666), ('110', 5667), ('racist', 5668), ('strangely', 5669), ('salesman', 5670), ('righthanded', 5671), ('profile', 5672), ('refresh', 5673), ('industry', 5674), ('muscles', 5675), ('tobacco', 5676), ('seatbelt', 5677), ('proven', 5678), ('activity', 5679), ('courtesy', 5680), ('hiccuping', 5681), ('crawling', 5682), ('ribbon', 5683), ('encouraging', 5684), ('dedicate', 5685), ('beep', 5686), ('wars', 5687), ('grammatically', 5688), ('cherries', 5689), ('clocks', 5690), ('abrupt', 5691), ('underlined', 5692), ('regard', 5693), ('banks', 5694), ('prepaid', 5695), ('minds', 5696), ('caffeine', 5697), ('reflection', 5698), ('healthier', 5699), ('imaginary', 5700), ('mugged', 5701), ('collapse', 5702), ('paints', 5703), ('downloaded', 5704), ('shiny', 5705), ('consists', 5706), ('ton', 5707), ('hammock', 5708), ('perform', 5709), ('cremated', 5710), ('constitution', 5711), ('forces', 5712), ('drafted', 5713), ('secondhand', 5714), ('gifted', 5715), ('sunshine', 5716), ('islands', 5717), ('overlook', 5718), ('oysters', 5719), ('scrawny', 5720), ('headaches', 5721), ('suspicions', 5722), ('judo', 5723), ('limousine', 5724), ('untie', 5725), ('aliens', 5726), ('chapters', 5727), ('exhaled', 5728), ('governor', 5729), ('assured', 5730), ('sights', 5731), ('elba', 5732), ('parallel', 5733), ('projects', 5734), ('boyfriends', 5735), ('physically', 5736), ('distrusted', 5737), ('vegan', 5738), ('restarting', 5739), ('confidential', 5740), ('howling', 5741), ('cloth', 5742), ('refer', 5743), ('mince', 5744), ('tb', 5745), ('dental', 5746), ('fragile', 5747), ('valentine', 5748), ('illogical', 5749), ('yeah', 5750), ('ecstatic', 5751), ('avid', 5752), ('seeks', 5753), ('intent', 5754), ('foxes', 5755), ('absentminded', 5756), ('fort', 5757), ('accepting', 5758), ('carries', 5759), ('extensive', 5760), ('timetable', 5761), ('unsolved', 5762), ('trainer', 5763), ('manhattan', 5764), ('stimulating', 5765), ('inflation', 5766), ('bland', 5767), ('movement', 5768), ('blocked', 5769), ('22', 5770), ('cheering', 5771), ('weighed', 5772), ('measles', 5773), ('glanced', 5774), ('1492', 5775), ('remembering', 5776), ('shrugged', 5777), ('frightening', 5778), ('undo', 5779), ('unique', 5780), ('flirting', 5781), ('fits', 5782), ('geniuses', 5783), ('shortest', 5784), ('hilarious', 5785), ('numbered', 5786), ('wiped', 5787), ('vouch', 5788), ('accomplish', 5789), ('europeans', 5790), ('democratic', 5791), ('dates', 5792), ('cairo', 5793), ('lifetime', 5794), ('butterflies', 5795), ('gesture', 5796), ('roast', 5797), ('sympathized', 5798), ('dime', 5799), ('thermostat', 5800), ('renewed', 5801), ('subscription', 5802), ('roundtrip', 5803), ('spots', 5804), ('resemble', 5805), ('iphone', 5806), ('attached', 5807), ('cured', 5808), ('passing', 5809), ('recorded', 5810), ('visible', 5811), ('stoplight', 5812), ('crusader', 5813), ('clingy', 5814), ('steep', 5815), ('discourage', 5816), ('eater', 5817), ('carrot', 5818), ('spelled', 5819), ('kisser', 5820), ('quarrels', 5821), ('affectionate', 5822), ('solar', 5823), ('portugal', 5824), ('dye', 5825), ('ace', 5826), ('ending', 5827), ('maximum', 5828), ('disregarded', 5829), ('frenchman', 5830), ('accusations', 5831), ('frighten', 5832), ('conspiracy', 5833), ('western', 5834), ('sirens', 5835), ('validate', 5836), ('precisely', 5837), ('backward', 5838), ('middleaged', 5839), ('copyrighted', 5840), ('specialty', 5841), ('improvement', 5842), ('skipping', 5843), ('thoroughly', 5844), ('rusty', 5845), ('trophy', 5846), ('patriotic', 5847), ('blabbermouth', 5848), ('59', 5849), ('colleagues', 5850), ('athletes', 5851), ('decline', 5852), ('humorous', 5853), ('intern', 5854), ('controversial', 5855), ('shelter', 5856), ('vacations', 5857), ('genuine', 5858), ('chaucer', 5859), ('granite', 5860), ('paragraph', 5861), ('confronted', 5862), ('shopped', 5863), ('contradict', 5864), ('sms', 5865), ('arrange', 5866), ('hindered', 5867), ('amaze', 5868), ('abolish', 5869), ('geography', 5870), ('ditched', 5871), ('atlantic', 5872), ('petty', 5873), ('poisoning', 5874), ('handgun', 5875), ('damp', 5876), ('dive', 5877), ('vomiting', 5878), ('outsmarted', 5879), ('wires', 5880), ('hollow', 5881), ('participated', 5882), ('monk', 5883), ('agriculture', 5884), ('rainbow', 5885), ('ruining', 5886), ('bragging', 5887), ('sting', 5888), ('principles', 5889), ('groaned', 5890), ('housewife', 5891), ('tradition', 5892), ('compact', 5893), ('rinsed', 5894), ('orphans', 5895), ('heels', 5896), ('interpreted', 5897), ('eternal', 5898), ('dim', 5899), ('explore', 5900), ('forth', 5901), ('hogwash', 5902), ('slouch', 5903), ('cancelled', 5904), ('refugees', 5905), ('resigning', 5906), ('fluke', 5907), ('technical', 5908), ('smokers', 5909), ('harmonica', 5910), ('manipulate', 5911), ('replied', 5912), ('testified', 5913), ('analyze', 5914), ('obsessive', 5915), ('blues', 5916), ('gaining', 5917), ('championship', 5918), ('twirling', 5919), ('venice', 5920), ('brightest', 5921), ('peppers', 5922), ('sniffed', 5923), ('regrettable', 5924), ('iq', 5925), ('carbon', 5926), ('supply', 5927), ('challenging', 5928), ('holland', 5929), ('listed', 5930), ('grip', 5931), ('swelling', 5932), ('illustrated', 5933), ('marilyn', 5934), ('startled', 5935), ('tale', 5936), ('barks', 5937), ('stereo', 5938), ('swum', 5939), ('flash', 5940), ('politicians', 5941), ('budge', 5942), ('dubious', 5943), ('seek', 5944), ('shadow', 5945), ('unstoppable', 5946), ('bark', 5947), ('defensive', 5948), ('sunlight', 5949), ('abundant', 5950), ('58', 5951), ('roman', 5952), ('freed', 5953), ('legend', 5954), ('fires', 5955), ('chin', 5956), ('toyota', 5957), ('stamina', 5958), ('embarrassment', 5959), ('communication', 5960), ('loaned', 5961), ('occasion', 5962), ('masochist', 5963), ('prioritize', 5964), ('croatian', 5965), ('corruption', 5966), ('producer', 5967), ('usb', 5968), ('rooting', 5969), ('refreshments', 5970), ('negotiations', 5971), ('xenophobic', 5972), ('represented', 5973), ('universal', 5974), ('stepbrother', 5975), ('overcoat', 5976), ('remorseful', 5977), ('locking', 5978), ('shivered', 5979), ('promising', 5980), ('chart', 5981), ('rubbed', 5982), ('hostage', 5983), ('fasting', 5984), ('hearts', 5985), ('gravity', 5986), ('perseverance', 5987), ('authorities', 5988), ('typos', 5989), ('fractured', 5990), ('misinformed', 5991), ('judged', 5992), ('gel', 5993), ('confessing', 5994), ('victims', 5995), ('psychology', 5996), ('niece', 5997), ('dweller', 5998), ('desperately', 5999), ('sniffling', 6000), ('sources', 6001), ('disability', 6002), ('slip', 6003), ('breast', 6004), ('humanity', 6005), ('accountable', 6006), ('eighth', 6007), ('dairy', 6008), ('stove', 6009), ('fruits', 6010), ('mere', 6011), ('pub', 6012), ('alley', 6013), ('pacifists', 6014), ('employ', 6015), ('exhilarating', 6016), ('bedrooms', 6017), ('blond', 6018), ('divide', 6019), ('cabin', 6020), ('actors', 6021), ('burped', 6022), ('murders', 6023), ('beaches', 6024), ('crab', 6025), ('invincible', 6026), ('maiden', 6027), ('corsage', 6028), ('regained', 6029), ('pursuit', 6030), ('borders', 6031), ('gravy', 6032), ('diagnosis', 6033), ('prepares', 6034), ('covers', 6035), ('gunshot', 6036), ('level', 6037), ('surface', 6038), ('grit', 6039), ('entitled', 6040), ('licking', 6041), ('bookworm', 6042), ('pro', 6043), ('residence', 6044), ('immigrant', 6045), ('impose', 6046), ('puzzles', 6047), ('bugs', 6048), ('9', 6049), ('bacteria', 6050), ('possessed', 6051), ('quantity', 6052), ('beautifully', 6053), ('blown', 6054), ('botanical', 6055), ('stiff', 6056), ('sole', 6057), ('volunteer', 6058), ('manner', 6059), ('improves', 6060), ('dice', 6061), ('cartoon', 6062), ('railroad', 6063), ('stain', 6064), ('hiccup', 6065), ('1', 6066), ('rifles', 6067), ('fireworks', 6068), ('imagining', 6069), ('albums', 6070), ('overreacted', 6071), ('melodramatic', 6072), ('guidance', 6073), ('85', 6074), ('cliff', 6075), ('catalog', 6076), ('girdle', 6077), ('probation', 6078), ('chapter', 6079), ('plausible', 6080), ('thames', 6081), ('songwriter', 6082), ('gunshots', 6083), ('wrestler', 6084), ('responsibly', 6085), ('discrete', 6086), ('whistling', 6087), ('highway', 6088), ('blinded', 6089), ('blushed', 6090), ('distances', 6091), ('priority', 6092), ('species', 6093), ('harmful', 6094), ('ties', 6095), ('leaning', 6096), ('regular', 6097), ('cabinet', 6098), ('occur', 6099), ('princes', 6100), ('cradle', 6101), ('scientific', 6102), ('refreshed', 6103), ('displeased', 6104), ('nara', 6105), ('whispering', 6106), ('attributes', 6107), ('condone', 6108), ('snores', 6109), ('blast', 6110), ('headstrong', 6111), ('allergy', 6112), ('meaningless', 6113), ('transported', 6114), ('punctuation', 6115), ('dolphin', 6116), ('traded', 6117), ('kilo', 6118), ('sixteen', 6119), ('planes', 6120), ('graceful', 6121), ('italo', 6122), ('calvino', 6123), ('sistersinlaw', 6124), ('grinned', 6125), ('virtue', 6126), ('obtain', 6127), ('hugging', 6128), ('leaf', 6129), ('heaven', 6130), ('sinking', 6131), ('beings', 6132), ('exacerbate', 6133), ('disillusioned', 6134), ('faking', 6135), ('penicillin', 6136), ('suitable', 6137), ('kanji', 6138), ('sweating', 6139), ('unimaginable', 6140), ('immune', 6141), ('burger', 6142), ('sides', 6143), ('showing', 6144), ('shove', 6145), ('snowmobile', 6146), ('senior', 6147), ('corn', 6148), ('literally', 6149), ('owed', 6150), ('weaker', 6151), ('vending', 6152), ('however', 6153), ('diaper', 6154), ('mild', 6155), ('bride', 6156), ('listener', 6157), ('episode', 6158), ('departed', 6159), ('associate', 6160), ('ironing', 6161), ('attendant', 6162), ('discussions', 6163), ('disadvantages', 6164), ('cushion', 6165), ('niagara', 6166), ('calculating', 6167), ('1814', 6168), ('arithmetic', 6169), ('prawns', 6170), ('shoplifting', 6171), ('polluted', 6172), ('tonic', 6173), ('nonsmoking', 6174), ('premonition', 6175), ('livid', 6176), ('pets', 6177), ('prudish', 6178), ('prodigy', 6179), ('nile', 6180), ('straightened', 6181), ('stir', 6182), ('worm', 6183), ('classmate', 6184), ('replaceable', 6185), ('teppanyaki', 6186), ('necessity', 6187), ('bloody', 6188), ('youtube', 6189), ('vision', 6190), ('lungs', 6191), ('deceased', 6192), ('surprisingly', 6193), ('poorer', 6194), ('elevators', 6195), ('urchins', 6196), ('review', 6197), ('pinched', 6198), ('norway', 6199), ('psychiatrists', 6200), ('unwanted', 6201), ('denial', 6202), ('extraordinarily', 6203), ('windshield', 6204), ('cigars', 6205), ('award', 6206), ('disgrace', 6207), ('planets', 6208), ('burglars', 6209), ('rapper', 6210), ('jungle', 6211), ('squash', 6212), ('gulf', 6213), ('chips', 6214), ('negligent', 6215), ('strongest', 6216), ('polished', 6217), ('dared', 6218), ('smooth', 6219), ('nun', 6220), ('abhor', 6221), ('summoned', 6222), ('1969', 6223), ('competitions', 6224), ('ecuador', 6225), ('mothers', 6226), ('boomerang', 6227), ('speakers', 6228), ('sack', 6229), ('lid', 6230), ('progressing', 6231), ('vaccine', 6232), ('tragically', 6233), ('routine', 6234), ('calmed', 6235), ('foolhardy', 6236), ('redneck', 6237), ('ethical', 6238), ('vengeance', 6239), ('partying', 6240), ('improvised', 6241), ('plague', 6242), ('submitted', 6243), ('turtle', 6244), ('sigh', 6245), ('mouths', 6246), ('alexandria', 6247), ('reindeer', 6248), ('lawnmower', 6249), ('mic', 6250), ('vices', 6251), ('diseases', 6252), ('luckiest', 6253), ('correcting', 6254), ('standards', 6255), ('hippies', 6256), ('misled', 6257), ('ninth', 6258), ('pigeon', 6259), ('huh', 6260), ('aftershave', 6261), ('taxis', 6262), ('fled', 6263), ('punctuality', 6264), ('passwords', 6265), ('roommates', 6266), ('collector', 6267), ('dermatologist', 6268), ('wimp', 6269), ('pirated', 6270), ('taiwan', 6271), ('gangsters', 6272), ('airmail', 6273), ('individual', 6274), ('tear', 6275), ('approximately', 6276), ('romney', 6277), ('saxophone', 6278), ('futile', 6279), ('sauna', 6280), ('obesity', 6281), ('frost', 6282), ('pinch', 6283), ('hitter', 6284), ('clutched', 6285), ('peninsula', 6286), ('avoids', 6287), ('trigger', 6288), ('depression', 6289), ('programs', 6290), ('leaders', 6291), ('concentrated', 6292), ('clinic', 6293), ('decorating', 6294), ('league', 6295), ('tomboy', 6296), ('despair', 6297), ('hook', 6298), ('rip', 6299), ('housework', 6300), ('rates', 6301), ('pears', 6302), ('1499', 6303), ('harmony', 6304), ('frowned', 6305), ('hounding', 6306), ('malaysia', 6307), ('terror', 6308), ('automatically', 6309), ('paramedic', 6310), ('calmly', 6311), ('reformat', 6312), ('wit', 6313), ('chalk', 6314), ('pupils', 6315), ('setting', 6316), ('olympic', 6317), ('abated', 6318), ('cutting', 6319), ('thesis', 6320), ('describing', 6321), ('lease', 6322), ('longing', 6323), ('trembled', 6324), ('diploma', 6325), ('unpopular', 6326), ('reconsider', 6327), ('industrial', 6328), ('lousy', 6329), ('swallowing', 6330), ('rolls', 6331), ('military', 6332), ('formula', 6333), ('requests', 6334), ('protein', 6335), ('accomplice', 6336), ('ups', 6337), ('downs', 6338), ('stupidity', 6339), ('cheeks', 6340), ('grits', 6341), ('pepsi', 6342), ('arthritis', 6343), ('services', 6344), ('newer', 6345), ('brick', 6346), ('portions', 6347), ('baking', 6348), ('selfie', 6349), ('wandered', 6350), ('halfbrother', 6351), ('interns', 6352), ('punch', 6353), ('tortellini', 6354), ('equally', 6355), ('profusely', 6356), ('trim', 6357), ('pardoned', 6358), ('foiled', 6359), ('portion', 6360), ('alternatives', 6361), ('stored', 6362), ('unclear', 6363), ('firewood', 6364), ('values', 6365), ('crafty', 6366), ('constructed', 6367), ('somber', 6368), ('speculation', 6369), ('pounding', 6370), ('settled', 6371), ('chewing', 6372), ('dense', 6373), ('tetanus', 6374), ('herring', 6375), ('tray', 6376), ('shuddered', 6377), ('dine', 6378), ('sunrise', 6379), ('disagreeable', 6380), ('beverage', 6381), ('multiple', 6382), ('finishes', 6383), ('sticky', 6384), ('obstacles', 6385), ('current', 6386), ('provoked', 6387), ('explanations', 6388), ('wavelength', 6389), ('mocking', 6390), ('artificial', 6391), ('reasoning', 6392), ('bridges', 6393), ('waking', 6394), ('infallible', 6395), ('renew', 6396), ('siding', 6397), ('stretch', 6398), ('windmills', 6399), ('disposal', 6400), ('backs', 6401), ('exhale', 6402), ('1950', 6403), ('checks', 6404), ('forbid', 6405), ('messed', 6406), ('coherent', 6407), ('deciding', 6408), ('disabilities', 6409), ('prediction', 6410), ('gathering', 6411), ('preoccupied', 6412), ('o', 6413), ('republican', 6414), ('motors', 6415), ('athens', 6416), ('cheerleaders', 6417), ('flaw', 6418), ('deposited', 6419), ('attending', 6420), ('petrified', 6421), ('beggar', 6422), ('preparations', 6423), ('hotter', 6424), ('composers', 6425), ('lonesome', 6426), ('chasing', 6427), ('separates', 6428), ('oath', 6429), ('brighter', 6430), ('drugstore', 6431), ('830', 6432), ('paulo', 6433), ('bled', 6434), ('vitamin', 6435), ('grounds', 6436), ('pirates', 6437), ('renounced', 6438), ('scaring', 6439), ('workout', 6440), ('christians', 6441), ('peach', 6442), ('martial', 6443), ('infectious', 6444), ('specify', 6445), ('exceptional', 6446), ('shouts', 6447), ('gently', 6448), ('verdict', 6449), ('chickened', 6450), ('resolved', 6451), ('touchy', 6452), ('cleans', 6453), ('thirtyone', 6454), ('humiliating', 6455), ('ninety', 6456), ('shaving', 6457), ('acid', 6458), ('tightly', 6459), ('quarreling', 6460), ('lamb', 6461), ('blacked', 6462), ('reduction', 6463), ('cases', 6464), ('thumb', 6465), ('heroic', 6466), ('silently', 6467), ('cultural', 6468), ('stacked', 6469), ('compulsive', 6470), ('perfectionist', 6471), ('insights', 6472), ('block', 6473), ('explode', 6474), ('delhi', 6475), ('kindhearted', 6476), ('blinds', 6477), ('thunder', 6478), ('panicking', 6479), ('explains', 6480), ('taunting', 6481), ('lenses', 6482), ('penny', 6483), ('technically', 6484), ('acknowledge', 6485), ('convertible', 6486), ('geraniums', 6487), ('convict', 6488), ('convicted', 6489), ('pinpoint', 6490), ('chemical', 6491), ('hostel', 6492), ('item', 6493), ('rot', 6494), ('actinium', 6495), ('preposterous', 6496), ('refugee', 6497), ('copper', 6498), ('floats', 6499), ('trusting', 6500), ('strainer', 6501), ('flush', 6502), ('route', 6503), ('effects', 6504), ('diagram', 6505), ('impostor', 6506), ('buck', 6507), ('utterly', 6508), ('boiled', 6509), ('bassoon', 6510), ('presented', 6511), ('indiscreet', 6512), ('instant', 6513), ('amateur', 6514), ('colorful', 6515), ('unfinished', 6516), ('mortal', 6517), ('villagers', 6518), ('5000', 6519), ('squeezed', 6520), ('pakistan', 6521), ('stocks', 6522), ('brotherinlaw', 6523), ('premier', 6524), ('readily', 6525), ('unharmed', 6526), ('kettle', 6527), ('wrinkles', 6528), ('confusion', 6529), ('appealed', 6530), ('oriental', 6531), ('pottery', 6532), ('breed', 6533), ('softly', 6534), ('aspiring', 6535), ('oversight', 6536), ('tacos', 6537), ('gummy', 6538), ('mortified', 6539), ('cheapest', 6540), ('stained', 6541), ('pricey', 6542), ('crow', 6543), ('unsafe', 6544), ('marijuana', 6545), ('pelican', 6546), ('pry', 6547), ('tone', 6548), ('warnings', 6549), ('assaulted', 6550), ('suicidal', 6551), ('hummingbird', 6552), ('sympathize', 6553), ('tanker', 6554), ('relevant', 6555), ('passports', 6556), ('trumpet', 6557), ('sunflower', 6558), ('grim', 6559), ('profanity', 6560), ('jewels', 6561), ('balcony', 6562), ('700', 6563), ('torment', 6564), ('minors', 6565), ('grain', 6566), ('cope', 6567), ('physical', 6568), ('arrogance', 6569), ('referee', 6570), ('gazed', 6571), ('lawn', 6572), ('dang', 6573), ('qualifications', 6574), ('begging', 6575), ('gather', 6576), ('brushwood', 6577), ('toss', 6578), ('questionable', 6579), ('curt', 6580), ('lacking', 6581), ('comforting', 6582), ('explored', 6583), ('proposing', 6584), ('bore', 6585), ('calories', 6586), ('emphasized', 6587), ('fastened', 6588), ('vocabulary', 6589), ('employed', 6590), ('vibrating', 6591), ('twentyfive', 6592), ('st', 6593), ('dismounted', 6594), ('situated', 6595), ('2010', 6596), ('therapy', 6597), ('sweaty', 6598), ('stingiest', 6599), ('unplugged', 6600), ('revolt', 6601), ('filmed', 6602), ('penpal', 6603), ('fireman', 6604), ('rebels', 6605), ('traitors', 6606), ('fountain', 6607), ('warmed', 6608), ('meanings', 6609), ('balloon', 6610), ('1990', 6611), ('kuwait', 6612), ('amputated', 6613), ('affection', 6614), ('donuts', 6615), ('keyed', 6616), ('reign', 6617), ('underestimating', 6618), ('homemade', 6619), ('wavering', 6620), ('intentional', 6621), ('reflexes', 6622), ('rushed', 6623), ('perfection', 6624), ('sleeve', 6625), ('duties', 6626), ('dealer', 6627), ('holds', 6628), ('pumpkins', 6629), ('knuckle', 6630), ('religions', 6631), ('essential', 6632), ('evasive', 6633), ('rackets', 6634), ('paramedics', 6635), ('relative', 6636), ('liver', 6637), ('dose', 6638), ('analyzed', 6639), ('contribution', 6640), ('chop', 6641), ('charity', 6642), ('braver', 6643), ('airports', 6644), ('disapprove', 6645), ('harmed', 6646), ('superficial', 6647), ('nonstop', 6648), ('naturally', 6649), ('23', 6650), ('understatement', 6651), ('oceanographer', 6652), ('tshirts', 6653), ('sarcasm', 6654), ('civic', 6655), ('pop', 6656), ('absorbs', 6657), ('tasks', 6658), ('repairs', 6659), ('duel', 6660), ('compassion', 6661), ('flavoring', 6662), ('cinderella', 6663), ('mesmerized', 6664), ('backpack', 6665), ('detest', 6666), ('leukemia', 6667), ('dormitory', 6668), ('annoys', 6669), ('delicately', 6670), ('damages', 6671), ('excluded', 6672), ('subtle', 6673), ('entries', 6674), ('hotwire', 6675), ('slim', 6676), ('conscience', 6677), ('camels', 6678), ('flags', 6679), ('generator', 6680), ('seized', 6681), ('subjective', 6682), ('fortunately', 6683), ('peeking', 6684), ('distributed', 6685), ('moderate', 6686), ('defended', 6687), ('clubs', 6688), ('advertising', 6689), ('popeye', 6690), ('racing', 6691), ('repay', 6692), ('oblivious', 6693), ('civilization', 6694), ('bipolar', 6695), ('ufos', 6696), ('wines', 6697), ('reread', 6698), ('typo', 6699), ('fourletter', 6700), ('altitude', 6701), ('invested', 6702), ('lightbulb', 6703), ('abilities', 6704), ('lateness', 6705), ('civilians', 6706), ('covering', 6707), ('plus', 6708), ('sharpening', 6709), ('1933', 6710), ('fossil', 6711), ('wage', 6712), ('wicked', 6713), ('claim', 6714), ('handling', 6715), ('indignant', 6716), ('permits', 6717), ('liter', 6718), ('excruciating', 6719), ('timing', 6720), ('broom', 6721), ('accuse', 6722), ('painfully', 6723), ('veranda', 6724), ('undressing', 6725), ('woken', 6726), ('conviction', 6727), ('yawned', 6728), ('hangs', 6729), ('dreads', 6730), ('legally', 6731), ('blackmailing', 6732), ('rival', 6733), ('corkscrew', 6734), ('treason', 6735), ('fierce', 6736), ('monte', 6737), ('peeked', 6738), ('bites', 6739), ('diabetes', 6740), ('farted', 6741), ('dante', 6742), ('buddy', 6743), ('mysteriously', 6744), ('unmoved', 6745), ('greets', 6746), ('tormented', 6747), ('tennessee', 6748), ('plucked', 6749), ('syllable', 6750), ('wikipedia', 6751), ('yeast', 6752), ('communists', 6753), ('pamphlet', 6754), ('seal', 6755), ('pudding', 6756), ('slander', 6757), ('manufactured', 6758), ('pocketknife', 6759), ('steals', 6760), ('inexcusable', 6761), ('1968', 6762), ('dignity', 6763), ('casual', 6764), ('myth', 6765), ('illusion', 6766), ('thinner', 6767), ('eightthirty', 6768), ('bookcase', 6769), ('sadness', 6770), ('notebooks', 6771), ('underwater', 6772), ('integrity', 6773), ('applicants', 6774), ('faded', 6775), ('centuries', 6776), ('worthwhile', 6777), ('accumulate', 6778), ('smash', 6779), ('hoax', 6780), ('intervened', 6781), ('female', 6782), ('disobedient', 6783), ('kilogram', 6784), ('1990s', 6785), ('scam', 6786), ('comedies', 6787), ('broad', 6788), ('ping', 6789), ('pong', 6790), ('emails', 6791), ('period', 6792), ('wasteful', 6793), ('thieves', 6794), ('belief', 6795), ('pheasant', 6796), ('sample', 6797), ('companies', 6798), ('irish', 6799), ('molecule', 6800), ('130', 6801), ('muslim', 6802), ('achille', 6803), ('1908', 6804), ('northern', 6805), ('drama', 6806), ('bruises', 6807), ('discretion', 6808), ('silenced', 6809), ('slices', 6810), ('estimate', 6811), ('socializing', 6812), ('signing', 6813), ('alerted', 6814), ('justified', 6815), ('economist', 6816), ('congested', 6817), ('decency', 6818), ('pediatrician', 6819), ('profound', 6820), ('historians', 6821), ('textbooks', 6822), ('pertinent', 6823), ('figs', 6824), ('productivity', 6825), ('fortyeight', 6826), ('forts', 6827), ('alps', 6828), ('anyhow', 6829), ('finishing', 6830), ('1636', 6831), ('fetch', 6832), ('tickled', 6833), ('adamant', 6834), ('gladly', 6835), ('dart', 6836), ('stopwatch', 6837), ('swept', 6838), ('filipino', 6839), ('exgirlfriends', 6840), ('grunted', 6841), ('poop', 6842), ('40000', 6843), ('intervention', 6844), ('drum', 6845), ('toured', 6846), ('motorcycles', 6847), ('graduates', 6848), ('survivor', 6849), ('spirited', 6850), ('trail', 6851), ('faxed', 6852), ('noticing', 6853), ('expires', 6854), ('liberal', 6855), ('ella', 6856), ('fitzgerald', 6857), ('podcasts', 6858), ('messing', 6859), ('buckets', 6860), ('zipper', 6861), ('songwriting', 6862), ('honshu', 6863), ('underage', 6864), ('201', 6865), ('mommy', 6866), ('pumpkin', 6867), ('bricks', 6868), ('utter', 6869), ('industrialization', 6870), ('divine', 6871), ('circled', 6872), ('saint', 6873), ('thirtythree', 6874), ('waterbed', 6875), ('factories', 6876), ('cafe', 6877), ('scarcely', 6878), ('puzzling', 6879), ('ultimate', 6880), ('highlighter', 6881), ('saints', 6882), ('packages', 6883), ('banner', 6884), ('storms', 6885), ('architecture', 6886), ('uncensored', 6887), ('laziest', 6888), ('wakes', 6889), ('coy', 6890), ('wiser', 6891), ('sloshed', 6892), ('complexion', 6893), ('incurable', 6894), ('butler', 6895), ('gif', 6896), ('smartest', 6897), ('compassionate', 6898), ('impoliteness', 6899), ('interrogate', 6900), ('centigrade', 6901), ('32', 6902), ('worsened', 6903), ('hay', 6904), ('attendance', 6905), ('screw', 6906), ('export', 6907), ('personable', 6908), ('unbutton', 6909), ('deposit', 6910), ('despises', 6911), ('sworn', 6912), ('pizzas', 6913), ('florists', 6914), ('leaks', 6915), ('dedication', 6916), ('firm', 6917), ('lunched', 6918), ('overcame', 6919), ('tropical', 6920), ('tulips', 6921), ('contentious', 6922), ('sandals', 6923), ('urge', 6924), ('eviction', 6925), ('vital', 6926), ('meditating', 6927), ('contrary', 6928), ('streak', 6929), ('distilled', 6930), ('proper', 6931), ('chubby', 6932), ('railroads', 6933), ('reassured', 6934), ('designs', 6935), ('stenography', 6936), ('amends', 6937), ('worships', 6938), ('sedative', 6939), ('antibiotics', 6940), ('trucker', 6941), ('connectivity', 6942), ('tender', 6943), ('rung', 6944), ('disconnected', 6945), ('whistled', 6946), ('evenings', 6947), ('netherlands', 6948), ('haiti', 6949), ('windsurfing', 6950), ('drown', 6951), ('feeding', 6952), ('concise', 6953), ('1975', 6954), ('filming', 6955), ('pelicans', 6956), ('buffaloes', 6957), ('rocks', 6958), ('chilly', 6959), ('reassuring', 6960), ('selena', 6961), ('gomez', 6962), ('sucking', 6963), ('fooling', 6964), ('pestering', 6965), ('perverse', 6966), ('spared', 6967), ('pains', 6968), ('parade', 6969), ('experiences', 6970), ('bleed', 6971), ('couples', 6972), ('chief', 6973), ('biography', 6974), ('heirs', 6975), ('fugitive', 6976), ('recognition', 6977), ('floating', 6978), ('tantalize', 6979), ('tempura', 6980), ('aunts', 6981), ('barn', 6982), ('knit', 6983), ('expertise', 6984), ('mandolin', 6985), ('horizon', 6986), ('tavern', 6987), ('disorientated', 6988), ('bugging', 6989), ('southern', 6990), ('feathers', 6991), ('slapping', 6992), ('pools', 6993), ('selfdefense', 6994), ('pawned', 6995), ('alter', 6996), ('protestant', 6997), ('self', 6998), ('sheriff', 6999), ('choke', 7000), ('soundly', 7001), ('coats', 7002), ('drag', 7003), ('celebration', 7004), ('hairbrush', 7005), ('attraction', 7006), ('kneeled', 7007), ('spray', 7008), ('evacuated', 7009), ('biological', 7010), ('equivalent', 7011), ('transaction', 7012), ('pint', 7013), ('renovated', 7014), ('container', 7015), ('awhile', 7016), ('dumber', 7017), ('surroundings', 7018), ('blessed', 7019), ('debatable', 7020), ('acquitted', 7021), ('twilight', 7022), ('overemotional', 7023), ('optimism', 7024), ('inning', 7025), ('calf', 7026), ('stings', 7027), ('narita', 7028), ('menace', 7029), ('alphabet', 7030), ('ruler', 7031), ('freezes', 7032), ('tumbled', 7033), ('dressing', 7034), ('forks', 7035), ('invaded', 7036), ('disagreeing', 7037), ('shelves', 7038), ('generalizations', 7039), ('including', 7040), ('disarm', 7041), ('timer', 7042), ('marvelous', 7043), ('imposter', 7044), ('staggered', 7045), ('selfcentered', 7046), ('19th', 7047), ('opponents', 7048), ('90', 7049), ('sully', 7050), ('wallflower', 7051), ('widow', 7052), ('harshly', 7053), ('narrowly', 7054), ('disgust', 7055), ('psyched', 7056), ('disagrees', 7057), ('beans', 7058), ('strained', 7059), ('gasoline', 7060), ('twostory', 7061), ('romans', 7062), ('entertainer', 7063), ('orville', 7064), ('dependents', 7065), ('miserly', 7066), ('ownership', 7067), ('coordinated', 7068), ('portrait', 7069), ('misleading', 7070), ('doubleparked', 7071), ('sleeves', 7072), ('district', 7073), ('temples', 7074), ('hoarse', 7075), ('riser', 7076), ('excessive', 7077), ('sucks', 7078), ('execute', 7079), ('robots', 7080), ('favors', 7081), ('cupboard', 7082), ('wobbly', 7083), ('beekeeper', 7084), ('25th', 7085), ('spitting', 7086), ('image', 7087), ('palms', 7088), ('legitimate', 7089), ('shuteye', 7090), ('bombing', 7091), ('stalled', 7092), ('sought', 7093), ('sits', 7094), ('waits', 7095), ('regretful', 7096), ('governed', 7097), ('indeed', 7098), ('9th', 7099), ('pigeontoed', 7100), ('pretends', 7101), ('negotiation', 7102), ('emphasis', 7103), ('printer', 7104), ('hostile', 7105), ('processed', 7106), ('thailand', 7107), ('handful', 7108), ('afternoons', 7109), ('shrine', 7110), ('unbeatable', 7111), ('nobel', 7112), ('bladder', 7113), ('cubes', 7114), ('element', 7115), ('calculated', 7116), ('vicinity', 7117), ('delays', 7118), ('meowed', 7119), ('destruction', 7120), ('lettuce', 7121), ('defense', 7122), ('core', 7123), ('departing', 7124), ('brightly', 7125), ('countryside', 7126), ('quiz', 7127), ('autopsy', 7128), ('extinguisher', 7129), ('marrying', 7130), ('cite', 7131), ('fiance', 7132), ('fields', 7133), ('54', 7134), ('mold', 7135), ('imprisoned', 7136), ('hesitation', 7137), ('launch', 7138), ('volcano', 7139), ('apricot', 7140), ('antique', 7141), ('composes', 7142), ('decode', 7143), ('struggling', 7144), ('sharpen', 7145), ('purist', 7146), ('od', 7147), ('billionaire', 7148), ('vip', 7149), ('boasted', 7150), ('billiards', 7151), ('addictive', 7152), ('groggy', 7153), ('drastically', 7154), ('decrease', 7155), ('clashed', 7156), ('watering', 7157), ('brownies', 7158), ('engineers', 7159), ('patrol', 7160), ('beware', 7161), ('pickpockets', 7162), ('resort', 7163), ('achievable', 7164), ('triangle', 7165), ('vet', 7166), ('unrest', 7167), ('ridiculed', 7168), ('immediate', 7169), ('smallest', 7170), ('responding', 7171), ('buzz', 7172), ('inspected', 7173), ('darts', 7174), ('cello', 7175), ('dutyfree', 7176), ('dodge', 7177), ('jar', 7178), ('contradicted', 7179), ('miner', 7180), ('solo', 7181), ('introduction', 7182), ('mindful', 7183), ('reporters', 7184), ('ached', 7185), ('nanny', 7186), ('manpower', 7187), ('protests', 7188), ('wagon', 7189), ('chatterbox', 7190), ('tolerated', 7191), ('reasonably', 7192), ('scale', 7193), ('screen', 7194), ('thirst', 7195), ('whipped', 7196), ('clearer', 7197), ('invent', 7198), ('hangover', 7199), ('typewriter', 7200), ('inventions', 7201), ('ecology', 7202), ('freaked', 7203), ('alongside', 7204), ('learns', 7205), ('oddly', 7206), ('inserted', 7207), ('faucet', 7208), ('exaggerates', 7209), ('praised', 7210), ('lighting', 7211), ('pinned', 7212), ('skunk', 7213), ('guarantor', 7214), ('distinguished', 7215), ('precaution', 7216), ('criticize', 7217), ('armstrong', 7218), ('theories', 7219), ('radios', 7220), ('risen', 7221), ('policies', 7222), ('prefectures', 7223), ('scanner', 7224), ('canned', 7225), ('vomited', 7226), ('melting', 7227), ('hibernate', 7228), ('kilt', 7229), ('dallas', 7230), ('wives', 7231), ('farewell', 7232), ('payroll', 7233), ('handles', 7234), ('auction', 7235), ('length', 7236), ('scorpion', 7237), ('bum', 7238), ('intrusion', 7239), ('sewer', 7240), ('android', 7241), ('tents', 7242), ('vacancy', 7243), ('blacklisted', 7244), ('sneezed', 7245), ('submarine', 7246), ('fatal', 7247), ('tanganyika', 7248), ('heir', 7249), ('passage', 7250), ('operated', 7251), ('mischievous', 7252), ('recover', 7253), ('commitment', 7254), ('partlyfrozen', 7255), ('delaware', 7256), ('guaranteed', 7257), ('ornament', 7258), ('scooter', 7259), ('spoil', 7260), ('adds', 7261), ('selfesteem', 7262), ('breathed', 7263), ('frog', 7264), ('resource', 7265), ('laziness', 7266), ('choking', 7267), ('unfaithful', 7268), ('siren', 7269), ('unhappiness', 7270), ('crawled', 7271), ('stephen', 7272), ('gambled', 7273), ('dazed', 7274), ('mankind', 7275), ('expedition', 7276), ('accountant', 7277), ('journal', 7278), ('edible', 7279), ('scotch', 7280), ('grill', 7281), ('itches', 7282), ('photographed', 7283), ('koalas', 7284), ('apollo', 7285), ('heads', 7286), ('pace', 7287), ('smoothly', 7288), ('celebrities', 7289), ('demoted', 7290), ('fuel', 7291), ('italians', 7292), ('tips', 7293), ('quieter', 7294), ('historian', 7295), ('disguised', 7296), ('shogi', 7297), ('outcome', 7298), ('similarities', 7299), ('otherwise', 7300), ('snowflake', 7301), ('ambiguous', 7302), ('adjust', 7303), ('swallowed', 7304), ('via', 7305), ('expressions', 7306), ('irrational', 7307), ('nightclub', 7308), ('vicious', 7309), ('nostalgic', 7310), ('prettiest', 7311), ('drops', 7312), ('shizuoka', 7313), ('speculating', 7314), ('phrases', 7315), ('sprang', 7316), ('briefly', 7317), ('sincerity', 7318), ('scholarship', 7319), ('horseback', 7320), ('melancholic', 7321), ('nonsmokers', 7322), ('flatter', 7323), ('grams', 7324), ('quiche', 7325), ('infatuation', 7326), ('muttering', 7327), ('chain', 7328), ('skull', 7329), ('assignment', 7330), ('morocco', 7331), ('ramen', 7332), ('shortcomings', 7333), ('updates', 7334), ('johnson', 7335), ('presume', 7336), ('rivals', 7337), ('myths', 7338), ('squashed', 7339), ('standard', 7340), ('danzig', 7341), ('info', 7342), ('excommunicated', 7343), ('swollen', 7344), ('expire', 7345), ('supervising', 7346), ('barefooted', 7347), ('arrests', 7348), ('elizabeth', 7349), ('teammate', 7350), ('perspective', 7351), ('swarms', 7352), ('buttered', 7353), ('backseat', 7354), ('anyways', 7355), ('accommodate', 7356), ('underwear', 7357), ('cages', 7358), ('prolonged', 7359), ('hottest', 7360), ('unscrew', 7361), ('radical', 7362), ('territory', 7363), ('monitor', 7364), ('hatred', 7365), ('congress', 7366), ('generation', 7367), ('senate', 7368), ('bodies', 7369), ('gossip', 7370), ('shellfish', 7371), ('endless', 7372), ('decreasing', 7373), ('stagnant', 7374), ('kidnappers', 7375), ('misjudged', 7376), ('unavoidable', 7377), ('flip', 7378), ('loon', 7379), ('hipster', 7380), ('fantasy', 7381), ('atm', 7382), ('sixtynine', 7383), ('curtain', 7384), ('kites', 7385), ('rib', 7386), ('agenda', 7387), ('obligation', 7388), ('flexed', 7389), ('citation', 7390), ('meager', 7391), ('blimp', 7392), ('emphasize', 7393), ('presentation', 7394), ('distractions', 7395), ('snubbed', 7396), ('steadfast', 7397), ('incentive', 7398), ('piles', 7399), ('theaters', 7400), ('bats', 7401), ('cemetery', 7402), ('98', 7403), ('bombers', 7404), ('napalm', 7405), ('origin', 7406), ('ostriches', 7407), ('toothbrush', 7408), ('celebrity', 7409), ('traditions', 7410), ('honors', 7411), ('kleenex', 7412), ('indebted', 7413), ('preacher', 7414), ('loop', 7415), ('carved', 7416), ('eiffel', 7417), ('superstitious', 7418), ('algebra', 7419), ('openminded', 7420), ('benefit', 7421), ('produce', 7422), ('marched', 7423), ('banker', 7424), ('vary', 7425), ('unperturbed', 7426), ('customs', 7427), ('insanity', 7428), ('slot', 7429), ('acknowledges', 7430), ('journalists', 7431), ('exclude', 7432), ('aardvarks', 7433), ('tango', 7434), ('abating', 7435), ('chopped', 7436), ('recovering', 7437), ('overwhelmed', 7438), ('processor', 7439), ('continuous', 7440), ('exercises', 7441), ('defence', 7442), ('burglar', 7443), ('telegraph', 7444), ('heals', 7445), ('oak', 7446), ('objects', 7447), ('bass', 7448), ('mink', 7449), ('sail', 7450), ('tragedy', 7451), ('participants', 7452), ('compromised', 7453), ('dozing', 7454), ('bushes', 7455), ('occupation', 7456), ('faced', 7457), ('pound', 7458), ('newcomer', 7459), ('overnight', 7460), ('conserve', 7461), ('ethics', 7462), ('strings', 7463), ('rivers', 7464), ('irritating', 7465), ('surviving', 7466), ('coffees', 7467), ('chill', 7468), ('honorable', 7469), ('sneeze', 7470), ('packs', 7471), ('puppies', 7472), ('2001', 7473), ('burgers', 7474), ('pine', 7475), ('host', 7476), ('snacks', 7477), ('forgives', 7478), ('unrealistic', 7479), ('cassino', 7480), ('seasons', 7481), ('250', 7482), ('715', 7483), ('33', 7484), ('underground', 7485), ('bundle', 7486), ('gracefully', 7487), ('unthinkable', 7488), ('waffles', 7489), ('powers', 7490), ('teens', 7491), ('cellulite', 7492), ('replacing', 7493), ('bias', 7494), ('amsterdam', 7495), ('transplant', 7496), ('phase', 7497), ('chores', 7498), ('thicker', 7499), ('qualities', 7500), ('peroxide', 7501), ('gay', 7502), ('mentor', 7503), ('canaries', 7504), ('empire', 7505), ('hassle', 7506), ('upper', 7507), ('stammered', 7508), ('teaspoons', 7509), ('violation', 7510), ('pin', 7511), ('hailing', 7512), ('bookkeeper', 7513), ('walker', 7514), ('surly', 7515), ('unafraid', 7516), ('defending', 7517), ('jaw', 7518), ('tablecloth', 7519), ('vegans', 7520), ('unimportant', 7521), ('overjoyed', 7522), ('stepsister', 7523), ('cellar', 7524), ('pigged', 7525), ('exports', 7526), ('chile', 7527), ('mischief', 7528), ('romeo', 7529), ('juliet', 7530), ('basque', 7531), ('assess', 7532), ('contractor', 7533), ('informal', 7534), ('biographies', 7535), ('depart', 7536), ('oceans', 7537), ('tenacious', 7538), ('collar', 7539), ('assassination', 7540), ('remedy', 7541), ('supporters', 7542), ('dialog', 7543), ('caesar', 7544), ('mute', 7545), ('marbles', 7546), ('soapy', 7547), ('formality', 7548), ('transmitted', 7549), ('cartoons', 7550), ('sisterinlaw', 7551), ('mummy', 7552), ('ego', 7553), ('bruised', 7554), ('linguist', 7555), ('tremendously', 7556), ('wheelchair', 7557), ('creams', 7558), ('pilots', 7559), ('argues', 7560), ('chestnuts', 7561), ('sicker', 7562), ('comparison', 7563), ('passenger', 7564), ('lear', 7565), ('traumatic', 7566), ('string', 7567), ('mislead', 7568), ('wing', 7569), ('overpriced', 7570), ('giraffe', 7571), ('1982', 7572), ('circus', 7573), ('raccoons', 7574), ('cholesterol', 7575), ('improvise', 7576), ('mixture', 7577), ('gases', 7578), ('camper', 7579), ('knuckles', 7580), ('psychiatrist', 7581), ('shore', 7582), ('welltrained', 7583), ('wellsupplied', 7584), ('airline', 7585), ('unlike', 7586), ('sioux', 7587), ('1868', 7588), ('eraser', 7589), ('grandsons', 7590), ('scrub', 7591), ('soviet', 7592), ('tons', 7593), ('gated', 7594), ('partnership', 7595), ('federal', 7596), ('republic', 7597), ('patriot', 7598), ('hypochondriac', 7599), ('conceal', 7600), ('klava', 7601), ('settlement', 7602), ('originals', 7603), ('commonlaw', 7604), ('cider', 7605), ('peacock', 7606), ('twister', 7607), ('brazilian', 7608), ('cable', 7609), ('admires', 7610), ('avoidable', 7611), ('machete', 7612), ('tuberculosis', 7613), ('stilts', 7614), ('snatched', 7615), ('stripes', 7616), ('atrocious', 7617), ('wrestlers', 7618), ('eerie', 7619), ('inventor', 7620), ('subtract', 7621), ('multiply', 7622), ('noodles', 7623), ('urgently', 7624), ('disclaimed', 7625), ('foreseen', 7626), ('broadcast', 7627), ('mailed', 7628), ('creeps', 7629), ('domesticated', 7630), ('egyptians', 7631), ('cloning', 7632), ('pack', 7633), ('hamlet', 7634), ('lucid', 7635), ('composed', 7636), ('detour', 7637), ('taco', 7638), ('blanks', 7639), ('viral', 7640), ('helium', 7641), ('warmhearted', 7642), ('variety', 7643), ('decides', 7644), ('rebuild', 7645), ('bewildered', 7646), ('scholar', 7647), ('talker', 7648), ('evacuate', 7649), ('eightyearold', 7650), ('autism', 7651), ('goodnight', 7652), ('managing', 7653), ('goggles', 7654), ('earphones', 7655), ('lays', 7656), ('unaffected', 7657), ('ros', 7658), ('vigilant', 7659), ('infinite', 7660), ('lyric', 7661), ('lumpy', 7662), ('disqualified', 7663), ('blinking', 7664), ('literal', 7665), ('throughout', 7666), ('newly', 7667), ('granddaughters', 7668), ('receives', 7669), ('pko', 7670), ('trivial', 7671), ('contacts', 7672), ('jabber', 7673), ('prenup', 7674), ('acrylic', 7675), ('nomination', 7676), ('waterproof', 7677), ('reflected', 7678), ('dinners', 7679), ('whisper', 7680), ('gratifying', 7681), ('sahara', 7682), ('authentic', 7683), ('birthplace', 7684), ('weekdays', 7685), ('preferably', 7686), ('maria', 7687), ('bliss', 7688), ('marks', 7689), ('context', 7690), ('participating', 7691), ('breastfeeding', 7692), ('strongwilled', 7693), ('consumes', 7694), ('foul', 7695), ('bodybuilders', 7696), ('appreciates', 7697), ('heats', 7698), ('posed', 7699), ('scenic', 7700), ('omelette', 7701), ('stroller', 7702), ('sukiyaki', 7703), ('arresting', 7704), ('ukraine', 7705), ('surreal', 7706), ('raft', 7707), ('lunatic', 7708), ('coldblooded', 7709), ('deciphered', 7710), ('nursery', 7711), ('boxing', 7712), ('caves', 7713), ('perspire', 7714), ('shepherd', 7715), ('charles', 7716), ('efficiency', 7717), ('unsatisfied', 7718), ('exploding', 7719), ('gondolier', 7720), ('lets', 7721), ('tremendous', 7722), ('cucumber', 7723), ('pursue', 7724), ('aardvark', 7725), ('zz', 7726), ('gripped', 7727), ('extorted', 7728), ('exboyfriends', 7729), ('itinerary', 7730), ('administration', 7731), ('kisses', 7732), ('cambridge', 7733), ('steaks', 7734), ('synagogue', 7735), ('bookmarked', 7736), ('sausage', 7737), ('ambush', 7738), ('muscle', 7739), ('lilies', 7740), ('mentally', 7741), ('fourteen', 7742), ('evade', 7743), ('metaphor', 7744), ('cursing', 7745), ('festivals', 7746), ('convincing', 7747), ('cooler', 7748), ('managers', 7749), ('newlyweds', 7750), ('characters', 7751), ('pinocchio', 7752), ('jack', 7753), ('inquisitive', 7754), ('presentable', 7755), ('elitist', 7756), ('natives', 7757), ('soaked', 7758), ('accomplishment', 7759), ('fictional', 7760), ('folks', 7761), ('chimpanzees', 7762), ('bogged', 7763), ('birthdays', 7764), ('weary', 7765), ('auditorium', 7766), ('handwritten', 7767), ('saddle', 7768), ('margarita', 7769), ('wiggled', 7770), ('truthfully', 7771), ('bashful', 7772), ('tractors', 7773), ('exaggeration', 7774), ('goahead', 7775), ('threepage', 7776), ('fixes', 7777), ('preferred', 7778), ('vaccinated', 7779), ('chauffeur', 7780), ('landline', 7781), ('epidemic', 7782), ('invitations', 7783), ('interpretation', 7784), ('download', 7785), ('confide', 7786), ('wart', 7787), ('kindest', 7788), ('bigheaded', 7789), ('quitter', 7790), ('noncaffeinated', 7791), ('dismayed', 7792), ('unit', 7793), ('gains', 7794), ('stashed', 7795), ('enjoyable', 7796), ('bluff', 7797), ('cargo', 7798), ('vessel', 7799), ('startling', 7800), ('freshmen', 7801), ('faq', 7802), ('unhealthy', 7803), ('butchers', 7804), ('stepping', 7805), ('procedures', 7806), ('whimpering', 7807), ('directness', 7808), ('hunted', 7809), ('defenses', 7810), ('mayonnaise', 7811), ('jurisdiction', 7812), ('horoscope', 7813), ('spin', 7814), ('twothirds', 7815), ('resulted', 7816), ('soda', 7817), ('decaf', 7818), ('offense', 7819), ('laidback', 7820), ('faked', 7821), ('wellliked', 7822), ('touches', 7823), ('deleted', 7824), ('mushroom', 7825), ('weakling', 7826), ('olive', 7827), ('obeys', 7828), ('thirteenth', 7829), ('sow', 7830), ('laboratory', 7831), ('shipment', 7832), ('kendo', 7833), ('showroom', 7834), ('meds', 7835), ('disabled', 7836), ('wonders', 7837), ('mechanical', 7838), ('corporation', 7839), ('plums', 7840), ('nixon', 7841), ('anorexic', 7842), ('socrates', 7843), ('includes', 7844), ('sciences', 7845), ('extinguishing', 7846), ('pouting', 7847), ('dire', 7848), ('mangoes', 7849), ('seaside', 7850), ('curly', 7851), ('blizzard', 7852), ('medium', 7853), ('cables', 7854), ('16th', 7855), ('schoolgirl', 7856), ('publish', 7857), ('restrain', 7858), ('types', 7859), ('urban', 7860), ('disagreement', 7861), ('acquire', 7862), ('oneself', 7863), ('reviews', 7864), ('aspirations', 7865), ('protesters', 7866), ('disgraced', 7867), ('hypnotherapy', 7868), ('stranded', 7869), ('cicada', 7870), ('wad', 7871), ('hedgehogs', 7872), ('footsteps', 7873), ('progressive', 7874), ('drinkable', 7875), ('loo', 7876), ('paddling', 7877), ('hungarian', 7878), ('replacement', 7879), ('stuntman', 7880), ('observatory', 7881), ('steam', 7882), ('spill', 7883), ('awaken', 7884), ('cardiff', 7885), ('meteor', 7886), ('railways', 7887), ('column', 7888), ('comedian', 7889), ('downcast', 7890), ('jealousy', 7891), ('workman', 7892), ('pruning', 7893), ('encouragement', 7894), ('graham', 7895), ('600', 7896), ('nosy', 7897), ('acquired', 7898), ('prank', 7899), ('upsets', 7900), ('deck', 7901), ('caterpillar', 7902), ('achievement', 7903), ('classifying', 7904), ('rejection', 7905), ('peculiar', 7906), ('suppliers', 7907), ('handkerchiefs', 7908), ('cardboard', 7909), ('painstakingly', 7910), ('tights', 7911), ('foregone', 7912), ('vocation', 7913), ('profitable', 7914), ('eavesdrop', 7915), ('automatic', 7916), ('feature', 7917), ('keyboardist', 7918), ('upbeat', 7919), ('considerable', 7920), ('maps', 7921), ('fingernails', 7922), ('extend', 7923), ('channels', 7924), ('earliest', 7925), ('13yearold', 7926), ('shone', 7927), ('baptized', 7928), ('cockroach', 7929), ('yells', 7930), ('halfbaked', 7931), ('rephrase', 7932), ('pickup', 7933), ('swords', 7934), ('entertaining', 7935), ('1995', 7936), ('spices', 7937), ('contemplated', 7938), ('drained', 7939), ('unicycle', 7940), ('exwives', 7941), ('barbeque', 7942), ('llama', 7943), ('youtry', 7944), ('pronouncing', 7945), ('thrifty', 7946), ('unpacking', 7947), ('schooling', 7948), ('sorts', 7949), ('virtually', 7950), ('1996', 7951), ('gossips', 7952), ('engineering', 7953), ('initially', 7954), ('exemplary', 7955), ('oversleep', 7956), ('incidents', 7957), ('domestic', 7958), ('unfit', 7959), ('blender', 7960), ('correspond', 7961), ('nest', 7962), ('candlelight', 7963), ('remarried', 7964), ('cults', 7965), ('tournament', 7966), ('blossoms', 7967), ('compressed', 7968), ('colorado', 7969), ('caller', 7970), ('lord', 7971), ('apron', 7972), ('significance', 7973), ('crop', 7974), ('fur', 7975), ('predictions', 7976), ('procrastinating', 7977), ('nave', 7978), ('incentives', 7979), ('prophet', 7980), ('thirtieth', 7981), ('turnips', 7982), ('gravitation', 7983), ('reborn', 7984), ('tricycle', 7985), ('possession', 7986), ('kim', 7987), ('ilsung', 7988), ('masterpiece', 7989), ('encountered', 7990), ('repairing', 7991), ('sharply', 7992), ('doughnut', 7993), ('intruded', 7994), ('reference', 7995), ('moderately', 7996), ('alarming', 7997), ('chatted', 7998), ('alibis', 7999), ('attorneys', 8000), ('emptied', 8001), ('lifted', 8002), ('englishman', 8003), ('squabbling', 8004), ('pneumonia', 8005), ('amuse', 8006), ('judas', 8007), ('christ', 8008), ('folder', 8009), ('bonaparte', 8010), ('maintained', 8011), ('booth', 8012), ('mowing', 8013), ('germans', 8014), ('cents', 8015), ('freckles', 8016), ('20000', 8017), ('gloated', 8018), ('finland', 8019), ('arson', 8020), ('obtained', 8021), ('robin', 8022), ('strive', 8023), ('germs', 8024), ('bonds', 8025), ('unforgivable', 8026), ('noticeably', 8027), ('adjacent', 8028), ('johnny', 8029), ('depp', 8030), ('concentration', 8031), ('holler', 8032), ('severely', 8033), ('blackmailer', 8034), ('classic', 8035), ('moist', 8036), ('toast', 8037), ('kangaroo', 8038), ('monks', 8039), ('armpits', 8040), ('triggered', 8041), ('unsuccessful', 8042), ('seize', 8043), ('melons', 8044), ('inhumane', 8045), ('satisfaction', 8046), ('mathematical', 8047), ('et', 8048), ('needles', 8049), ('ostrich', 8050), ('spacious', 8051), ('denounced', 8052), ('punctured', 8053), ('baker', 8054), ('offers', 8055), ('lifelong', 8056), ('crosses', 8057), ('reception', 8058), ('hamper', 8059), ('remodel', 8060), ('keeper', 8061), ('revolution', 8062), ('edited', 8063), ('chili', 8064), ('1988', 8065), ('spades', 8066), ('extravagant', 8067), ('experiments', 8068), ('thunderstorms', 8069), ('device', 8070), ('altogether', 8071), ('pointblank', 8072), ('gamblers', 8073), ('bleeds', 8074), ('prevail', 8075), ('maze', 8076), ('belly', 8077), ('phenomenal', 8078), ('salmon', 8079), ('lukewarm', 8080), ('tanned', 8081), ('cent', 8082), ('leftover', 8083), ('flammable', 8084), ('sneaked', 8085), ('dash', 8086), ('medicines', 8087), ('queasy', 8088), ('12', 8089), ('smog', 8090), ('swiss', 8091), ('proceeded', 8092), ('void', 8093), ('crashing', 8094), ('quickened', 8095), ('redheads', 8096), ('commercial', 8097), ('unrelated', 8098), ('edge', 8099), ('provisions', 8100), ('male', 8101), ('joe', 8102), ('bathing', 8103), ('chatty', 8104), ('sticker', 8105), ('100000', 8106), ('1st', 8107), ('grinning', 8108), ('trading', 8109), ('thirdyear', 8110), ('pasteur', 8111), ('reptiles', 8112), ('successor', 8113), ('fails', 8114), ('reimbursed', 8115), ('outfit', 8116), ('lunar', 8117), ('bathe', 8118), ('uninvited', 8119), ('zezo', 8120), ('feminine', 8121), ('ferry', 8122), ('yachts', 8123), ('slam', 8124), ('intolerable', 8125), ('omitted', 8126), ('blinked', 8127), ('amounts', 8128), ('1642', 8129), ('abel', 8130), ('tasman', 8131), ('tasmania', 8132), ('fishmonger', 8133), ('levee', 8134), ('sweltering', 8135), ('nonplussed', 8136), ('photocopier', 8137), ('threeyearold', 8138), ('topping', 8139), ('audiobook', 8140), ('sneered', 8141), ('mini', 8142), ('desires', 8143), ('1130', 8144), ('astrologer', 8145), ('grated', 8146), ('undefeated', 8147), ('mocked', 8148), ('memorization', 8149), ('formulas', 8150), ('19', 8151), ('persecuted', 8152), ('belched', 8153), ('posting', 8154), ('vanilla', 8155), ('riches', 8156), ('idle', 8157), ('subpoenaed', 8158), ('neatly', 8159), ('honda', 8160), ('plotting', 8161), ('showers', 8162), ('barack', 8163), ('mammals', 8164), ('equipped', 8165), ('indonesian', 8166), ('probe', 8167), ('con', 8168), ('glitters', 8169), ('quoted', 8170), ('pretzels', 8171), ('prompt', 8172), ('consist', 8173), ('handkerchief', 8174), ('prevention', 8175), ('aggression', 8176), ('freely', 8177), ('englishjapanese', 8178), ('corpus', 8179), ('ashes', 8180), ('spinning', 8181), ('incapable', 8182), ('shameful', 8183), ('fireplace', 8184), ('contradicting', 8185), ('taxdeductible', 8186), ('suey', 8187), ('unmanageable', 8188), ('voluntarily', 8189), ('bankruptcy', 8190), ('liliuokalani', 8191), ('peppered', 8192), ('jargon', 8193), ('honolulu', 8194), ('approaches', 8195), ('hospitalized', 8196), ('prophecy', 8197), ('strangled', 8198), ('fuzzy', 8199), ('pros', 8200), ('cons', 8201), ('halfsister', 8202), ('behaves', 8203), ('circles', 8204), ('skeptic', 8205), ('controls', 8206), ('unofficially', 8207), ('deafening', 8208), ('rows', 8209), ('ptsd', 8210), ('pearls', 8211), ('insufficient', 8212), ('bull', 8213), ('asians', 8214), ('eyepatch', 8215), ('reset', 8216), ('odometer', 8217), ('accelerated', 8218), ('rhetorical', 8219), ('basically', 8220), ('disgraceful', 8221), ('knackered', 8222), ('losses', 8223), ('employment', 8224), ('soil', 8225), ('measurements', 8226), ('explosions', 8227), ('gum', 8228), ('cavities', 8229), ('mammal', 8230), ('flame', 8231), ('corrupt', 8232), ('hell', 8233), ('permanent', 8234), ('bowls', 8235), ('congratulate', 8236), ('sprained', 8237), ('unused', 8238), ('absurdly', 8239), ('inflatable', 8240), ('fare', 8241), ('stream', 8242), ('cookbook', 8243), ('hornets', 8244), ('galileo', 8245), ('slowpoke', 8246), ('fuss', 8247), ('putt', 8248), ('keyboard', 8249), ('centers', 8250), ('healed', 8251), ('drunken', 8252), ('unbearably', 8253), ('regardless', 8254), ('travesty', 8255), ('vermont', 8256), ('armenia', 8257), ('liquid', 8258), ('maintain', 8259), ('prenuptial', 8260), ('angola', 8261), ('felon', 8262), ('firmly', 8263), ('blondes', 8264), ('impact', 8265), ('flannel', 8266), ('backup', 8267), ('donation', 8268), ('orient', 8269), ('libraries', 8270), ('greet', 8271), ('tomfoolery', 8272), ('overcooked', 8273), ('anxiety', 8274), ('manufactures', 8275), ('lantern', 8276), ('manna', 8277), ('rank', 8278), ('lieutenant', 8279), ('muslims', 8280), ('remaining', 8281), ('retires', 8282), ('yearold', 8283), ('lavish', 8284), ('disobeyed', 8285), ('shrimp', 8286), ('videogames', 8287), ('scarce', 8288), ('tarantula', 8289), ('callous', 8290), ('moons', 8291), ('1600s', 8292), ('audition', 8293), ('indecisive', 8294), ('flavors', 8295), ('baboon', 8296), ('ancestors', 8297), ('detention', 8298), ('pleasures', 8299), ('crutches', 8300), ('bagpipes', 8301), ('comet', 8302), ('shikoku', 8303), ('teenage', 8304), ('payment', 8305), ('rack', 8306), ('saver', 8307), ('handy', 8308), ('heroine', 8309), ('1979', 8310), ('deadbeat', 8311), ('wisest', 8312), ('gauge', 8313), ('godforsaken', 8314), ('metals', 8315), ('omit', 8316), ('owning', 8317), ('phd', 8318), ('collaboration', 8319), ('farms', 8320), ('roar', 8321), ('loneliness', 8322), ('cellmate', 8323), ('agnostic', 8324), ('sustained', 8325), ('utmost', 8326), ('bonkers', 8327), ('scalpel', 8328), ('youngsters', 8329), ('spectators', 8330), ('cheers', 8331), ('leaking', 8332), ('reloaded', 8333), ('payments', 8334), ('disputing', 8335), ('colosseum', 8336), ('bearer', 8337), ('teas', 8338), ('pedestrian', 8339), ('downsides', 8340), ('geology', 8341), ('appalled', 8342), ('piccolo', 8343), ('nikko', 8344), ('stated', 8345), ('survival', 8346), ('amounted', 8347), ('improvements', 8348), ('hemisphere', 8349), ('shuffle', 8350), ('combined', 8351), ('shaped', 8352), ('1955', 8353), ('suntan', 8354), ('negotiable', 8355), ('scenario', 8356), ('tangerines', 8357), ('viruses', 8358), ('sixthirty', 8359), ('50000', 8360), ('tuna', 8361), ('jug', 8362), ('hippopotamuses', 8363), ('sunk', 8364), ('meditate', 8365), ('sharpest', 8366), ('expose', 8367), ('denver', 8368), ('montreal', 8369), ('selfservice', 8370), ('ignores', 8371), ('presumed', 8372), ('fanfare', 8373), ('blooming', 8374), ('accidental', 8375), ('pasty', 8376), ('gown', 8377), ('grilled', 8378), ('meek', 8379), ('dig', 8380), ('electrocuted', 8381), ('sandcastle', 8382), ('phenomenon', 8383), ('management', 8384), ('objectives', 8385), ('penmanship', 8386), ('manslaughter', 8387), ('harry', 8388), ('potter', 8389), ('seawater', 8390), ('cola', 8391), ('shutting', 8392), ('reelected', 8393), ('arts', 8394), ('strengths', 8395), ('1603', 8396), ('outlive', 8397), ('uncommunicative', 8398), ('bulbs', 8399), ('camel', 8400), ('knocking', 8401), ('unfamiliar', 8402), ('stepmother', 8403), ('skilled', 8404), ('stuffy', 8405), ('pipes', 8406), ('dimension', 8407), ('bolt', 8408), ('threeday', 8409), ('beaver', 8410), ('mental', 8411), ('breadwinner', 8412), ('cuff', 8413), ('flesh', 8414), ('caviar', 8415), ('madly', 8416), ('translations', 8417), ('jellyfish', 8418), ('links', 8419), ('falsified', 8420), ('principle', 8421), ('directions', 8422), ('nurses', 8423), ('tempting', 8424), ('skied', 8425), ('einstein', 8426), ('junior', 8427), ('withered', 8428), ('14', 8429), ('fluids', 8430), ('format', 8431), ('leopard', 8432), ('watchful', 8433), ('digitized', 8434), ('emailed', 8435), ('marshmallows', 8436), ('burma', 8437), ('acreage', 8438), ('hiccups', 8439), ('insincere', 8440), ('froze', 8441), ('disclosed', 8442), ('hazelnuts', 8443), ('incomplete', 8444), ('consulting', 8445), ('landscapes', 8446), ('nieces', 8447), ('occasions', 8448), ('imperfection', 8449), ('fascinate', 8450), ('thrift', 8451), ('expand', 8452), ('delivers', 8453), ('rockets', 8454), ('zombies', 8455), ('alligator', 8456), ('ballpark', 8457), ('iv', 8458), ('spatula', 8459), ('glove', 8460), ('sugary', 8461), ('discouraging', 8462), ('dump', 8463), ('pleasantly', 8464), ('duet', 8465), ('revived', 8466), ('fiveminute', 8467), ('stripped', 8468), ('nashville', 8469), ('sew', 8470), ('turks', 8471), ('determine', 8472), ('punches', 8473), ('contained', 8474), ('announcer', 8475), ('racial', 8476), ('discrimination', 8477), ('saffron', 8478), ('fuels', 8479), ('greed', 8480), ('tab', 8481), ('seatbelts', 8482), ('pseudoscience', 8483), ('dorm', 8484), ('slowed', 8485), ('swans', 8486), ('un', 8487), ('hustle', 8488), ('negatively', 8489), ('soldering', 8490), ('bizarre', 8491), ('wounds', 8492), ('pianos', 8493), ('balalaika', 8494), ('banquet', 8495), ('odor', 8496), ('revolve', 8497), ('sum', 8498), ('sunsets', 8499), ('subordinates', 8500), ('inhabitants', 8501), ('sweaters', 8502), ('pudgy', 8503), ('eyebrows', 8504), ('vacancies', 8505), ('thinker', 8506), ('booed', 8507), ('credits', 8508), ('goofy', 8509), ('medications', 8510), ('bachelor', 8511), ('kidney', 8512), ('mutton', 8513), ('displayed', 8514), ('spit', 8515), ('milkman', 8516), ('remodeling', 8517), ('attempts', 8518), ('limitless', 8519), ('2008', 8520), ('deliberately', 8521), ('900', 8522), ('overthrown', 8523), ('plaid', 8524), ('comforted', 8525), ('helena', 8526), ('sexist', 8527), ('gossiping', 8528), ('appearing', 8529), ('60', 8530), ('sketching', 8531), ('scorned', 8532), ('accordion', 8533), ('tours', 8534), ('trend', 8535), ('craziest', 8536), ('fights', 8537), ('bye', 8538), ('michael', 8539), ('clichs', 8540), ('bandages', 8541), ('orthodontist', 8542), ('parachute', 8543), ('flipped', 8544), ('prayers', 8545), ('poking', 8546), ('slide', 8547), ('unlock', 8548), ('sonnets', 8549), ('copied', 8550), ('favourite', 8551), ('liters', 8552), ('liking', 8553), ('deadly', 8554), ('loveable', 8555), ('jailed', 8556), ('trumpedup', 8557), ('fortnight', 8558), ('trunks', 8559), ('electronic', 8560), ('historic', 8561), ('scuttlebutt', 8562), ('aggravated', 8563), ('medic', 8564), ('misprints', 8565), ('banished', 8566), ('angrily', 8567), ('tiki', 8568), ('ordinarily', 8569), ('motherinlaw', 8570), ('alright', 8571), ('gouging', 8572), ('sensation', 8573), ('expectantly', 8574), ('aptitude', 8575), ('preventable', 8576), ('freelancer', 8577), ('sandbags', 8578), ('lesser', 8579), ('evils', 8580), ('freshwater', 8581), ('comedians', 8582), ('strengthens', 8583), ('unpunished', 8584), ('clam', 8585), ('chowder', 8586), ('downloading', 8587), ('chews', 8588), ('summary', 8589), ('hopefully', 8590), ('grapefruit', 8591), ('braces', 8592), ('forged', 8593), ('biked', 8594), ('lap', 8595), ('1949', 8596), ('hustling', 8597), ('sumter', 8598), ('accustom', 8599), ('ebay', 8600), ('attacker', 8601), ('summertime', 8602), ('grownups', 8603), ('unconstitutional', 8604), ('videos', 8605), ('cavalry', 8606), ('macadamia', 8607), ('ushered', 8608), ('cracks', 8609), ('amid', 8610), ('threeyear', 8611), ('dustcovered', 8612), ('sinister', 8613), ('haiku', 8614), ('hives', 8615), ('miners', 8616), ('eyewitness', 8617), ('cocacola', 8618), ('imposed', 8619), ('capsized', 8620), ('bellyaching', 8621), ('revisions', 8622), ('exuberant', 8623), ('alphabetical', 8624), ('hawaiian', 8625), ('simultaneous', 8626), ('applauding', 8627), ('calcutta', 8628), ('verbs', 8629), ('spam', 8630), ('microchips', 8631), ('pill', 8632), ('malaria', 8633), ('unshaken', 8634), ('rumored', 8635), ('communications', 8636), ('bid', 8637), ('plunged', 8638), ('ingredient', 8639), ('appetizing', 8640), ('jefferson', 8641), ('1809', 8642), ('resolve', 8643), ('commanders', 8644), ('weeds', 8645), ('boredom', 8646), ('muttered', 8647), ('foretell', 8648), ('deterred', 8649), ('fishermen', 8650), ('summit', 8651), ('sheepish', 8652), ('vividly', 8653), ('nineteen', 8654), ('1763', 8655), ('chapel', 8656), ('lifting', 8657), ('weights', 8658), ('inch', 8659), ('crouched', 8660), ('skeleton', 8661), ('dandruff', 8662), ('laminated', 8663), ('explicitly', 8664), ('nod', 8665), ('digest', 8666), ('zapped', 8667), ('defibrillator', 8668), ('prior', 8669), ('sociologist', 8670), ('retreated', 8671), ('caracas', 8672), ('notion', 8673), ('ocd', 8674), ('aerobics', 8675), ('overtake', 8676), ('dispute', 8677), ('wrongs', 8678), ('particularily', 8679), ('adored', 8680), ('planetarium', 8681), ('cesar', 8682), ('chavez', 8683), ('1993', 8684), ('sixtysix', 8685), ('avenged', 8686), ('rematch', 8687), ('ostracized', 8688), ('swapped', 8689), ('peculiarities', 8690), ('cupcakes', 8691), ('slap', 8692), ('catholics', 8693), ('heartwarming', 8694), ('emerged', 8695), ('slope', 8696), ('birdcage', 8697), ('retain', 8698), ('anchored', 8699), ('jock', 8700), ('bestliked', 8701), ('barbarians', 8702), ('dehydrated', 8703), ('dissatisfaction', 8704), ('earmuffs', 8705), ('faintest', 8706), ('primarily', 8707), ('considers', 8708), ('preferable', 8709), ('coroner', 8710), ('pangs', 8711), ('jambalaya', 8712), ('flexibility', 8713), ('zoos', 8714), ('prisons', 8715), ('monopoly', 8716), ('clash', 8717), ('furnish', 8718), ('robe', 8719), ('racked', 8720), ('konrad', 8721), ('adenauer', 8722), ('chancellor', 8723), ('dishwater', 8724), ('cuban', 8725), ('wax', 8726), ('piled', 8727), ('owing', 8728), ('freaking', 8729), ('motorboat', 8730), ('attribute', 8731), ('dioxin', 8732), ('plural', 8733), ('painkiller', 8734), ('dreamt', 8735), ('hippie', 8736), ('bouncer', 8737), ('scripts', 8738), ('zebras', 8739), ('implements', 8740), ('stockings', 8741), ('piggy', 8742), ('findings', 8743), ('knickknacks', 8744), ('printing', 8745), ('carriages', 8746), ('rallied', 8747), ('morphine', 8748), ('retaliate', 8749), ('ditch', 8750), ('devout', 8751), ('grotesque', 8752), ('satellite', 8753), ('orbit', 8754), ('unsung', 8755), ('26', 8756), ('chanting', 8757), ('nitrogen', 8758), ('musicologist', 8759), ('relation', 8760), ('festive', 8761), ('gibberish', 8762), ('ironclad', 8763), ('icelandic', 8764), ('doves', 8765), ('replying', 8766), ('emailing', 8767), ('institutions', 8768), ('reboot', 8769), ('martini', 8770), ('evaporated', 8771), ('anagrams', 8772), ('fundamental', 8773), ('universities', 8774), ('coaches', 8775), ('martin', 8776), ('administrative', 8777), ('soles', 8778), ('orchard', 8779), ('goodness', 8780), ('1500', 8781), ('favorites', 8782), ('countdown', 8783), ('hoot', 8784), ('suppress', 8785), ('debated', 8786), ('undeterred', 8787), ('pilaf', 8788), ('eulogy', 8789), ('submit', 8790), ('parole', 8791), ('beasts', 8792), ('antagonize', 8793), ('deleting', 8794), ('brie', 8795), ('thankyou', 8796), ('overused', 8797), ('confront', 8798), ('termites', 8799), ('conquer', 8800), ('bowling', 8801), ('hurricane', 8802), ('fees', 8803), ('volunteering', 8804), ('trifles', 8805), ('norwegian', 8806), ('criticisms', 8807), ('tiptoed', 8808), ('anticipating', 8809), ('scoffed', 8810), ('gunpowder', 8811), ('composure', 8812), ('delinquency', 8813), ('resolution', 8814), ('negotiating', 8815), ('greenhouse', 8816), ('cassette', 8817), ('hovered', 8818), ('excessively', 8819), ('proficient', 8820), ('marksman', 8821), ('quantities', 8822), ('callas', 8823), ('indigestion', 8824), ('intimacy', 8825), ('amateurs', 8826), ('untranslated', 8827), ('ancestry', 8828), ('ignition', 8829), ('neglect', 8830), ('reaches', 8831), ('eels', 8832), ('cannibals', 8833), ('hungover', 8834), ('bucked', 8835), ('vomit', 8836), ('arose', 8837), ('variants', 8838), ('hallucinate', 8839), ('apologetic', 8840), ('decreased', 8841), ('expendable', 8842), ('unpaid', 8843), ('obsolete', 8844), ('rhyme', 8845), ('knitted', 8846), ('hammering', 8847), ('turban', 8848), ('exceeded', 8849), ('homicide', 8850), ('redundant', 8851), ('pressured', 8852), ('soared', 8853), ('moore', 8854), ('sacrificing', 8855), ('summons', 8856), ('issued', 8857), ('dachshund', 8858), ('nutmeg', 8859), ('gulliver', 8860), ('phony', 8861), ('similarly', 8862), ('confirms', 8863), ('inability', 8864), ('promptly', 8865), ('stereotypes', 8866), ('candid', 8867), ('schoolteacher', 8868), ('beggars', 8869), ('welldressed', 8870), ('unsettled', 8871), ('extinguished', 8872), ('trimmed', 8873), ('specializes', 8874), ('disorders', 8875), ('earache', 8876), ('globe', 8877), ('copenhagen', 8878), ('celery', 8879), ('intellectual', 8880), ('defective', 8881), ('glowed', 8882), ('daybreak', 8883), ('improbable', 8884), ('toying', 8885), ('gondola', 8886), ('actresses', 8887), ('bodybuilder', 8888), ('deluding', 8889), ('monster', 8890), ('tempt', 8891), ('manufacture', 8892), ('manuals', 8893), ('willpower', 8894), ('badtempered', 8895), ('gunman', 8896), ('ruby', 8897), ('chuckling', 8898), ('dined', 8899), ('feasible', 8900), ('mitsubishi', 8901), ('merged', 8902), ('snowflakes', 8903), ('confiscate', 8904), ('courtroom', 8905), ('handmade', 8906), ('perth', 8907), ('1987', 8908), ('cruelty', 8909), ('bulky', 8910), ('traps', 8911), ('mules', 8912), ('autobiography', 8913), ('fortyfive', 8914), ('surfer', 8915), ('abuses', 8916), ('quesadillas', 8917), ('thorns', 8918), ('bloodshed', 8919), ('extortion', 8920), ('interchangeable', 8921), ('launching', 8922), ('twain', 8923), ('grumble', 8924), ('resemblance', 8925), ('uncanny', 8926), ('preconceived', 8927), ('pilgrims', 8928), ('lands', 8929), ('cringed', 8930), ('onebedroom', 8931), ('wagging', 8932), ('emotionally', 8933), ('jaguar', 8934), ('duplicate', 8935), ('creep', 8936), ('1962', 8937), ('algeria', 8938), ('teak', 8939), ('smuggler', 8940), ('simulation', 8941), ('picassos', 8942), ('skies', 8943), ('layer', 8944), ('doomed', 8945), ('despondent', 8946), ('joint', 8947), ('cusses', 8948), ('procrastinate', 8949), ('microwaving', 8950), ('snowstorm', 8951), ('skillful', 8952), ('excitement', 8953), ('reputable', 8954), ('bulls', 8955), ('hits', 8956), ('radium', 8957), ('pizzeria', 8958), ('ouch', 8959), ('hyperventilating', 8960), ('roaring', 8961), ('belligerent', 8962), ('moderation', 8963), ('paella', 8964), ('deceitful', 8965), ('charmed', 8966), ('tragedies', 8967), ('fee', 8968), ('skeptics', 8969), ('copying', 8970), ('pluto', 8971), ('pricing', 8972), ('holy', 8973), ('hopelessly', 8974), ('impoverished', 8975), ('pervert', 8976), ('ticking', 8977), ('rendered', 8978), ('prohibiting', 8979), ('pyramids', 8980), ('curves', 8981), ('tuba', 8982), ('affect', 8983), ('dialysis', 8984), ('beeped', 8985), ('antsy', 8986), ('converse', 8987), ('joyous', 8988), ('undressed', 8989), ('generate', 8990), ('tiptoes', 8991), ('accessed', 8992), ('rotting', 8993), ('jumps', 8994), ('speculate', 8995), ('stuttered', 8996), ('jupiter', 8997), ('publication', 8998), ('pronounced', 8999), ('slit', 9000), ('wrists', 9001), ('insanely', 9002), ('noted', 9003), ('piracy', 9004), ('engines', 9005), ('spiteful', 9006), ('whackjob', 9007), ('convention', 9008), ('gigantic', 9009), ('concrete', 9010), ('turnip', 9011), ('downsizing', 9012), ('cans', 9013), ('socialist', 9014), ('stepson', 9015), ('miserably', 9016), ('defiant', 9017), ('tel', 9018), ('aviv', 9019), ('mechanism', 9020), ('jammed', 9021), ('anime', 9022), ('garrison', 9023), ('publicity', 9024), ('despised', 9025), ('atoms', 9026), ('unbuttoned', 9027), ('counterfeit', 9028), ('blackjack', 9029), ('anticipate', 9030), ('shortsleeved', 9031), ('conspicuous', 9032), ('bangkok', 9033), ('strummed', 9034), ('outcast', 9035), ('reflects', 9036), ('deliberate', 9037), ('1963', 9038), ('refrain', 9039), ('frazzled', 9040), ('sloths', 9041), ('interrogated', 9042), ('piper', 9043), ('unprepared', 9044), ('30th', 9045), ('120', 9046), ('160', 9047), ('remodelling', 9048), ('dublin', 9049), ('hallway', 9050), ('mona', 9051), ('lisa', 9052), ('dvd', 9053), ('tank', 9054), ('misconduct', 9055), ('restriction', 9056), ('firemen', 9057), ('quickest', 9058), ('increases', 9059), ('greene', 9060), ('estimated', 9061), ('unhurt', 9062), ('pearl', 9063), ('1941', 9064), ('workshop', 9065), ('guarantees', 9066), ('yolks', 9067), ('espresso', 9068), ('allied', 9069), ('misbehaving', 9070), ('commercials', 9071), ('housewarming', 9072), ('cores', 9073), ('gaze', 9074), ('paratrooper', 9075), ('intercepted', 9076), ('blossom', 9077), ('classy', 9078), ('checkers', 9079), ('rattled', 9080), ('mammogram', 9081), ('flop', 9082), ('deemed', 9083), ('buffet', 9084), ('inmates', 9085), ('murderers', 9086), ('tendonitis', 9087), ('limitations', 9088), ('awaited', 9089), ('constellations', 9090), ('undocumented', 9091), ('sin', 9092), ('activities', 9093), ('medieval', 9094), ('employer', 9095), ('stabbing', 9096), ('unquestionably', 9097), ('seniority', 9098), ('chiba', 9099), ('pubs', 9100), ('itsutsugi', 9101), ('florist', 9102), ('jewish', 9103), ('catchy', 9104), ('muted', 9105), ('eagle', 9106), ('gulp', 9107), ('emigrated', 9108), ('premature', 9109), ('statesman', 9110), ('1815', 9111), ('awarded', 9112), ('barged', 9113), ('choirboy', 9114), ('invalid', 9115), ('qualms', 9116), ('keg', 9117), ('hounds', 9118), ('hunters', 9119), ('nonrefundable', 9120), ('coupons', 9121), ('dyeing', 9122), ('records', 9123), ('kyudo', 9124), ('backed', 9125), ('sauerkraut', 9126), ('imagines', 9127), ('hawking', 9128), ('locksmith', 9129), ('doubled', 9130), ('tiara', 9131), ('scrambled', 9132), ('penguin', 9133), ('disciples', 9134), ('paul', 9135), ('declutter', 9136), ('wellinformed', 9137), ('barricaded', 9138), ('overly', 9139), ('graphic', 9140), ('repeats', 9141), ('porcupine', 9142), ('devil', 9143), ('farragut', 9144), ('pledge', 9145), ('brass', 9146), ('taxpayer', 9147), ('cuba', 9148), ('seine', 9149), ('studio', 9150), ('samurai', 9151), ('wages', 9152), ('conceivable', 9153), ('mammoths', 9154), ('vast', 9155), ('bach', 9156), ('foosball', 9157), ('mineral', 9158), ('podcast', 9159), ('builtin', 9160), ('digital', 9161), ('magnets', 9162), ('genetically', 9163), ('modified', 9164), ('alliance', 9165), ('infant', 9166), ('slumber', 9167), ('littering', 9168), ('multiplied', 9169), ('feast', 9170), ('prized', 9171), ('acquaintances', 9172), ('clueless', 9173), ('tenth', 9174), ('marital', 9175), ('unfolded', 9176), ('advertisements', 9177), ('childproof', 9178), ('sockets', 9179), ('birthrate', 9180), ('nongoogle', 9181), ('bigamy', 9182), ('hypnotized', 9183), ('oversleeping', 9184), ('passive', 9185), ('eastern', 9186), ('raincoat', 9187), ('unwell', 9188), ('baskets', 9189), ('unsteady', 9190), ('observer', 9191), ('treatable', 9192), ('gong', 9193), ('enlist', 9194), ('hybrid', 9195), ('moccasins', 9196), ('conductor', 9197), ('undoing', 9198), ('corsica', 9199), ('curling', 9200), ('scoot', 9201), ('scotsman', 9202), ('posters', 9203), ('quibble', 9204), ('shorts', 9205), ('builder', 9206), ('judges', 9207), ('chugalug', 9208), ('revolting', 9209), ('passerby', 9210), ('everest', 9211), ('suggests', 9212), ('janitor', 9213), ('accepts', 9214), ('worldwide', 9215), ('err', 9216), ('helsinki', 9217), ('fans', 9218), ('rattlesnake', 9219), ('trickortreating', 9220), ('musicians', 9221), ('screws', 9222), ('mimic', 9223), ('mourned', 9224), ('123', 9225), ('mornings', 9226), ('apnea', 9227), ('attachment', 9228), ('abstract', 9229), ('marinated', 9230), ('webs', 9231), ('drier', 9232), ('abolished', 9233), ('shrink', 9234), ('noah', 9235), ('ark', 9236), ('1732', 9237), ('involuntary', 9238), ('birdwatching', 9239), ('coffeepot', 9240), ('simplified', 9241), ('handicapped', 9242), ('industries', 9243), ('1791', 9244), ('bonehead', 9245), ('castles', 9246), ('stifled', 9247), ('groan', 9248), ('blurry', 9249), ('audible', 9250), ('1650', 9251), ('tenminute', 9252), ('beneficial', 9253), ('goose', 9254), ('zone', 9255), ('organizations', 9256), ('nuggets', 9257), ('serial', 9258), ('racy', 9259), ('bursting', 9260), ('unreadable', 9261), ('execution', 9262), ('lethal', 9263), ('injection', 9264), ('antonio', 9265), ('guzmn', 9266), ('blanco', 9267), ('venezuela', 9268), ('1870', 9269), ('sneak', 9270), ('grandchild', 9271), ('ribs', 9272), ('thankfully', 9273), ('ordering', 9274), ('grimaced', 9275), ('liz', 9276), ('dew', 9277), ('capricorn', 9278), ('broth', 9279), ('understandingly', 9280), ('index', 9281), ('minimalist', 9282), ('typed', 9283), ('crooked', 9284), ('tracks', 9285), ('favorable', 9286), ('stunningly', 9287), ('toad', 9288), ('torturing', 9289), ('collaborate', 9290), ('instinctively', 9291), ('prosecuted', 9292), ('waterfall', 9293), ('tangent', 9294), ('lee', 9295), ('harvey', 9296), ('oswald', 9297), ('floods', 9298), ('promoting', 9299), ('magnetic', 9300), ('mumbling', 9301), ('cloned', 9302), ('observed', 9303), ('recognising', 9304), ('lawns', 9305), ('braided', 9306), ('discoveries', 9307), ('combat', 9308), ('portable', 9309), ('supports', 9310), ('clinton', 9311), ('controlling', 9312), ('bassist', 9313), ('1911', 9314), ('sucked', 9315), ('nouns', 9316), ('capitalised', 9317), ('convulsions', 9318), ('initiative', 9319), ('hundredth', 9320), ('dumbstruck', 9321), ('removing', 9322), ('brash', 9323), ('syndrome', 9324), ('priced', 9325), ('1847', 9326), ('horserace', 9327), ('chronic', 9328), ('twentysecond', 9329), ('1974', 9330), ('photographic', 9331), ('verb', 9332), ('wrongly', 9333), ('rental', 9334), ('disposable', 9335), ('desserts', 9336), ('knight', 9337), ('galleries', 9338), ('columbia', 9339), ('addiction', 9340), ('queue', 9341), ('hangman', 9342), ('potion', 9343), ('smoothie', 9344), ('exporting', 9345), ('optimists', 9346), ('graveyard', 9347), ('11', 9348), ('darkskinned', 9349), ('recharged', 9350), ('dyes', 9351), ('iraq', 9352), ('juries', 9353), ('praise', 9354), ('evaluated', 9355), ('rebellious', 9356), ('tails', 9357), ('observations', 9358), ('boost', 9359), ('penguins', 9360), ('gnp', 9361), ('suspiciously', 9362), ('entertainment', 9363), ('glut', 9364), ('crucial', 9365), ('mexicans', 9366), ('monopolies', 9367), ('feeble', 9368), ('twentyfour', 9369), ('needle', 9370), ('handcrafted', 9371), ('pitted', 9372), ('hare', 9373), ('raced', 9374), ('tortoise', 9375), ('famine', 9376), ('winters', 9377), ('slimming', 9378), ('sabotage', 9379), ('frowning', 9380), ('firefighters', 9381), ('bin', 9382), ('fisherman', 9383), ('redoubling', 9384), ('sixtyfive', 9385), ('boycotted', 9386), ('exile', 9387), ('televisions', 9388), ('misfortunes', 9389), ('bodyguards', 9390), ('reunion', 9391), ('grande', 9392), ('alaska', 9393), ('tenure', 9394), ('lowest', 9395), ('denominator', 9396), ('arrangements', 9397), ('tux', 9398), ('inseparable', 9399), ('flowerpot', 9400), ('hallucinating', 9401), ('anthem', 9402), ('amassed', 9403), ('herod', 9404), ('graph', 9405), ('plumber', 9406), ('assembles', 9407), ('binge', 9408), ('repairmen', 9409), ('truman', 9410), ('mosques', 9411), ('istanbul', 9412), ('18th', 9413), ('breach', 9414), ('wheezing', 9415), ('rebuilt', 9416), ('milky', 9417), ('officers', 9418), ('massaged', 9419), ('licensed', 9420), ('pisa', 9421), ('submarines', 9422), ('insert', 9423), ('coupon', 9424), ('whom', 9425), ('smirked', 9426), ('nosmoking', 9427), ('output', 9428), ('inhaler', 9429), ('clap', 9430), ('smeared', 9431), ('electrocution', 9432), ('stupidest', 9433), ('prescribed', 9434), ('boxers', 9435), ('superhero', 9436), ('subscribed', 9437), ('diarrhea', 9438), ('partial', 9439), ('legendary', 9440), ('contempt', 9441), ('redoubled', 9442), ('miniskirt', 9443), ('colony', 9444), ('1700', 9445), ('feud', 9446), ('youthful', 9447), ('taj', 9448), ('mahal', 9449), ('celtic', 9450), ('discarded', 9451), ('halves', 9452), ('screwed', 9453), ('romanians', 9454), ('transylvania', 9455), ('badger', 9456), ('cranberry', 9457), ('formerly', 9458), ('kilometer', 9459), ('watermelons', 9460), ('glare', 9461), ('hairy', 9462), ('steroids', 9463), ('controversy', 9464), ('tetris', 9465), ('pheasants', 9466), ('currency', 9467), ('adequate', 9468), ('ponytail', 9469), ('kingdom', 9470), ('asparagus', 9471), ('babysit', 9472), ('tycoon', 9473), ('sedated', 9474), ('armpit', 9475), ('platinum', 9476), ('1912', 9477), ('conducts', 9478), ('nicest', 9479), ('shattered', 9480), ('royal', 9481), ('lakes', 9482), ('intolerant', 9483), ('speedy', 9484), ('failures', 9485), ('watchman', 9486), ('devonshire', 9487), ('adolescents', 9488), ('loophole', 9489), ('develops', 9490), ('340', 9491), ('hummingbirds', 9492), ('curfew', 9493), ('wrap', 9494), ('storyteller', 9495), ('entry', 9496), ('regions', 9497), ('unruly', 9498), ('emojis', 9499), ('sloppy', 9500), ('lunchroom', 9501), ('fencing', 9502), ('coincidences', 9503), ('riots', 9504), ('condo', 9505), ('clearing', 9506), ('purr', 9507), ('canal', 9508), ('lively', 9509), ('issues', 9510), ('prohibits', 9511), ('falsehoods', 9512), ('overall', 9513), ('bosom', 9514), ('swine', 9515), ('andrew', 9516), ('flee', 9517), ('poetic', 9518), ('vulture', 9519), ('cheetah', 9520), ('addressing', 9521), ('imprecise', 9522), ('rewritten', 9523), ('nets', 9524), ('jigsaw', 9525), ('itchy', 9526), ('portuguese', 9527), ('florence', 9528), ('solomon', 9529), ('kneeling', 9530), ('gorillas', 9531), ('lunchtime', 9532), ('sermon', 9533), ('skateboarding', 9534), ('spoils', 9535), ('petals', 9536), ('renovating', 9537), ('daniel', 9538), ('gabriel', 9539), ('1686', 9540), ('ensure', 9541), ('connections', 9542), ('syria', 9543), ('profits', 9544), ('tottori', 9545), ('3yearold', 9546), ('orchids', 9547), ('footprints', 9548), ('scarlet', 9549), ('cycle', 9550), ('grenade', 9551), ('locals', 9552), ('ninetyfive', 9553), ('sorority', 9554), ('definite', 9555), ('bookmark', 9556), ('excess', 9557), ('lawsuit', 9558), ('1903', 9559), ('braked', 9560), ('iowa', 9561), ('knelt', 9562), ('indisposed', 9563), ('arranging', 9564), ('colored', 9565), ('puke', 9566), ('overbite', 9567), ('forgiving', 9568), ('18008286322', 9569), ('mopping', 9570), ('smug', 9571), ('connects', 9572), ('swarm', 9573), ('appropriately', 9574), ('1100', 9575), ('ninetynine', 9576), ('koran', 9577), ('gazelle', 9578), ('firstyear', 9579), ('promote', 9580), ('daiquiri', 9581), ('fines', 9582), ('imf', 9583), ('monetary', 9584), ('fund', 9585), ('pope', 9586), ('statements', 9587), ('boasts', 9588), ('wristwatch', 9589), ('nutritious', 9590), ('folktales', 9591), ('megaphone', 9592), ('counterproductive', 9593), ('privilege', 9594), ('thirtyfive', 9595), ('vicksburg', 9596), ('elves', 9597), ('pointy', 9598), ('merely', 9599), ('nocturnal', 9600), ('warsaw', 9601), ('stunning', 9602), ('valley', 9603), ('330', 9604), ('hyperactive', 9605), ('informing', 9606), ('lectures', 9607), ('giddy', 9608), ('misspelled', 9609), ('decompose', 9610), ('remarkably', 9611), ('participation', 9612), ('bmw', 9613), ('protesting', 9614), ('easiest', 9615), ('slew', 9616), ('successive', 9617), ('steering', 9618), ('mailman', 9619), ('godmother', 9620), ('unlatched', 9621), ('nests', 9622), ('trucks', 9623), ('deodorant', 9624), ('1961', 9625), ('influences', 9626), ('brewed', 9627), ('voicemail', 9628), ('merchants', 9629), ('dictator', 9630), ('physicist', 9631), ('graves', 9632), ('exasperated', 9633), ('diameter', 9634), ('chuck', 9635), ('terminal', 9636), ('softer', 9637), ('dock', 9638), ('milking', 9639), ('funnier', 9640), ('meddling', 9641), ('nudist', 9642), ('senses', 9643), ('campaign', 9644), ('meguro', 9645), ('unload', 9646), ('mist', 9647), ('trauma', 9648), ('deadend', 9649), ('screechy', 9650), ('idiotic', 9651), ('venus', 9652), ('crowds', 9653), ('snails', 9654), ('ninjas', 9655), ('prewar', 9656), ('identifies', 9657), ('beliefs', 9658), ('equals', 9659), ('eightacre', 9660), ('profession', 9661), ('prays', 9662), ('pastimes', 9663), ('authenticity', 9664), ('lacked', 9665), ('shopkeepers', 9666), ('rubbish', 9667), ('uploaded', 9668), ('swing', 9669), ('views', 9670), ('defensively', 9671), ('loads', 9672), ('mcdonald', 9673), ('peacefully', 9674), ('brutal', 9675), ('knitting', 9676), ('monthly', 9677), ('lumber', 9678), ('theoretically', 9679), ('kimchi', 9680), ('moments', 9681), ('gasps', 9682), ('illustrate', 9683), ('verbal', 9684), ('fears', 9685), ('hideout', 9686), ('relieves', 9687), ('remorse', 9688), ('snowball', 9689), ('winded', 9690), ('seaworthy', 9691), ('townspeople', 9692), ('frustration', 9693), ('hollered', 9694), ('muhammad', 9695), ('ali', 9696), ('particulars', 9697), ('goodfornothing', 9698), ('conclusions', 9699), ('flock', 9700), ('notvery', 9701), ('dissolves', 9702), ('contrite', 9703), ('conducting', 9704), ('revealing', 9705), ('radar', 9706), ('symphonies', 9707), ('beethoven', 9708), ('compose', 9709), ('529', 9710), ('commented', 9711), ('evaded', 9712), ('civilized', 9713), ('octopus', 9714), ('capacity', 9715), ('tighten', 9716), ('1965', 9717), ('converts', 9718), ('wireless', 9719), ('resisting', 9720), ('meteorites', 9721), ('miniskirts', 9722), ('gladiators', 9723), ('declare', 9724), ('cures', 9725), ('collects', 9726), ('teapot', 9727), ('philippine', 9728), ('derive', 9729), ('versa', 9730), ('masculine', 9731), ('coercion', 9732), ('downhearted', 9733), ('regain', 9734), ('tricky', 9735), ('politically', 9736), ('salesperson', 9737), ('squid', 9738), ('knowledgeable', 9739), ('extinction', 9740), ('1970s', 9741), ('satisfying', 9742), ('feudal', 9743), ('poets', 9744), ('confidentially', 9745), ('helen', 9746), ('keller', 9747), ('frustrate', 9748), ('stroll', 9749), ('scope', 9750), ('illustrations', 9751), ('hijackers', 9752), ('database', 9753), ('35', 9754), ('worstcase', 9755), ('heritage', 9756), ('stem', 9757), ('disapproved', 9758), ('skittish', 9759), ('malignant', 9760), ('dirt', 9761), ('21st', 9762), ('ardent', 9763), ('strangest', 9764), ('sighed', 9765), ('hebrew', 9766), ('obstructed', 9767), ('venture', 9768), ('meatloaf', 9769), ('facetious', 9770), ('thug', 9771), ('cited', 9772), ('undeniable', 9773), ('meatballs', 9774), ('requesting', 9775), ('positions', 9776), ('calculations', 9777), ('doughnuts', 9778), ('illuminated', 9779), ('du', 9780), ('jour', 9781), ('cramp', 9782), ('bans', 9783), ('socialize', 9784), ('casualty', 9785), ('glance', 9786), ('telephones', 9787), ('factors', 9788), ('fright', 9789), ('snickered', 9790), ('crux', 9791), ('experimentation', 9792), ('abusive', 9793), ('drowsy', 9794), ('reeked', 9795), ('narrative', 9796), ('withheld', 9797), ('injustice', 9798), ('burglary', 9799), ('logarithms', 9800), ('thrilling', 9801), ('distort', 9802), ('fascinates', 9803), ('formidable', 9804), ('miniature', 9805), ('ally', 9806), ('ceo', 9807), ('dumbest', 9808), ('phrased', 9809), ('reopen', 9810), ('overruled', 9811), ('growling', 9812), ('dutch', 9813), ('superiority', 9814), ('decades', 9815), ('hippopotamus', 9816), ('frizzy', 9817), ('reigned', 9818), ('drenched', 9819), ('paradise', 9820), ('unwelcome', 9821), ('googled', 9822), ('armies', 9823), ('investigator', 9824), ('hemlines', 9825), ('missouri', 9826), ('louisiana', 9827), ('elicit', 9828), ('imply', 9829), ('mitzvah', 9830), ('indicate', 9831), ('reformed', 9832), ('repaint', 9833), ('dismantled', 9834), ('almonds', 9835), ('developing', 9836), ('mock', 9837), ('supreme', 9838), ('abraham', 9839), ('friendlier', 9840), ('assault', 9841), ('gallows', 9842), ('caps', 9843), ('axle', 9844), ('iran', 9845), ('alzheimer', 9846), ('sunroof', 9847), ('coconut', 9848), ('destroys', 9849), ('aspire', 9850), ('inhaled', 9851), ('cherish', 9852), ('bruise', 9853), ('bullied', 9854), ('superb', 9855), ('villa', 9856), ('overlooking', 9857), ('trickster', 9858), ('supernatural', 9859), ('flames', 9860), ('dimensions', 9861), ('unlikeable', 9862), ('smartly', 9863), ('breathless', 9864), ('handtomouth', 9865), ('guinea', 9866), ('finnish', 9867), ('solvers', 9868), ('prominent', 9869), ('brats', 9870), ('oppressive', 9871), ('barrel', 9872), ('portal', 9873), ('doubling', 9874), ('impulse', 9875), ('survey', 9876), ('hairdresser', 9877), ('seventeenth', 9878), ('fame', 9879), ('bragged', 9880), ('returns', 9881), ('spreading', 9882), ('wallets', 9883), ('sweeter', 9884), ('6000', 9885), ('cord', 9886), ('poll', 9887), ('standpoint', 9888), ('practicality', 9889), ('biwa', 9890), ('hooky', 9891), ('wheelbarrow', 9892), ('breathtaking', 9893), ('pigsty', 9894), ('frequent', 9895), ('pastime', 9896), ('humidity', 9897), ('liverpool', 9898), ('rescuing', 9899), ('hamster', 9900), ('applicable', 9901), ('broadminded', 9902), ('mandarin', 9903), ('toolbox', 9904), ('censoring', 9905), ('motivates', 9906), ('exemptions', 9907), ('platoon', 9908), ('sergeant', 9909), ('ingenuity', 9910), ('tendered', 9911), ('beats', 9912), ('mumbled', 9913), ('x', 9914), ('commotion', 9915), ('glimpse', 9916), ('rabbi', 9917), ('persistence', 9918), ('republicans', 9919), ('companion', 9920), ('greener', 9921), ('despite', 9922), ('measure', 9923), ('slums', 9924), ('resistance', 9925), ('aspect', 9926), ('stevie', 9927), ('assembly', 9928), ('archeologist', 9929), ('disgusts', 9930), ('teasing', 9931), ('suffocating', 9932), ('madman', 9933), ('obscurity', 9934), ('kidnap', 9935), ('ingenious', 9936), ('farce', 9937), ('retail', 9938), ('mischievously', 9939), ('belching', 9940), ('100meter', 9941), ('woollen', 9942), ('textiles', 9943), ('licenses', 9944), ('disasters', 9945), ('carols', 9946), ('gates', 9947), ('competitors', 9948), ('scalawag', 9949), ('detroit', 9950), ('visual', 9951), ('unlaced', 9952), ('sponsor', 9953), ('vibrate', 9954), ('proceeding', 9955), ('tastier', 9956), ('soy', 9957), ('scars', 9958), ('saves', 9959), ('assemble', 9960), ('champions', 9961), ('apparent', 9962), ('swimsuit', 9963), ('affiliated', 9964), ('literate', 9965), ('unbreakable', 9966), ('fraud', 9967), ('pints', 9968), ('quart', 9969), ('racism', 9970), ('minimize', 9971), ('slacker', 9972), ('spade', 9973), ('fatigue', 9974), ('roasted', 9975), ('sulfa', 9976), ('giraffes', 9977), ('dove', 9978), ('plump', 9979), ('bedside', 9980), ('wasp', 9981), ('breeds', 9982), ('resumed', 9983), ('magical', 9984), ('authorization', 9985), ('grandkids', 9986), ('150', 9987), ('bunk', 9988), ('parted', 9989), ('vow', 9990), ('opposition', 9991), ('imbecile', 9992), ('stains', 9993), ('violate', 9994), ('regulations', 9995), ('stark', 9996), ('witchcraft', 9997), ('georges', 9998), ('questionnaire', 9999), ('notturn', 10000), ('downan', 10001), ('stepsisters', 10002), ('nephews', 10003), ('spiked', 10004), ('remark', 10005), ('fist', 10006), ('organisation', 10007), ('recognised', 10008), ('slugs', 10009), ('treadmill', 10010), ('nearsighted', 10011), ('signboard', 10012), ('usable', 10013), ('grammatical', 10014), ('tentatively', 10015), ('straighten', 10016), ('heartily', 10017), ('angered', 10018), ('elders', 10019), ('pit', 10020), ('ottoman', 10021), ('conquered', 10022), ('1517', 10023), ('dynamite', 10024), ('equality', 10025), ('media', 10026), ('endured', 10027), ('profit', 10028), ('neptune', 10029), ('stables', 10030), ('scallions', 10031), ('basil', 10032), ('poorest', 10033), ('eradicate', 10034), ('category', 10035), ('sufficient', 10036), ('4159048873', 10037), ('chains', 10038), ('raises', 10039), ('glutton', 10040), ('typhoons', 10041), ('input', 10042), ('baffles', 10043), ('hills', 10044), ('redder', 10045), ('assessing', 10046), ('venetian', 10047), ('dislocated', 10048), ('nondisclosure', 10049), ('undone', 10050), ('florida', 10051), ('wales', 10052), ('sadly', 10053), ('reasonablypriced', 10054), ('toothless', 10055), ('span', 10056), ('symphony', 10057), ('poke', 10058), ('creates', 10059), ('awards', 10060), ('tendollar', 10061), ('nicelooking', 10062), ('inhale', 10063), ('fumes', 10064), ('recommends', 10065), ('unleashed', 10066), ('unmerciful', 10067), ('unscrewed', 10068), ('joker', 10069), ('catastrophic', 10070), ('donor', 10071), ('dickens', 10072), ('rubber', 10073), ('1030', 10074), ('bombs', 10075), ('swerved', 10076), ('drill', 10077), ('peoples', 10078), ('bedtime', 10079), ('horns', 10080), ('devastating', 10081), ('regarded', 10082), ('stuffedup', 10083), ('gut', 10084), ('dots', 10085), ('vinegar', 10086), ('investments', 10087), ('physician', 10088), ('grievance', 10089), ('lunches', 10090), ('tuesdays', 10091), ('killers', 10092), ('interrogating', 10093), ('roots', 10094), ('grieving', 10095), ('discredited', 10096), ('headscarf', 10097), ('veterans', 10098), ('hustler', 10099), ('prospect', 10100), ('terminally', 10101), ('greenland', 10102), ('creatures', 10103), ('2009', 10104), ('selection', 10105), ('typographical', 10106), ('lisp', 10107), ('bashed', 10108), ('eruption', 10109), ('travelers', 10110), ('pantry', 10111), ('basking', 10112), ('enviable', 10113), ('peered', 10114), ('pressing', 10115), ('necks', 10116), ('5th', 10117), ('rockefeller', 10118), ('400', 10119), ('fanned', 10120), ('initial', 10121), ('demonstrated', 10122), ('claustrophobia', 10123), ('nonalcoholic', 10124), ('consecutive', 10125), ('scenery', 10126), ('interlingua', 10127), ('klingon', 10128), ('attaching', 10129), ('complimentary', 10130), ('ghetto', 10131), ('falsely', 10132), ('ad', 10133), ('daydreamer', 10134), ('belongings', 10135), ('windowshopping', 10136), ('headquarters', 10137), ('robbers', 10138), ('arctic', 10139), ('educational', 10140), ('insubordination', 10141), ('generations', 10142), ('simplicity', 10143), ('outdated', 10144), ('mosquitos', 10145), ('mourning', 10146), ('nelson', 10147), ('mandela', 10148), ('ocarina', 10149), ('inexperience', 10150), ('salami', 10151), ('shearing', 10152), ('exterminator', 10153), ('eavesdropping', 10154), ('villages', 10155), ('freshlybaked', 10156), ('flaky', 10157), ('knot', 10158), ('imaginable', 10159), ('objections', 10160), ('bounced', 10161), ('kneel', 10162), ('loading', 10163), ('invasion', 10164), ('explicit', 10165), ('mississippi', 10166), ('186000', 10167), ('shed', 10168), ('elope', 10169), ('violating', 10170), ('1947', 10171), ('shorthanded', 10172), ('joints', 10173), ('unnerved', 10174), ('programming', 10175), ('schizophrenia', 10176), ('otaru', 10177), ('warmth', 10178), ('immunity', 10179), ('regarding', 10180), ('interior', 10181), ('distinct', 10182), ('definition', 10183), ('slang', 10184), ('sanda', 10185), ('firefox', 10186), ('interviewing', 10187), ('prizes', 10188), ('distracting', 10189), ('vehicles', 10190), ('paraphrasing', 10191), ('spine', 10192), ('deceiving', 10193), ('naps', 10194), ('intact', 10195), ('explorers', 10196), ('meticulous', 10197), ('leap', 10198), ('postman', 10199), ('sway', 10200), ('dragons', 10201), ('diagnosed', 10202), ('demolished', 10203), ('forgery', 10204), ('contaminated', 10205), ('casualties', 10206), ('1776', 10207), ('precision', 10208), ('measurement', 10209), ('smoky', 10210), ('locally', 10211), ('ohio', 10212), ('honeymooning', 10213), ('shrunk', 10214), ('archaeologist', 10215), ('county', 10216), ('trends', 10217), ('notices', 10218), ('premeditated', 10219), ('weeping', 10220), ('refusing', 10221), ('priceless', 10222), ('critics', 10223), ('framework', 10224), ('nanako', 10225), ('kills', 10226), ('evaporates', 10227), ('concerning', 10228), ('claps', 10229), ('perishes', 10230), ('ballerina', 10231), ('muzzle', 10232), ('charging', 10233), ('crate', 10234), ('1899', 10235), ('la', 10236), ('indisputable', 10237), ('librarian', 10238), ('hemoglobin', 10239), ('landscape', 10240), ('noses', 10241), ('muscular', 10242), ('dismissed', 10243), ('jeep', 10244), ('borrowing', 10245), ('mongolia', 10246), ('parasol', 10247), ('impromptu', 10248), ('footing', 10249), ('prius', 10250), ('extracted', 10251), ('1994', 10252), ('protege', 10253), ('cheats', 10254), ('distorted', 10255), ('archer', 10256), ('plug', 10257), ('inbox', 10258), ('nextdoor', 10259), ('enters', 10260), ('allegedly', 10261), ('gander', 10262), ('impertinent', 10263), ('wary', 10264), ('selfmade', 10265), ('f1', 10266), ('schumacher', 10267), ('toilets', 10268), ('surplus', 10269), ('hatched', 10270), ('burp', 10271), ('pinpointed', 10272), ('cozy', 10273), ('reap', 10274), ('1936', 10275), ('ethiopian', 10276), ('thrust', 10277), ('evaluate', 10278), ('avenue', 10279), ('gibraltar', 10280), ('skinned', 10281), ('immigration', 10282), ('sociopath', 10283), ('benches', 10284), ('carts', 10285), ('dagger', 10286), ('elements', 10287), ('genetic', 10288), ('halfway', 10289), ('drummed', 10290), ('hallucinated', 10291), ('criticizes', 10292), ('indistinguishable', 10293), ('healing', 10294), ('shorthand', 10295), ('computergenerated', 10296), ('barbarian', 10297), ('reckon', 10298), ('paraglider', 10299), ('philosophers', 10300), ('latex', 10301), ('volcanoes', 10302), ('token', 10303), ('1940', 10304), ('chipped', 10305), ('hatchet', 10306), ('motorbike', 10307), ('spirits', 10308), ('forewarned', 10309), ('forearmed', 10310), ('extension', 10311), ('unto', 10312), ('pe', 10313), ('drastic', 10314), ('stakes', 10315), ('cultures', 10316), ('gotta', 10317), ('terrify', 10318), ('<end>', 10319), ('lured', 10320), ('beforehand', 10321), ('vigorous', 10322), ('82', 10323), ('governments', 10324), ('tusk', 10325), ('handbook', 10326), ('jerky', 10327), ('dh', 10328), ('lawrence', 10329), ('underlying', 10330), ('apes', 10331), ('squints', 10332), ('shantytowns', 10333), ('745', 10334), ('wisconsin', 10335), ('demons', 10336), ('nikita', 10337), ('khrushchev', 10338), ('legit', 10339), ('harpsichord', 10340), ('weakens', 10341), ('geronimo', 10342), ('census', 10343), ('nicotine', 10344), ('boast', 10345), ('staten', 10346), ('boroughs', 10347), ('temp', 10348), ('encyclopedia', 10349), ('neglects', 10350), ('clogged', 10351), ('iced', 10352), ('reagan', 10353), ('reveille', 10354), ('bugle', 10355), ('excavation', 10356), ('canals', 10357), ('weaving', 10358), ('midlife', 10359), ('inca', 10360), ('anthropology', 10361), ('demolish', 10362), ('brushes', 10363), ('varicose', 10364), ('veins', 10365), ('observation', 10366), ('osamu', 10367), ('dazai', 10368), ('thirtynine', 10369), ('intersect', 10370), ('goingson', 10371), ('unproductive', 10372), ('geologist', 10373), ('bubbles', 10374), ('disciplined', 10375), ('prevalent', 10376), ('mayan', 10377), ('resulting', 10378), ('commodity', 10379), ('hothead', 10380), ('appetizer', 10381), ('underdog', 10382), ('1000000', 10383), ('organism', 10384), ('80000', 10385), ('monitored', 10386), ('violates', 10387), ('incur', 10388), ('wrath', 10389), ('800000', 10390), ('heartbreaking', 10391), ('conflicts', 10392), ('extradited', 10393), ('planting', 10394), ('barbecuing', 10395), ('recovers', 10396), ('governing', 10397), ('22nd', 10398), ('waves', 10399), ('knits', 10400), ('checkin', 10401), ('snowy', 10402), ('careers', 10403), ('sleds', 10404), ('snakebite', 10405), ('charger', 10406), ('outer', 10407), ('tanning', 10408), ('salon', 10409), ('imitated', 10410), ('grader', 10411), ('ankara', 10412), ('vaccinations', 10413), ('defects', 10414), ('a1', 10415), ('rhinoceroses', 10416), ('tonsillectomy', 10417), ('gout', 10418), ('studious', 10419), ('blisters', 10420), ('pierce', 10421), ('1852', 10422), ('shamefully', 10423), ('memorizing', 10424), ('transparent', 10425), ('panther', 10426), ('insured', 10427), ('pedal', 10428), ('fragrance', 10429), ('elderly', 10430), ('tyrol', 10431), ('massacre', 10432), ('forbidding', 10433), ('endurance', 10434), ('bungee', 10435), ('creature', 10436), ('openly', 10437), ('weakening', 10438), ('clarinetist', 10439), ('upsetting', 10440), ('saturated', 10441), ('tagalog', 10442), ('halfnaked', 10443), ('sienna', 10444), ('momotarou', 10445), ('eggplant', 10446), ('tworoom', 10447), ('techie', 10448), ('mumble', 10449), ('retrospect', 10450), ('vases', 10451), ('takeoff', 10452), ('trout', 10453), ('intently', 10454), ('paranormal', 10455), ('phenomena', 10456), ('mortar', 10457), ('reminisced', 10458), ('bang', 10459), ('nonstarchy', 10460), ('lifeboats', 10461), ('battlefield', 10462), ('mortgaged', 10463), ('adobe', 10464), ('topnotch', 10465), ('editing', 10466), ('attacks', 10467), ('perimeter', 10468), ('breached', 10469), ('mythology', 10470), ('1877', 10471), ('females', 10472), ('minachan', 10473), ('router', 10474), ('ethernet', 10475), ('breathes', 10476), ('potbelly', 10477), ('mutate', 10478), ('530', 10479), ('jaguars', 10480), ('condors', 10481), ('bred', 10482), ('overcast', 10483), ('rowboat', 10484), ('stocky', 10485), ('swarthy', 10486), ('alcoholism', 10487), ('handshake', 10488), ('guidebook', 10489), ('bestseller', 10490), ('perspiring', 10491), ('vowed', 10492), ('depraved', 10493), ('transplants', 10494), ('crept', 10495), ('invulnerable', 10496), ('agency', 10497), ('conformist', 10498), ('necessities', 10499), ('crosslegged', 10500), ('fiasco', 10501), ('contents', 10502), ('delivering', 10503), ('wholegrain', 10504), ('cereals', 10505), ('snored', 10506), ('incompatible', 10507), ('supposedly', 10508), ('analyst', 10509), ('mba', 10510), ('sabbatical', 10511), ('ferment', 10512), ('bummed', 10513), ('jade', 10514), ('invaluable', 10515), ('scorsese', 10516), ('reforms', 10517), ('subscribing', 10518), ('helper', 10519), ('lasting', 10520), ('kagoshima', 10521), ('thump', 10522), ('beget', 10523), ('confrontation', 10524), ('hen', 10525), ('hygienic', 10526), ('bikes', 10527), ('focusing', 10528), ('topics', 10529), ('timeless', 10530), ('temperatures', 10531), ('untouched', 10532), ('wastes', 10533), ('memorable', 10534), ('backstage', 10535), ('inadequate', 10536), ('healer', 10537), ('wrenching', 10538), ('pyramid', 10539), ('scheme', 10540), ('mistyped', 10541), ('conveniences', 10542), ('hotheaded', 10543), ('judgements', 10544), ('championships', 10545), ('slipping', 10546), ('kabul', 10547), ('afghanistan', 10548), ('tambourine', 10549), ('uk', 10550), ('unattractive', 10551), ('visibility', 10552), ('noticeable', 10553), ('hesitates', 10554), ('crude', 10555), ('beaks', 10556), ('grinding', 10557), ('quotation', 10558), ('acoustic', 10559), ('azaleas', 10560), ('distinction', 10561), ('offline', 10562), ('immortality', 10563), ('undesirable', 10564), ('gorges', 10565), ('forceful', 10566), ('ajar', 10567), ('onetrick', 10568), ('internationally', 10569), ('achievements', 10570), ('aisle', 10571), ('diced', 10572), ('ukrainian', 10573), ('manages', 10574), ('nypd', 10575), ('botany', 10576), ('grind', 10577), ('catalogue', 10578), ('verifiable', 10579), ('cheaply', 10580), ('westerns', 10581), ('scraggly', 10582), ('migraines', 10583), ('alleviate', 10584), ('exmarine', 10585), ('nmes', 10586), ('imitates', 10587), ('kiev', 10588), ('blackbirds', 10589), ('egocentric', 10590), ('balding', 10591), ('aces', 10592), ('involving', 10593), ('hillside', 10594), ('elvis', 10595), ('presley', 10596), ('jailhouse', 10597), ('diffused', 10598), ('kelantan', 10599), ('wealthiest', 10600), ('equator', 10601), ('divides', 10602), ('hemispheres', 10603), ('flapped', 10604), ('highlight', 10605), ('illegally', 10606), ('artilleryman', 10607), ('gadgets', 10608), ('sclerosis', 10609), ('overcomplicate', 10610), ('jello', 10611), ('rabid', 10612), ('combed', 10613), ('1812', 10614), ('sunburn', 10615), ('twenties', 10616), ('whitened', 10617), ('instantaneous', 10618), ('creativity', 10619), ('beekeepers', 10620), ('relaxes', 10621), ('untrue', 10622), ('congregation', 10623), ('testimony', 10624), ('inconsistent', 10625), ('spendthrift', 10626), ('bounce', 10627), ('departments', 10628), ('staffing', 10629), ('besttasting', 10630), ('repeatedly', 10631), ('refers', 10632), ('hooks', 10633), ('parlor', 10634), ('communicator', 10635), ('biker', 10636), ('fend', 10637), ('hotcakes', 10638), ('punishing', 10639), ('manufacturing', 10640), ('sheer', 10641), ('13th', 10642), ('nfl', 10643), ('embargo', 10644), ('violators', 10645), ('agile', 10646), ('fairy', 10647), ('restrictions', 10648), ('360', 10649), ('technician', 10650), ('tech', 10651), ('eyelashes', 10652), ('trickery', 10653), ('mediterranean', 10654), ('shiro', 10655), ('accessibility', 10656), ('calming', 10657), ('nessie', 10658), ('spa', 10659), ('airtight', 10660), ('swivel', 10661), ('disorder', 10662), ('washroom', 10663), ('diego', 10664), ('presenters', 10665), ('forearm', 10666), ('outdoor', 10667), ('ingredients', 10668), ('tassaadit', 10669), ('carp', 10670), ('beholder', 10671), ('painters', 10672), ('sorting', 10673), ('unmovable', 10674), ('hangzhou', 10675), ('brands', 10676), ('somali', 10677), ('unshaven', 10678), ('disheveled', 10679), ('pharmaceutical', 10680), ('seasoning', 10681), ('foreclosures', 10682), ('carrie', 10683), ('underwood', 10684), ('1806', 10685), ('amendment', 10686), ('negro', 10687), ('toudaiji', 10688), ('highways', 10689), ('inherit', 10690), ('enlightening', 10691), ('macdonald', 10692), ('1600', 10693), ('collarbone', 10694), ('kicks', 10695), ('yukio', 10696), ('mishima', 10697), ('1970', 10698), ('wellmanaged', 10699), ('karim', 10700), ('atheism', 10701), ('zeus', 10702), ('mushy', 10703), ('decks', 10704), ('cheaters', 10705), ('prosper', 10706), ('precooked', 10707), ('advocated', 10708), ('manuscript', 10709), ('landslide', 10710), ('fractions', 10711), ('emphatic', 10712), ('circulating', 10713), ('bending', 10714), ('bores', 10715), ('endeavored', 10716), ('colonies', 10717), ('billions', 10718), ('fellow', 10719), ('noble', 10720), ('occupations', 10721), ('eyewitnesses', 10722), ('misunderstand', 10723), ('economical', 10724), ('deeds', 10725), ('amuses', 10726), ('awol', 10727), ('heirloom', 10728), ('inspiring', 10729), ('fireflies', 10730), ('40s', 10731), ('budged', 10732), ('wander', 10733), ('buries', 10734), ('howl', 10735), ('cornered', 10736), ('jackal', 10737), ('toms', 10738), ('bend', 10739), ('immortal', 10740), ('revolutions', 10741), ('aristocracy', 10742), ('downloads', 10743), ('verse', 10744), ('natto', 10745), ('clarification', 10746), ('duis', 10747), ('atom', 10748), ('macaroni', 10749), ('psychoanalyst', 10750), ('sweetener', 10751), ('monarch', 10752), ('arabs', 10753), ('exhusbands', 10754), ('hummer', 10755), ('limousines', 10756), ('datsun', 10757), ('brutally', 10758), ('exploded', 10759), ('expands', 10760), ('fraternity', 10761), ('bruce', 10762), ('springsteen', 10763), ('jersey', 10764), ('shortsleeve', 10765), ('bookshop', 10766), ('minus', 10767), ('samarium', 10768), ('sm', 10769), ('silvery', 10770), ('clogs', 10771), ('webcam', 10772), ('huskies', 10773), ('buoy', 10774), ('commitments', 10775), ('steer', 10776), ('fringe', 10777), ('suwon', 10778), ('incheon', 10779), ('brooklyn', 10780), ('helicopters', 10781), ('snuck', 10782), ('lollipop', 10783), ('sorceress', 10784), ('kerosene', 10785), ('mustaches', 10786), ('racists', 10787), ('lends', 10788), ('fingerprint', 10789), ('gee', 10790), ('nursing', 10791), ('undisturbed', 10792), ('kublai', 10793), ('khan', 10794), ('yuan', 10795), ('dynasty', 10796), ('1271', 10797), ('breeze', 10798), ('planner', 10799), ('gawking', 10800), ('designing', 10801), ('145', 10802), ('kimonos', 10803), ('bangladesh', 10804), ('1971', 10805), ('pondering', 10806), ('realtor', 10807), ('adept', 10808), ('smuggling', 10809), ('erupted', 10810), ('commentary', 10811), ('footandmouth', 10812), ('speechwriter', 10813), ('buenos', 10814), ('aires', 10815), ('argentina', 10816), ('autographs', 10817), ('julius', 10818), ('assassinated', 10819), ('brace', 10820), ('housewives', 10821), ('seed', 10822), ('pedestrianfriendly', 10823), ('quantum', 10824), ('buds', 10825), ('shuffler', 10826), ('runners', 10827), ('embezzling', 10828), ('classify', 10829), ('ointment', 10830), ('icicle', 10831), ('moped', 10832), ('inconclusive', 10833), ('gearing', 10834), ('achieving', 10835), ('distortion', 10836), ('blackboards', 10837), ('admiration', 10838), ('poorly', 10839), ('regime', 10840), ('gracious', 10841), ('scribble', 10842), ('moustache', 10843), ('drawers', 10844), ('immigrated', 10845), ('desks', 10846), ('hiroshima', 10847), ('chopper', 10848), ('relations', 10849), ('seeking', 10850), ('abomination', 10851), ('copilot', 10852), ('headlights', 10853), ('threshold', 10854), ('benjamin', 10855), ('inedible', 10856), ('rosa', 10857), ('developer', 10858), ('arch', 10859), ('tourism', 10860), ('generated', 10861), ('dishonor', 10862), ('bushy', 10863), ('bestlooking', 10864), ('awakened', 10865), ('rotted', 10866), ('stems', 10867), ('equilateral', 10868), ('prague', 10869), ('czech', 10870), ('joey', 10871), ('shane', 10872), ('investors', 10873), ('regional', 10874), ('caption', 10875), ('sage', 10876), ('maladies', 10877), ('sashimi', 10878), ('cooling', 10879), ('restrooms', 10880), ('intrigues', 10881), ('outsider', 10882), ('bravest', 10883), ('craters', 10884), ('chase', 10885), ('bravely', 10886), ('aged', 10887), ('approves', 10888), ('toppings', 10889), ('contracts', 10890), ('cooled', 10891), ('zhengzhou', 10892), ('courses', 10893), ('crackpot', 10894), ('enthusiastically', 10895), ('silverware', 10896), ('1997', 10897), ('stinky', 10898), ('turpentine', 10899), ('runny', 10900), ('aiming', 10901), ('cain', 10902), ('oneyear', 10903), ('letdown', 10904), ('dyslexia', 10905), ('handel', 10906), ('contemporaries', 10907), ('manchester', 10908), ('discipline', 10909), ('bullying', 10910), ('hardness', 10911), ('mohs', 10912), ('ordeal', 10913), ('entertain', 10914), ('cleft', 10915), ('transports', 10916), ('racoon', 10917), ('anagram', 10918), ('pullover', 10919), ('ulterior', 10920), ('motives', 10921), ('soprano', 10922), ('piling', 10923), ('moms', 10924), ('prints', 10925), ('optical', 10926), ('commissioner', 10927), ('herman', 10928), ('melville', 10929), ('atrocities', 10930), ('tautology', 10931), ('watchdog', 10932), ('30passenger', 10933), ('sympathetically', 10934), ('nearing', 10935), ('completion', 10936), ('schoolroom', 10937), ('obscure', 10938), ('shortens', 10939), ('intrude', 10940), ('perceptive', 10941), ('bela', 10942), ('lugosi', 10943), ('foundation', 10944), ('straightforward', 10945), ('founder', 10946), ('appraised', 10947), ('neardeath', 10948), ('43', 10949), ('worldfamous', 10950), ('brat', 10951), ('lowalcohol', 10952), ('dispensed', 10953), ('scruffy', 10954), ('choreography', 10955), ('paws', 10956), ('width', 10957), ('glaciers', 10958), ('renamed', 10959), ('pastor', 10960), ('accessible', 10961), ('miso', 10962), ('kyiv', 10963), ('dragonfly', 10964), ('admiral', 10965), ('microscopic', 10966), ('organisms', 10967), ('exposure', 10968), ('harassment', 10969), ('paddled', 10970), ('syntax', 10971), ('python', 10972), ('technicians', 10973), ('coaching', 10974), ('lib', 10975), ('images', 10976), ('algorithm', 10977), ('breeding', 10978), ('epidemiologist', 10979), ('resembled', 10980), ('1051c', 10981), ('cornflakes', 10982), ('punishes', 10983), ('immobile', 10984), ('derailed', 10985), ('neuroscientist', 10986), ('matured', 10987), ('edit', 10988), ('pitched', 10989), ('govern', 10990), ('jogs', 10991), ('climbs', 10992), ('disobey', 10993), ('zucchinis', 10994), ('hospitable', 10995), ('reprint', 10996), ('allies', 10997), ('iraqi', 10998), ('adjective', 10999), ('noun', 11000), ('presenter', 11001), ('himalayas', 11002), ('cleanliness', 11003), ('fortyseven', 11004), ('apartments', 11005), ('computational', 11006), ('cellmates', 11007), ('offices', 11008), ('yemen', 11009), ('collided', 11010), ('headon', 11011), ('angrier', 11012), ('innumerable', 11013), ('mimicking', 11014), ('manchuria', 11015), ('buddhist', 11016), ('schoolyard', 11017), ('hitman', 11018), ('zeros', 11019), ('ogai', 11020), ('hears', 11021), ('surging', 11022), ('sweeping', 11023), ('whiskies', 11024), ('hip', 11025), ('abstains', 11026), ('bullfighting', 11027), ('herbivores', 11028), ('buffoon', 11029), ('costumes', 11030), ('conquers', 11031), ('console', 11032), ('adapts', 11033), ('contracted', 11034), ('shutters', 11035), ('bookshelf', 11036), ('minnesota', 11037), ('fortynine', 11038), ('shoveling', 11039), ('commission', 11040), ('bowing', 11041), ('receipts', 11042), ('asperger', 11043), ('underpants', 11044), ('conjugate', 11045), ('repetitive', 11046), ('persuading', 11047), ('convey', 11048), ('hop', 11049), ('mucks', 11050), ('destructive', 11051), ('ozone', 11052), ('naturalsounding', 11053), ('gills', 11054), ('trance', 11055), ('nitpicker', 11056), ('comforts', 11057), ('erupt', 11058), ('sleigh', 11059), ('sincerely', 11060), ('troubleshooter', 11061), ('showering', 11062), ('preceding', 11063), ('farming', 11064), ('lizard', 11065), ('clasped', 11066), ('zip', 11067), ('stirring', 11068), ('temporarily', 11069), ('fiberglass', 11070), ('rust', 11071), ('trans', 11072), ('fats', 11073), ('italianamericans', 11074), ('howled', 11075), ('prey', 11076), ('patrols', 11077), ('sews', 11078), ('thread', 11079), ('seconded', 11080), ('bandana', 11081), ('moscow', 11082), ('assignments', 11083), ('blackmail', 11084), ('lifesize', 11085), ('crochet', 11086), ('idealistic', 11087), ('cumin', 11088), ('nuns', 11089), ('airs', 11090), ('jets', 11091), ('crosscountry', 11092), ('waters', 11093), ('fivethirty', 11094), ('gums', 11095), ('brochure', 11096), ('medicated', 11097), ('hardboiled', 11098), ('zither', 11099), ('infective', 11100), ('traumatized', 11101), ('oxymoron', 11102), ('sombrero', 11103), ('unburdened', 11104), ('risotto', 11105), ('rinsing', 11106), ('welders', 11107), ('mathematician', 11108), ('rod', 11109), ('enables', 11110), ('functional', 11111), ('analogy', 11112), ('subjected', 11113), ('lowbudget', 11114), ('alexander', 11115), ('casanova', 11116), ('eighties', 11117), ('resent', 11118), ('renounce', 11119), ('clapping', 11120), ('pisces', 11121), ('polyglot', 11122), ('sedimentary', 11123), ('signify', 11124), ('hangout', 11125), ('macintosh', 11126), ('86', 11127), ('transmit', 11128), ('organizing', 11129), ('fundraising', 11130), ('doodad', 11131), ('precedes', 11132), ('lending', 11133), ('champ', 11134), ('cling', 11135), ('minerals', 11136), ('scholars', 11137), ('acrobat', 11138), ('folding', 11139), ('obnoxiously', 11140), ('cultivate', 11141), ('sinks', 11142), ('marriageable', 11143), ('limb', 11144), ('goodbyes', 11145), ('arbitrarily', 11146), ('venue', 11147), ('username', 11148), ('combine', 11149), ('theme', 11150), ('fourhour', 11151), ('genes', 11152), ('sequence', 11153), ('approachable', 11154), ('839', 11155), ('abhorrent', 11156), ('wipers', 11157), ('urn', 11158), ('biceps', 11159), ('objector', 11160), ('traces', 11161), ('tiring', 11162), ('evict', 11163), ('smith', 11164), ('kabuki', 11165), ('unionized', 11166), ('compiled', 11167), ('groceries', 11168), ('photography', 11169), ('warms', 11170), ('bjrk', 11171), ('anaesthesia', 11172), ('secretaries', 11173), ('wagged', 11174), ('millionth', 11175), ('brandnew', 11176), ('sweep', 11177), ('blushes', 11178), ('pooped', 11179), ('ereader', 11180), ('drifter', 11181), ('bids', 11182), ('insatiable', 11183), ('astonishingly', 11184), ('flosses', 11185), ('souls', 11186), ('dc', 11187), ('delight', 11188), ('encourages', 11189), ('practices', 11190), ('bulgarian', 11191), ('saucer', 11192), ('oiling', 11193), ('informant', 11194), ('striking', 11195), ('businessmen', 11196), ('1629', 11197), ('richelieu', 11198), ('manila', 11199), ('lactose', 11200), ('visually', 11201), ('impaired', 11202), ('covid19', 11203), ('evaluations', 11204), ('greta', 11205), ('garbo', 11206), ('housing', 11207), ('pitied', 11208), ('hitchhiking', 11209), ('cerebral', 11210), ('palsy', 11211), ('dumpster', 11212), ('flow', 11213), ('1891', 11214), ('civilian', 11215), ('clipping', 11216), ('introvert', 11217), ('scales', 11218), ('baroque', 11219), ('matching', 11220), ('commutes', 11221), ('flowed', 11222), ('sparked', 11223), ('grey', 11224), ('cycles', 11225), ('rabat', 11226), ('saturn', 11227), ('gestured', 11228), ('vowel', 11229), ('psychological', 11230), ('missionary', 11231), ('unexpectedly', 11232), ('cracking', 11233), ('penthouse', 11234), ('guides', 11235), ('port', 11236), ('financially', 11237), ('woodpecker', 11238), ('3rd', 11239), ('satellites', 11240), ('shades', 11241), ('gluten', 11242), ('evacuating', 11243), ('catastrophe', 11244), ('hail', 11245), ('comprehension', 11246), ('sills', 11247), ('deteriorating', 11248), ('swayed', 11249), ('staged', 11250), ('walkout', 11251), ('marys', 11252), ('sailors', 11253), ('blooms', 11254), ('expresses', 11255), ('ulcer', 11256), ('hakata', 11257), ('humus', 11258), ('amnesia', 11259), ('knights', 11260), ('damascus', 11261), ('untranslatable', 11262), ('lifejacket', 11263), ('househusband', 11264), ('rationally', 11265), ('oars', 11266), ('dread', 11267), ('collars', 11268), ('lobbyist', 11269), ('tonsils', 11270), ('criticizing', 11271), ('termite', 11272), ('prophets', 11273), ('forecasting', 11274), ('vibraphone', 11275), ('cauliflower', 11276), ('receptionist', 11277), ('bulletproof', 11278), ('cheesecake', 11279), ('ambushed', 11280), ('unopened', 11281), ('neglected', 11282), ('calculus', 11283), ('ugliness', 11284), ('contributes', 11285), ('sleeper', 11286), ('wheels', 11287), ('debut', 11288), ('majorette', 11289), ('eliminate', 11290), ('reciprocated', 11291), ('pump', 11292), ('incessant', 11293), ('widespread', 11294), ('molehill', 11295), ('fiercely', 11296), ('washer', 11297), ('mantelpiece', 11298), ('lengthened', 11299), ('predetermined', 11300), ('taylor', 11301), ('curiously', 11302), ('implications', 11303), ('performer', 11304), ('rehearse', 11305), ('whip', 11306), ('yielded', 11307), ('operator', 11308), ('donations', 11309), ('500000', 11310), ('swift', 11311), ('quicktempered', 11312), ('sketch', 11313), ('sisterly', 11314), ('allowance', 11315), ('tensions', 11316), ('schnapps', 11317), ('infections', 11318), ('keener', 11319), ('memo', 11320), ('imperial', 11321), ('vancouver', 11322), ('anomaly', 11323), ('industrious', 11324), ('outlaw', 11325), ('withdrew', 11326), ('shaman', 11327), ('entrepreneur', 11328), ('hippy', 11329), ('underneath', 11330), ('agony', 11331), ('unsolvable', 11332), ('simplest', 11333), ('forum', 11334), ('slacks', 11335), ('wrinkled', 11336), ('bond', 11337), ('balloons', 11338), ('helmets', 11339), ('riders', 11340), ('wellwritten', 11341), ('powder', 11342), ('contender', 11343), ('pia', 11344), ('colada', 11345), ('successfully', 11346), ('hampshire', 11347), ('updating', 11348), ('busybody', 11349), ('barium', 11350), ('smelling', 11351), ('inflating', 11352), ('snowboard', 11353), ('weatherman', 11354), ('speakerphone', 11355), ('hawk', 11356), ('siesta', 11357), ('volatile', 11358), ('joins', 11359), ('clarity', 11360), ('lotion', 11361), ('recalled', 11362), ('insoluble', 11363), ('anesthesiologist', 11364), ('solitude', 11365), ('apocalypse', 11366), ('armageddon', 11367), ('hubcaps', 11368), ('autobiographical', 11369), ('salesgirl', 11370), ('opium', 11371), ('snitch', 11372), ('kenji', 11373), ('miyazawa', 11374), ('viewed', 11375), ('pursuing', 11376), ('constantinople', 11377), ('activist', 11378), ('250000', 11379), ('retreat', 11380), ('quits', 11381), ('chiropractor', 11382), ('heartless', 11383), ('gripping', 11384), ('shaver', 11385), ('picturesque', 11386), ('zugspitze', 11387), ('anchor', 11388), ('aroma', 11389), ('freshly', 11390), ('rechargeable', 11391), ('fianc', 11392), ('enforced', 11393), ('reminding', 11394), ('mastering', 11395), ('snuggle', 11396), ('instrumental', 11397), ('stockholm', 11398), ('crumbs', 11399), ('tide', 11400), ('pitcher', 11401), ('forte', 11402), ('bedridden', 11403), ('bands', 11404), ('acquaint', 11405), ('insidious', 11406), ('shambles', 11407), ('behaviour', 11408), ('faithfulness', 11409), ('minimizing', 11410), ('cuzco', 11411), ('cancellation', 11412), ('marriages', 11413), ('democracies', 11414), ('fib', 11415), ('venomous', 11416), ('zookeeper', 11417), ('samurais', 11418), ('consoled', 11419), ('alqaeda', 11420), ('osama', 11421), ('laden', 11422), ('murky', 11423), ('appeals', 11424), ('counterfeiter', 11425), ('waikiki', 11426), ('hungary', 11427), ('budapest', 11428), ('mailing', 11429), ('pragmatically', 11430), ('beast', 11431), ('aboriginal', 11432), ('didgeridoo', 11433), ('eucalyptus', 11434), ('rebirth', 11435), ('lifesized', 11436), ('fastfood', 11437), ('no9', 11438), ('intestine', 11439), ('wets', 11440), ('blueberry', 11441), ('tarts', 11442), ('resisted', 11443), ('democrat', 11444), ('1956', 11445), ('sneezes', 11446), ('1992', 11447), ('maori', 11448), ('fluctuates', 11449), ('anniversaries', 11450), ('buzzwords', 11451), ('japanesestyle', 11452), ('worldly', 11453), ('nabbed', 11454), ('collectors', 11455), ('fists', 11456), ('runaway', 11457), ('compiling', 11458), ('kangaroos', 11459), ('moldy', 11460), ('recreation', 11461), ('licence', 11462), ('unzen', 11463), ('rehearsals', 11464), ('vibrated', 11465), ('investigations', 11466), ('murmured', 11467), ('growled', 11468), ('cryogenic', 11469), ('outward', 11470), ('chester', 11471), ('arthur', 11472), ('synonym', 11473), ('sketches', 11474), ('heist', 11475), ('expertly', 11476), ('payday', 11477), ('revenue', 11478), ('warranted', 11479), ('brainchild', 11480), ('aluminum', 11481), ('flawlessly', 11482), ('pleases', 11483), ('poked', 11484), ('fleas', 11485), ('breathlessly', 11486), ('adding', 11487), ('paths', 11488), ('sacrifices', 11489), ('skinning', 11490), ('podium', 11491), ('puddles', 11492), ('belts', 11493), ('ax', 11494), ('gloat', 11495), ('7th', 11496), ('nonjudgmental', 11497), ('enthusiast', 11498), ('moneylaundering', 11499), ('mainland', 11500), ('hesitating', 11501), ('installed', 11502), ('meanwhile', 11503), ('shadows', 11504), ('zones', 11505), ('splitting', 11506), ('pan', 11507), ('childrens', 11508), ('resume', 11509), ('arched', 11510), ('10th', 11511), ('fairies', 11512), ('unconventional', 11513), ('exclusive', 11514), ('patronizing', 11515), ('chemotherapy', 11516), ('pedometer', 11517), ('eclipses', 11518), ('booming', 11519), ('sentimental', 11520), ('gunsmith', 11521), ('yugoslavia', 11522), ('1910', 11523), ('panama', 11524), ('coalition', 11525), ('henpecked', 11526), ('warden', 11527), ('extract', 11528), ('conversations', 11529), ('markings', 11530), ('label', 11531), ('albino', 11532), ('ann', 11533), ('dunham', 11534), ('anthropologist', 11535), ('opposites', 11536), ('massive', 11537), ('crawl', 11538), ('sulking', 11539), ('cholera', 11540), ('resolute', 11541), ('twofaced', 11542), ('fullest', 11543), ('sensed', 11544), ('riskier', 11545), ('nickel', 11546), ('prawn', 11547), ('indonesia', 11548), ('clasp', 11549), ('ubuntu', 11550), ('distribution', 11551), ('recluse', 11552), ('paragraphs', 11553), ('shinano', 11554), ('daisies', 11555), ('roulette', 11556), ('cursive', 11557), ('hovering', 11558), ('overhead', 11559), ('guidelines', 11560), ('jest', 11561), ('snowslide', 11562), ('campground', 11563), ('yerevan', 11564), ('mumps', 11565), ('zinc', 11566), ('rereading', 11567), ('unjust', 11568), ('logo', 11569), ('ugliest', 11570), ('forges', 11571), ('prophetic', 11572), ('nosebleed', 11573), ('bratty', 11574), ('9minute', 11575), ('demeaning', 11576), ('galaxies', 11577), ('chained', 11578), ('corrections', 11579), ('ladle', 11580), ('anna', 11581), ('freud', 11582), ('relentless', 11583), ('virginia', 11584), ('tickle', 11585), ('impersonal', 11586), ('speculators', 11587), ('helplessness', 11588), ('jiro', 11589), ('akagawa', 11590), ('480', 11591), ('luxembourg', 11592), ('motionless', 11593), ('plummeting', 11594), ('whatsoever', 11595), ('superstition', 11596), ('haley', 11597), ('concepts', 11598), ('geometry', 11599), ('slobbered', 11600), ('moonlight', 11601), ('comedy', 11602), ('undid', 11603), ('onesixth', 11604), ('sculpture', 11605), ('bluntly', 11606), ('corrupted', 11607), ('forbids', 11608), ('crystalline', 11609), ('structure', 11610), ('needlessly', 11611), ('sunbathing', 11612), ('sellers', 11613), ('twinkling', 11614), ('exits', 11615), ('pentium', 11616), ('microprocessor', 11617), ('empathy', 11618), ('carpets', 11619), ('madonna', 11620), ('symptom', 11621), ('100c', 11622), ('pagoda', 11623), ('schoolchildren', 11624), ('peary', 11625), ('pole', 11626), ('hillbilly', 11627), ('nonfiction', 11628), ('unsaid', 11629), ('measuring', 11630), ('slender', 11631), ('reconstruct', 11632), ('discreetly', 11633), ('moored', 11634), ('asteroids', 11635), ('comets', 11636), ('evaluation', 11637), ('wellmannered', 11638), ('cramped', 11639), ('communities', 11640), ('cabins', 11641), ('blades', 11642), ('drains', 11643), ('bloomed', 11644), ('warmers', 11645), ('applause', 11646), ('bra', 11647), ('playground', 11648), ('canary', 11649), ('escalator', 11650), ('bold', 11651), ('presses', 11652), ('payable', 11653), ('cliche', 11654), ('seismologists', 11655), ('frightens', 11656), ('tardy', 11657), ('glistened', 11658), ('disfigured', 11659), ('gin', 11660), ('slacking', 11661), ('skincare', 11662), ('coasts', 11663), ('tearjerker', 11664), ('adversity', 11665), ('jew', 11666), ('officiate', 11667), ('repetition', 11668), ('oppressed', 11669), ('stickers', 11670), ('laurels', 11671), ('pel', 11672), ('worms', 11673), ('leapfrog', 11674), ('thirtyish', 11675), ('candidacy', 11676), ('brink', 11677), ('seconddegree', 11678), ('pointers', 11679), ('bottoms', 11680), ('1960s', 11681), ('historically', 11682), ('persian', 11683), ('somersaults', 11684), ('mats', 11685), ('budging', 11686), ('pending', 11687), ('sphere', 11688), ('ferrari', 11689), ('schedules', 11690), ('coordinate', 11691), ('administrator', 11692), ('properties', 11693), ('ambiguities', 11694), ('napping', 11695), ('quills', 11696), ('greatlooking', 11697), ('pilgrimage', 11698), ('picks', 11699), ('regulated', 11700), ('21', 11701), ('philosophical', 11702), ('misfit', 11703), ('skater', 11704), ('generously', 11705), ('fingertip', 11706), ('pervasive', 11707), ('daylights', 11708), ('sickly', 11709), ('contradiction', 11710), ('marika', 11711), ('hamsters', 11712), ('105', 11713), ('algerians', 11714), ('depth', 11715), ('kaisha', 11716), ('dipped', 11717), ('foreman', 11718), ('galloping', 11719), ('mistrial', 11720), ('threebedroom', 11721), ('climber', 11722), ('steve', 11723), ('outright', 11724), ('piercing', 11725), ('realizes', 11726), ('unprofessional', 11727), ('docile', 11728), ('drunkard', 11729), ('manga', 11730), ('bestsellers', 11731), ('jiffy', 11732), ('airlines', 11733), ('wellmatched', 11734), ('780', 11735), ('hugs', 11736), ('scurvy', 11737), ('zappa', 11738), ('absented', 11739), ('salsa', 11740), ('melon', 11741), ('meditation', 11742), ('characteristics', 11743), ('soundtrack', 11744), ('prevails', 11745), ('rotates', 11746), ('drunks', 11747), ('impeccable', 11748), ('neighboring', 11749), ('bubble', 11750), ('worldhead', 11751), ('gettysburg', 11752), ('zealots', 11753), ('jumpsuit', 11754), ('peasants', 11755), ('2007', 11756), ('isfor', 11757), ('highlights', 11758), ('relies', 11759), ('franks', 11760), ('honorary', 11761), ('knighthood', 11762), ('placebo', 11763), ('pathological', 11764), ('proclamation', 11765), ('brainwashing', 11766), ('understaffed', 11767), ('moderator', 11768), ('spacing', 11769), ('slumped', 11770), ('antimatter', 11771), ('receptionists', 11772), ('extends', 11773), ('unanimous', 11774), ('blackpool', 11775), ('coastal', 11776), ('territorial', 11777), ('motive', 11778), ('freshener', 11779), ('unauthorized', 11780), ('momentary', 11781), ('pause', 11782), ('ablaze', 11783), ('examining', 11784), ('disrespect', 11785), ('scorpions', 11786), ('relativity', 11787), ('sculptor', 11788), ('tumor', 11789), ('nonnegotiable', 11790), ('incomprehensible', 11791), ('substance', 11792), ('plaguing', 11793), ('cobra', 11794), ('javascript', 11795), ('grainy', 11796), ('vanity', 11797), ('bounds', 11798), ('42', 11799), ('fuse', 11800), ('potty', 11801), ('repaid', 11802), ('generates', 11803), ('sitcoms', 11804), ('kidnapping', 11805), ('2539', 11806), ('ropes', 11807), ('indians', 11808), ('snowcovered', 11809), ('unkempt', 11810), ('15th', 11811), ('colonial', 11812), ('numbs', 11813), ('limbs', 11814), ('stoic', 11815), ('beginnings', 11816), ('maintains', 11817), ('toolkit', 11818), ('dubbed', 11819), ('absconded', 11820), ('splattered', 11821), ('clung', 11822), ('reticent', 11823), ('dilated', 11824), ('sanctions', 11825), ('encyclopedic', 11826), ('oslo', 11827), ('debater', 11828), ('cogent', 11829), ('yukawa', 11830), ('fluorescent', 11831), ('admiring', 11832), ('asphalt', 11833), ('exorbitant', 11834), ('occurrence', 11835), ('bloomer', 11836), ('instructive', 11837), ('rejuvenated', 11838), ('internal', 11839), ('organs', 11840), ('spoonful', 11841), ('rainproof', 11842), ('officials', 11843), ('potassium', 11844), ('ads', 11845), ('pose', 11846), ('nude', 11847), ('censorship', 11848), ('karin', 11849), ('irritates', 11850), ('boyhood', 11851), ('pile', 11852), ('overlap', 11853), ('stabilize', 11854), ('scolding', 11855), ('hippo', 11856), ('flyfishing', 11857), ('fulfill', 11858), ('obligations', 11859), ('stitch', 11860), ('armchairs', 11861), ('scrupulous', 11862), ('pluck', 11863), ('waving', 11864), ('plato', 11865), ('fellows', 11866), ('ablebodied', 11867), ('parliament', 11868), ('timidly', 11869), ('obligatory', 11870), ('nonprofit', 11871), ('chaos', 11872), ('insight', 11873), ('flourish', 11874), ('nonchristians', 11875), ('cyborg', 11876), ('amazes', 11877), ('criterion', 11878), ('croutons', 11879), ('playwright', 11880), ('lens', 11881), ('tacky', 11882), ('contributions', 11883), ('ploy', 11884), ('suceeded', 11885), ('recommendations', 11886), ('wronging', 11887), ('welfare', 11888), ('manipulator', 11889), ('pacing', 11890), ('insulin', 11891), ('chrysanthemums', 11892), ('unbothered', 11893), ('stool', 11894), ('commanded', 11895), ('renewal', 11896), ('tamed', 11897), ('climbers', 11898), ('austrian', 11899), ('magnetism', 11900), ('flaws', 11901), ('montana', 11902), ('compensated', 11903), ('chipper', 11904), ('perugia', 11905), ('brussels', 11906), ('810', 11907), ('splinter', 11908), ('10minute', 11909), ('contrast', 11910), ('dosage', 11911), ('emptyhanded', 11912), ('stormy', 11913), ('expressway', 11914), ('michigan', 11915), ('summarize', 11916), ('twentyone', 11917), ('dipping', 11918), ('postal', 11919), ('solstice', 11920), ('depresses', 11921), ('delightful', 11922), ('presidential', 11923), ('greeks', 11924), ('ambiguity', 11925), ('bartending', 11926), ('optional', 11927), ('luxuries', 11928), ('depress', 11929), ('genocides', 11930), ('refunds', 11931), ('multinational', 11932), ('severed', 11933), ('highdefinition', 11934), ('anarchy', 11935), ('goalie', 11936), ('alligators', 11937), ('justin', 11938), ('bieber', 11939), ('zealous', 11940), ('range', 11941), ('strikes', 11942), ('wildflowers', 11943), ('fridays', 11944), ('utilized', 11945), ('purposes', 11946), ('milestone', 11947), ('treacherous', 11948), ('cart', 11949), ('provinces', 11950), ('territories', 11951), ('dryer', 11952), ('chocolates', 11953), ('upstream', 11954), ('cult', 11955), ('expunged', 11956), ('confided', 11957), ('wiping', 11958), ('quaint', 11959), ('1951', 11960), ('sliding', 11961), ('bumps', 11962), ('nip', 11963), ('bud', 11964), ('insightful', 11965), ('kane', 11966), ('intending', 11967), ('naturalborn', 11968), ('stuckup', 11969), ('resident', 11970), ('ghostwriter', 11971), ('instinctive', 11972), ('battered', 11973), ('kelly', 11974), ('completes', 11975), ('seltzer', 11976), ('derived', 11977), ('fraction', 11978), ('orbits', 11979), ('elliptical', 11980), ('commercialized', 11981), ('selfeducated', 11982), ('sown', 11983), ('whiter', 11984), ('vietnamese', 11985), ('pamper', 11986), ('baikal', 11987), ('quintet', 11988), ('hilton', 11989), ('lightheaded', 11990), ('brooch', 11991), ('leopards', 11992), ('cheetahs', 11993), ('uranus', 11994), ('twentytwo', 11995), ('exploring', 11996), ('leash', 11997), ('beeline', 11998), ('kazakhstan', 11999), ('barns', 12000), ('damaging', 12001), ('doubtless', 12002), ('respecting', 12003), ('detests', 12004), ('ineffective', 12005), ('capitalized', 12006), ('japaneseenglish', 12007), ('asphyxiation', 12008), ('phoenix', 12009), ('arizona', 12010), ('demon', 12011), ('cronies', 12012), ('arabian', 12013), ('soundproof', 12014), ('infested', 12015), ('housesitting', 12016), ('chihuahua', 12017), ('cosmetics', 12018), ('expiration', 12019), ('haggis', 12020), ('scottish', 12021), ('overboard', 12022), ('ngo', 12023), ('radioactive', 12024), ('meowing', 12025), ('yearround', 12026), ('appliances', 12027), ('russians', 12028), ('worsening', 12029), ('motto', 12030), ('vaporizes', 12031), ('3198c', 12032), ('1989', 12033), ('belo', 12034), ('blotting', 12035), ('circulation', 12036), ('haystack', 12037), ('tireless', 12038), ('ugandans', 12039), ('kneehigh', 12040), ('negligible', 12041), ('roller', 12042), ('coaster', 12043), ('looptheloop', 12044), ('malt', 12045), ('patronage', 12046), ('nominees', 12047), ('coffin', 12048), ('migrate', 12049), ('merchant', 12050), ('thirties', 12051), ('antidepressants', 12052), ('ophthalmologist', 12053), ('unalike', 12054), ('urged', 12055), ('desktop', 12056), ('blueberries', 12057), ('kaleidoscopes', 12058), ('barbells', 12059), ('dominant', 12060), ('sawdust', 12061), ('squinting', 12062), ('abusing', 12063), ('ripoff', 12064), ('philip', 12065), ('cherryblossomviewing', 12066), ('neighbours', 12067), ('blister', 12068), ('undermining', 12069), ('possessions', 12070), ('decay', 12071), ('fingerprints', 12072), ('mixing', 12073), ('cyanide', 12074), ('outofbody', 12075), ('yoyo', 12076), ('policewoman', 12077), ('dialect', 12078), ('irs', 12079), ('cadillac', 12080), ('1200', 12081), ('occasional', 12082), ('ussr', 12083), ('mountainous', 12084), ('nabil', 12085), ('gazing', 12086), ('24th', 12087), ('cultivated', 12088), ('systems', 12089), ('liable', 12090), ('hike', 12091), ('firearms', 12092), ('guitarists', 12093), ('incomparable', 12094), ('requirements', 12095), ('lithuania', 12096), ('gazpacho', 12097), ('egomaniac', 12098), ('nevada', 12099), ('ah', 12100), ('populated', 12101), ('adaptation', 12102), ('momentarily', 12103), ('cutest', 12104), ('romania', 12105), ('bucharest', 12106), ('approvingly', 12107), ('grazing', 12108), ('dearly', 12109), ('wellbuilt', 12110), ('relics', 12111), ('recycling', 12112), ('sickened', 12113), ('compensate', 12114), ('curb', 12115), ('yale', 12116), ('samples', 12117), ('hive', 12118), ('blots', 12119), ('freeway', 12120), ('encounter', 12121), ('clarify', 12122), ('tyranny', 12123), ('jf', 12124), ('kennedy', 12125), ('arlington', 12126), ('minivan', 12127), ('eighteenth', 12128), ('marconi', 12129), ('sprain', 12130), ('heal', 12131), ('ragged', 12132), ('emperor', 12133), ('nero', 12134), ('tyrant', 12135), ('englishwomen', 12136), ('convert', 12137), ('budding', 12138), ('manually', 12139), ('inconvenient', 12140), ('fastidious', 12141), ('videogame', 12142), ('unfazed', 12143), ('fabrication', 12144), ('overpopulation', 12145), ('unfairly', 12146), ('looting', 12147), ('concertina', 12148), ('presumptuous', 12149), ('trio', 12150), ('er', 12151), ('consoling', 12152), ('uranium', 12153), ('miscalculated', 12154), ('fares', 12155), ('limo', 12156), ('masters', 12157), ('formalities', 12158), ('tedious', 12159), ('memorial', 12160), ('sewage', 12161), ('soothe', 12162), ('prides', 12163), ('campfire', 12164), ('tuner', 12165), ('auto', 12166), ('pennsylvania', 12167), ('ominous', 12168), ('decipher', 12169), ('colombia', 12170), ('branched', 12171), ('lanes', 12172), ('invites', 12173), ('2006', 12174), ('cordial', 12175), ('mastermind', 12176), ('insurgents', 12177), ('bookstores', 12178), ('traveler', 12179), ('blossomed', 12180), ('whoopee', 12181), ('advises', 12182), ('hydrotherapy', 12183), ('beak', 12184), ('continuously', 12185), ('sneakers', 12186), ('handheld', 12187), ('kidneys', 12188), ('frail', 12189), ('kin', 12190), ('competitor', 12191), ('maple', 12192), ('syrup', 12193), ('outweigh', 12194), ('substantial', 12195), ('skates', 12196), ('possess', 12197), ('discounted', 12198), ('poinsettias', 12199), ('editor', 12200), ('engrossed', 12201), ('crane', 12202), ('deviate', 12203), ('troll', 12204), ('forums', 12205), ('elections', 12206), ('boot', 12207), ('witches', 12208), ('horizontal', 12209), ('earplugs', 12210), ('winds', 12211), ('cooing', 12212), ('altruistic', 12213), ('tricycles', 12214), ('monasteries', 12215), ('hesitantly', 12216), ('proverbs', 12217), ('dictatorship', 12218), ('absolved', 12219), ('spells', 12220), ('envelopes', 12221), ('celebrations', 12222), ('carcass', 12223), ('calmer', 12224), ('samba', 12225), ('ido', 12226), ('lojban', 12227), ('navi', 12228), ('volapk', 12229), ('wornout', 12230), ('migraine', 12231), ('toupee', 12232), ('bottled', 12233), ('tenthirty', 12234), ('grand', 12235), ('prairie', 12236), ('loosefitting', 12237), ('tipped', 12238), ('disheartened', 12239), ('sealed', 12240), ('yamamoto', 12241), ('sixtytwo', 12242), ('intercom', 12243), ('windmill', 12244), ('outrun', 12245), ('abstained', 12246), ('hearsay', 12247), ('musty', 12248), ('redhanded', 12249), ('moroccans', 12250), ('merlin', 12251), ('sheltered', 12252), ('beatnik', 12253), ('unanswered', 12254), ('experimenting', 12255), ('mountaintop', 12256), ('evaporation', 12257), ('alkalis', 12258), ('neutralize', 12259), ('acids', 12260), ('barbed', 12261), ('newsstand', 12262), ('brad', 12263), ('pitt', 12264), ('cinders', 12265), ('archeology', 12266), ('reveals', 12267), ('salmonella', 12268), ('twisted', 12269), ('preferences', 12270), ('hedge', 12271), ('103', 12272), ('undertaker', 12273), ('peddler', 12274), ('pillar', 12275), ('pouring', 12276), ('committing', 12277), ('bloodier', 12278), ('finance', 12279), ('increasingly', 12280), ('husbands', 12281), ('humility', 12282), ('peru', 12283), ('contemporary', 12284), ('marlowe', 12285), ('steadily', 12286), ('fibers', 12287), ('deplorable', 12288), ('rugs', 12289), ('absorb', 12290), ('arrivals', 12291), ('misinterpreted', 12292), ('arthropods', 12293), ('acupuncturist', 12294), ('donkeys', 12295), ('brasilia', 12296), ('slack', 12297), ('limbo', 12298), ('unison', 12299), ('spongy', 12300), ('reluctance', 12301), ('basses', 12302), ('incredulous', 12303), ('shapes', 12304), ('toll', 12305), ('scratching', 12306), ('shaggy', 12307), ('reunions', 12308), ('subtitled', 12309), ('yakitori', 12310), ('saddened', 12311), ('stepdaughter', 12312), ('soloist', 12313), ('yearly', 12314), ('fossils', 12315), ('nakameguro', 12316), ('pulsating', 12317), ('glow', 12318), ('embers', 12319), ('upcoming', 12320), ('peas', 12321), ('pod', 12322), ('fazed', 12323), ('elect', 12324), ('deed', 12325), ('shivers', 12326), ('suffocated', 12327), ('loaf', 12328), ('stern', 12329), ('reachable', 12330), ('76000', 12331), ('ipads', 12332), ('symbolic', 12333), ('masha', 12334), ('flattery', 12335), ('misconception', 12336), ('erase', 12337), ('rainwater', 12338), ('riddles', 12339), ('transmits', 12340), ('stank', 12341), ('retriever', 12342), ('buzzed', 12343), ('rivalry', 12344), ('academic', 12345), ('astonishment', 12346), ('groom', 12347), ('downfall', 12348), ('decorator', 12349), ('biodiversity', 12350), ('waterfalls', 12351), ('blackberries', 12352), ('goatee', 12353), ('barricade', 12354), ('karma', 12355), ('beards', 12356), ('farida', 12357), ('neil', 12358), ('blows', 12359), ('entertained', 12360), ('1914', 12361), ('oiled', 12362), ('jaywalking', 12363), ('hakodate', 12364), ('softspoken', 12365), ('imitations', 12366), ('ral', 12367), ('branded', 12368), ('yorker', 12369), ('watchmen', 12370), ('pretentious', 12371), ('velocity', 12372), ('display', 12373), ('radiant', 12374), ('trampoline', 12375), ('incorporated', 12376), ('urgency', 12377), ('arise', 12378), ('chopping', 12379), ('delinquent', 12380), ('bulk', 12381), ('fahima', 12382), ('dudes', 12383), ('sovereignty', 12384), ('advances', 12385), ('corporal', 12386), ('womanizer', 12387), ('probable', 12388), ('stuttering', 12389), ('sonnet', 12390), ('indestructible', 12391), ('sewed', 12392), ('navigation', 12393), ('aristocrat', 12394), ('raspberries', 12395), ('comparing', 12396), ('17', 12397), ('adverse', 12398), ('rightfully', 12399), ('injected', 12400), ('delegations', 12401), ('geneva', 12402), ('distantly', 12403), ('ugh', 12404), ('trench', 12405), ('cicadas', 12406), ('obsessing', 12407), ('fess', 12408), ('ottawa', 12409), ('imperfections', 12410), ('meadow', 12411), ('bargained', 12412), ('gasping', 12413), ('ruled', 12414), ('levels', 12415), ('bikini', 12416), ('corny', 12417), ('extravagantly', 12418), ('twoday', 12419), ('correctional', 12420), ('casks', 12421), ('amazoncom', 12422), ('futon', 12423), ('auditions', 12424), ('net', 12425), ('absorbent', 12426), ('fabric', 12427), ('dow', 12428), ('jones', 12429), ('understandably', 12430), ('perks', 12431), ('adverb', 12432), ('carolina', 12433), ('grasp', 12434), ('throne', 12435), ('pronounces', 12436), ('seoul', 12437), ('explorer', 12438), ('wrench', 12439), ('commonly', 12440), ('ifeel', 12441), ('likeeating', 12442), ('tucked', 12443), ('builds', 12444), ('sheds', 12445), ('compasses', 12446), ('diagonal', 12447), ('significantly', 12448), ('outlived', 12449), ('transition', 12450), ('obsession', 12451), ('kidnapper', 12452), ('mumbai', 12453), ('maharashtra', 12454), ('milked', 12455), ('psycho', 12456), ('synchronized', 12457), ('amazon', 12458), ('encrypted', 12459), ('atlanta', 12460), ('obediently', 12461), ('prussian', 12462), ('baltic', 12463), ('adam', 12464), ('frying', 12465), ('lizards', 12466), ('instructed', 12467), ('malaysian', 12468), ('respectable', 12469), ('quotations', 12470), ('hailstones', 12471), ('elk', 12472), ('craft', 12473), ('amputate', 12474), ('dexterous', 12475), ('1983', 12476), ('enchanted', 12477), ('bail', 12478), ('twohour', 12479), ('monsoon', 12480), ('oaks', 12481), ('sumatra', 12482), ('restricted', 12483), ('credentials', 12484), ('tonguetwister', 12485), ('tepid', 12486), ('cactus', 12487), ('unqualified', 12488), ('hijacked', 12489), ('latrine', 12490), ('hitch', 12491), ('bathrooms', 12492), ('tenor', 12493), ('pacemaker', 12494), ('seething', 12495), ('cravings', 12496), ('individualist', 12497), ('petroleum', 12498), ('faintly', 12499), ('warrior', 12500), ('mightier', 12501), ('luster', 12502), ('indifferent', 12503), ('trainers', 12504), ('teetotaller', 12505), ('diggers', 12506), ('nonexistent', 12507), ('detonated', 12508), ('professionals', 12509), ('groans', 12510), ('unpacked', 12511), ('anticipates', 12512), ('preface', 12513), ('weighing', 12514), ('amoeba', 12515), ('desperation', 12516), ('undrinkable', 12517), ('1040', 12518), ('affectations', 12519), ('slump', 12520), ('exhaust', 12521), ('pollutes', 12522), ('durable', 12523), ('saitama', 12524), ('misspelling', 12525), ('skeletons', 12526), ('researching', 12527), ('tenyear', 12528), ('pavement', 12529), ('commanding', 12530), ('shack', 12531), ('celebrates', 12532), ('50th', 12533), ('unorthodox', 12534), ('statistically', 12535), ('resorting', 12536), ('minimal', 12537), ('scientifically', 12538), ('mispronounces', 12539), ('monument', 12540), ('perky', 12541), ('reelection', 12542), ('remixed', 12543), ('kittens', 12544), ('delicatessen', 12545), ('zorro', 12546), ('unite', 12547), ('delusion', 12548), ('brr', 12549), ('magnet', 12550), ('ulaanbaatar', 12551), ('brandenburg', 12552), ('landmarks', 12553), ('widest', 12554), ('shells', 12555), ('beams', 12556), ('translators', 12557), ('copyright', 12558), ('refrigerators', 12559), ('corrupts', 12560), ('pta', 12561), ('inattention', 12562), ('extraction', 12563), ('fertilizer', 12564), ('blend', 12565), ('fistfight', 12566), ('baldness', 12567), ('auckland', 12568), ('infuriated', 12569), ('metric', 12570), ('spineless', 12571), ('outlet', 12572), ('spiraling', 12573), ('downwards', 12574), ('pun', 12575), ('gucci', 12576), ('fatigued', 12577), ('microphones', 12578), ('suspicion', 12579), ('haggle', 12580), ('stradivarius', 12581), ('unfavorable', 12582), ('cleaners', 12583), ('sensei', 12584), ('internship', 12585), ('nineties', 12586), ('shortterm', 12587), ('kentucky', 12588), ('amputations', 12589), ('manufacturers', 12590), ('explainable', 12591), ('busiest', 12592), ('circulates', 12593), ('foggiest', 12594), ('drawings', 12595), ('specimen', 12596), ('supposition', 12597), ('wouldhelp', 12598), ('represents', 12599), ('litter', 12600), ('terrace', 12601), ('pronunciations', 12602), ('disorienting', 12603), ('1920', 12604), ('plaintiff', 12605), ('devoid', 12606), ('hachiko', 12607), ('advisable', 12608), ('magicians', 12609), ('imminent', 12610), ('prolific', 12611), ('magpies', 12612), ('revival', 12613), ('cloakanddagger', 12614), ('salesmen', 12615), ('blindness', 12616), ('projector', 12617), ('privileged', 12618), ('tinfoil', 12619), ('cooperated', 12620), ('ventured', 12621), ('caverns', 12622), ('glued', 12623), ('reasoned', 12624), ('summarily', 12625), ('qualify', 12626), ('gangs', 12627), ('atmospheric', 12628), ('heavens', 12629), ('personalities', 12630), ('outdoes', 12631), ('capri', 12632), ('operations', 12633), ('underway', 12634), ('squeak', 12635), ('undercooked', 12636), ('homey', 12637), ('perfected', 12638), ('embittered', 12639), ('individuals', 12640), ('aspirins', 12641), ('270', 12642), ('opossum', 12643), ('indescribable', 12644), ('yamina', 12645), ('slowing', 12646), ('individually', 12647), ('bends', 12648), ('hitachi', 12649), ('nec', 12650), ('competing', 12651), ('earnings', 12652), ('pbs', 12653), ('extremes', 12654), ('birdhouse', 12655), ('duly', 12656), ('exponentially', 12657), ('paroled', 12658), ('uphill', 12659), ('microbiologist', 12660), ('tadpoles', 12661), ('unconvincing', 12662), ('slaughter', 12663), ('barbarous', 12664), ('heebie', 12665), ('jeebies', 12666), ('boasting', 12667), ('clamoring', 12668), ('greatgrandparents', 12669), ('osteoporosis', 12670), ('groping', 12671), ('halfhour', 12672), ('overdue', 12673), ('discs', 12674), ('snare', 12675), ('verified', 12676), ('nominate', 12677), ('snorted', 12678), ('truffles', 12679), ('feather', 12680), ('pickles', 12681), ('irrationally', 12682), ('wrung', 12683), ('iaido', 12684), ('undisciplined', 12685), ('puppet', 12686), ('polar', 12687), ('achilles', 12688), ('hereditary', 12689), ('homeward', 12690), ('hasty', 12691), ('nearer', 12692), ('knowhow', 12693), ('fable', 12694), ('fairytale', 12695), ('935', 12696), ('bambury', 12697), ('beverages', 12698), ('secrecy', 12699), ('stature', 12700), ('duke', 12701), ('prosperity', 12702), ('largely', 12703), ('rests', 12704), ('craving', 12705), ('180', 12706), ('haste', 12707), ('undergone', 12708), ('hermits', 12709), ('prosecutor', 12710), ('tutor', 12711), ('destroying', 12712), ('antiques', 12713), ('catnip', 12714), ('lobes', 12715), ('amputation', 12716), ('proudly', 12717), ('marine', 12718), ('dedicates', 12719), ('maintenance', 12720), ('contradictory', 12721), ('justifies', 12722), ('fumbled', 12723), ('doorknob', 12724), ('stunt', 12725), ('leaked', 12726), ('intuitive', 12727), ('repairman', 12728), ('compulsory', 12729), ('stereotype', 12730), ('widen', 12731), ('1917', 12732), ('missionaries', 12733), ('workload', 12734), ('carsick', 12735), ('southampton', 12736), ('handlebars', 12737), ('foyer', 12738), ('mountaineering', 12739), ('rearranged', 12740), ('pillows', 12741), ('bidding', 12742), ('overestimated', 12743), ('purring', 12744), ('compensation', 12745), ('warp', 12746), ('swell', 12747), ('honked', 12748), ('melt', 12749), ('subtracted', 12750), ('provides', 12751), ('buzzer', 12752), ('singly', 12753), ('spies', 12754), ('colossal', 12755), ('augustus', 12756), ('wetsuit', 12757), ('sidewalks', 12758), ('revised', 12759), ('stacking', 12760), ('consumed', 12761), ('shichigosan', 12762), ('charred', 12763), ('quench', 12764), ('biodegradable', 12765), ('teamwork', 12766), ('flustered', 12767), ('machida', 12768), ('1683', 12769), ('besieged', 12770), ('deaths', 12771), ('probability', 12772), ('pesticides', 12773), ('cautionary', 12774), ('motorcyclist', 12775), ('cyclists', 12776), ('diver', 12777), ('luther', 12778), ('resigns', 12779), ('eightyfive', 12780), ('hardened', 12781), ('grudges', 12782), ('surpass', 12783), ('bologna', 12784), ('rhymes', 12785), ('bentley', 12786), ('peeped', 12787), ('creationism', 12788), ('tactless', 12789), ('windier', 12790), ('practising', 12791), ('barometer', 12792), ('cinnamon', 12793), ('explosives', 12794), ('utah', 12795), ('1865', 12796), ('nonetheless', 12797), ('permissive', 12798), ('solemn', 12799), ('crows', 12800), ('thickets', 12801), ('conjunctivitis', 12802), ('ample', 12803), ('avalanche', 12804), ('dresser', 12805), ('sweats', 12806), ('slavic', 12807), ('deranged', 12808), ('paragliding', 12809), ('centuryold', 12810), ('inmate', 12811), ('highsecurity', 12812), ('doubting', 12813), ('wrinkle', 12814), ('kitten', 12815), ('myopia', 12816), ('detector', 12817), ('inadmissible', 12818), ('halted', 12819), ('tougher', 12820), ('giggling', 12821), ('laser', 12822), ('screenwriter', 12823), ('flulike', 12824), ('lecherous', 12825), ('improviser', 12826), ('inheritance', 12827), ('castanets', 12828), ('tapping', 12829), ('antivirus', 12830), ('utility', 12831), ('toxic', 12832), ('kawasaki', 12833), ('catcher', 12834), ('4th', 12835), ('swimmers', 12836), ('teller', 12837), ('punchline', 12838), ('minorities', 12839), ('prejudice', 12840), ('schoolbag', 12841), ('acknowledging', 12842), ('texted', 12843), ('fertilizers', 12844), ('mama', 12845), ('hymn', 12846), ('icecaps', 12847), ('1835', 12848), ('optometrist', 12849), ('tailing', 12850), ('ulysses', 12851), ('kenichi', 12852), ('snag', 12853), ('sciencefiction', 12854), ('paraplegic', 12855), ('defied', 12856), ('combustion', 12857), ('homeschooled', 12858), ('beds', 12859), ('disable', 12860), ('winston', 12861), ('churchill', 12862), ('parallels', 12863), ('blunt', 12864), ('ishikawa', 12865), ('cluttered', 12866), ('insecurity', 12867), ('grafton', 12868), ('joggers', 12869), ('courier', 12870), ('binding', 12871), ('burden', 12872), ('favour', 12873), ('hurriedly', 12874), ('gymnasium', 12875), ('quickwitted', 12876), ('rockandroll', 12877), ('sofas', 12878), ('gallery', 12879), ('rebelled', 12880), ('limp', 12881), ('2014', 12882), ('tonsillitis', 12883), ('voluntary', 12884), ('spirit', 12885), ('streetcars', 12886), ('invade', 12887), ('stainless', 12888), ('consumers', 12889), ('ntt', 12890), ('towada', 12891), ('sixtyeight', 12892), ('treatments', 12893), ('whitening', 12894), ('removal', 12895), ('georgia', 12896), ('danish', 12897), ('fuming', 12898), ('divorcing', 12899), ('concussion', 12900), ('disturbs', 12901), ('bolts', 12902), ('inarticulate', 12903), ('bikefriendly', 12904), ('shocks', 12905), ('matsuko', 12906), ('ashburton', 12907), ('sex', 12908), ('screwball', 12909), ('casket', 12910), ('devote', 12911), ('tenant', 12912), ('hump', 12913), ('horrifyingly', 12914), ('pentagram', 12915), ('lookout', 12916), ('introductory', 12917), ('phew', 12918), ('groaning', 12919), ('overheats', 12920), ('hepatitis', 12921), ('opossums', 12922), ('mower', 12923), ('tenforty', 12924), ('conceived', 12925), ('aired', 12926), ('rembrandt', 12927), ('thou', 12928), ('shalt', 12929), ('sulfur', 12930), ('courtyard', 12931), ('hermit', 12932), ('terrorism', 12933), ('faulted', 12934), ('burglaries', 12935), ('sweetheart', 12936), ('blacks', 12937), ('plumbers', 12938), ('bookcases', 12939), ('ginseng', 12940), ('antidepressant', 12941), ('alarmed', 12942), ('senile', 12943), ('pedicure', 12944), ('stadiums', 12945), ('eerily', 12946), ('iridium', 12947), ('rarest', 12948), ('f', 12949), ('sixth', 12950), ('estonia', 12951), ('unlimited', 12952), ('sculptures', 12953), ('teddy', 12954), ('constructive', 12955), ('ssh', 12956), ('remotely', 12957), ('enforcement', 12958), ('castro', 12959), ('premium', 12960), ('passengerside', 12961), ('shredded', 12962), ('misused', 12963), ('bakes', 12964), ('origins', 12965), ('shrouded', 12966), ('subtraction', 12967), ('functions', 12968), ('unavailable', 12969), ('astrophysicist', 12970), ('tolerance', 12971), ('frustrations', 12972), ('churches', 12973), ('designated', 12974), ('archeological', 12975), ('sites', 12976), ('salve', 12977), ('aggressor', 12978), ('twine', 12979), ('2268', 12980), ('shintaro', 12981), ('wada', 12982), ('lust', 12983), ('gluttony', 12984), ('sloth', 12985), ('describes', 12986), ('passiveaggressive', 12987), ('horseshoe', 12988), ('fourleaf', 12989), ('clover', 12990), ('1497', 12991), ('cabot', 12992), ('deacon', 12993), ('toenails', 12994), ('intensity', 12995), ('demolition', 12996), ('disconcerting', 12997), ('parody', 12998), ('sandalwood', 12999), ('229', 13000), ('broadway', 13001), ('grueling', 13002), ('fanatical', 13003), ('grayhaired', 13004), ('forgiveness', 13005), ('fascist', 13006), ('revelation', 13007), ('defined', 13008), ('childless', 13009), ('holed', 13010), ('longsleeved', 13011), ('cleveland', 13012), ('creek', 13013), ('enraged', 13014), ('banged', 13015), ('morality', 13016), ('intuition', 13017), ('mercury', 13018), ('dominates', 13019), ('overseas', 13020), ('sri', 13021), ('lanka', 13022), ('appendix', 13023), ('cm', 13024), ('backache', 13025), ('cruise', 13026), ('p', 13027), ('m', 13028), ('bilabial', 13029), ('consonants', 13030), ('crocodiles', 13031), ('appendicitis', 13032), ('cleanshaven', 13033), ('chops', 13034), ('mediocre', 13035), ('andrlouis', 13036), ('debierne', 13037), ('occupational', 13038), ('surged', 13039), ('dodging', 13040), ('dealings', 13041), ('prototypes', 13042), ('scriptwriter', 13043), ('lavender', 13044), ('hardhearted', 13045), ('contested', 13046), ('measures', 13047), ('carnations', 13048), ('frenchspeaking', 13049), ('unites', 13050), ('laced', 13051), ('snowfall', 13052), ('strolled', 13053), ('heap', 13054), ('montcalm', 13055), ('1757', 13056), ('reassigned', 13057), ('cellphones', 13058), ('renewable', 13059), ('renter', 13060), ('blankly', 13061), ('sails', 13062), ('strait', 13063), ('gymnast', 13064), ('wasps', 13065), ('dioxide', 13066), ('emissions', 13067), ('acute', 13068), ('napkins', 13069), ('crossword', 13070), ('nonnative', 13071), ('surveillance', 13072), ('divorces', 13073), ('ceramics', 13074), ('frantically', 13075), ('backpedaling', 13076), ('archives', 13077), ('gravely', 13078), ('brunette', 13079), ('drivein', 13080), ('torn', 13081), ('unsuitable', 13082), ('dreary', 13083), ('overdramatic', 13084), ('lidya', 13085), ('fashions', 13086), ('toddler', 13087), ('prospering', 13088), ('muffin', 13089), ('dreamers', 13090), ('2000000', 13091), ('schoolbooks', 13092), ('maids', 13093), ('conundrum', 13094), ('shyness', 13095), ('viewpoint', 13096), ('trophies', 13097), ('hopscotch', 13098), ('stumbled', 13099), ('flank', 13100), ('nunnery', 13101), ('flask', 13102), ('overprotective', 13103), ('pebble', 13104), ('snickering', 13105), ('tram', 13106), ('spouses', 13107)])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d8ZeSKV0x_d8",
        "outputId": "8c3570bb-7ccc-455b-f5fd-2a34a6d61f9e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          italian  \\\n",
              "63501                           non cè caldo oggi   \n",
              "227738                    non osare toccare nulla   \n",
              "241713       tutti hanno detto che io avevo torto   \n",
              "200152      io spero di vederti la prossima volta   \n",
              "216938  sono andata a fare trekking con il gruppo   \n",
              "\n",
              "                                   english_inp  \\\n",
              "63501        <start> it is not hot today <end>   \n",
              "227738  <start> do not you dare touch anything   \n",
              "241713  <start> everyone said that i was wrong   \n",
              "200152     <start> i hope to see you next time   \n",
              "216938    <start> i went hiking with the group   \n",
              "\n",
              "                                 english_out  \n",
              "63501        it is not hot today <end> <end>  \n",
              "227738  do not you dare touch anything <end>  \n",
              "241713  everyone said that i was wrong <end>  \n",
              "200152     i hope to see you next time <end>  \n",
              "216938    i went hiking with the group <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e1bc177-22be-48fa-950d-955083a2f91c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63501</th>\n",
              "      <td>non cè caldo oggi</td>\n",
              "      <td>&lt;start&gt; it is not hot today &lt;end&gt;</td>\n",
              "      <td>it is not hot today &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227738</th>\n",
              "      <td>non osare toccare nulla</td>\n",
              "      <td>&lt;start&gt; do not you dare touch anything</td>\n",
              "      <td>do not you dare touch anything &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241713</th>\n",
              "      <td>tutti hanno detto che io avevo torto</td>\n",
              "      <td>&lt;start&gt; everyone said that i was wrong</td>\n",
              "      <td>everyone said that i was wrong &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200152</th>\n",
              "      <td>io spero di vederti la prossima volta</td>\n",
              "      <td>&lt;start&gt; i hope to see you next time</td>\n",
              "      <td>i hope to see you next time &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216938</th>\n",
              "      <td>sono andata a fare trekking con il gruppo</td>\n",
              "      <td>&lt;start&gt; i went hiking with the group</td>\n",
              "      <td>i went hiking with the group &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e1bc177-22be-48fa-950d-955083a2f91c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e1bc177-22be-48fa-950d-955083a2f91c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e1bc177-22be-48fa-950d-955083a2f91c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_text(s):\n",
        "  s = \" \".join([ c for c in reversed(s.split())])\n",
        "  return s\n",
        "print(reverse_text(\"I am great machine learning engineer\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLvkmk2Z6eYb",
        "outputId": "87edd337-dceb-466f-f023-c613be744501"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engineer learning machine great am I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_rev = train.copy()\n",
        "validation_rev = validation.copy()\n",
        "\n",
        "\n",
        "def reverse_text(s):\n",
        "  s = \" \".join([ c for c in reversed(s.split())])\n",
        "  return s\n",
        "\n",
        "train_rev.italian = train_rev.italian.apply(reverse_text)\n",
        "validation_rev.italian = validation_rev.italian.apply(reverse_text)"
      ],
      "metadata": {
        "id": "-6gi-GN8576H"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rev.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m346Z8RO8nU1",
        "outputId": "6fc5d6ff-89c9-4ef2-8c01-5b10531e53ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          italian  \\\n",
              "63501                           oggi caldo cè non   \n",
              "227738                    nulla toccare osare non   \n",
              "241713       torto avevo io che detto hanno tutti   \n",
              "200152      volta prossima la vederti di spero io   \n",
              "216938  gruppo il con trekking fare a andata sono   \n",
              "\n",
              "                                   english_inp  \\\n",
              "63501        <start> it is not hot today <end>   \n",
              "227738  <start> do not you dare touch anything   \n",
              "241713  <start> everyone said that i was wrong   \n",
              "200152     <start> i hope to see you next time   \n",
              "216938    <start> i went hiking with the group   \n",
              "\n",
              "                                 english_out  \n",
              "63501        it is not hot today <end> <end>  \n",
              "227738  do not you dare touch anything <end>  \n",
              "241713  everyone said that i was wrong <end>  \n",
              "200152     i hope to see you next time <end>  \n",
              "216938    i went hiking with the group <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-584c33c6-5d06-44e3-b551-d44ef5da23e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63501</th>\n",
              "      <td>oggi caldo cè non</td>\n",
              "      <td>&lt;start&gt; it is not hot today &lt;end&gt;</td>\n",
              "      <td>it is not hot today &lt;end&gt; &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227738</th>\n",
              "      <td>nulla toccare osare non</td>\n",
              "      <td>&lt;start&gt; do not you dare touch anything</td>\n",
              "      <td>do not you dare touch anything &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241713</th>\n",
              "      <td>torto avevo io che detto hanno tutti</td>\n",
              "      <td>&lt;start&gt; everyone said that i was wrong</td>\n",
              "      <td>everyone said that i was wrong &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200152</th>\n",
              "      <td>volta prossima la vederti di spero io</td>\n",
              "      <td>&lt;start&gt; i hope to see you next time</td>\n",
              "      <td>i hope to see you next time &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216938</th>\n",
              "      <td>gruppo il con trekking fare a andata sono</td>\n",
              "      <td>&lt;start&gt; i went hiking with the group</td>\n",
              "      <td>i went hiking with the group &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-584c33c6-5d06-44e3-b551-d44ef5da23e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-584c33c6-5d06-44e3-b551-d44ef5da23e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-584c33c6-5d06-44e3-b551-d44ef5da23e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nimFuXqzsXWH"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nWdidbtsfcq",
        "outputId": "036eb0d5-c596-4453-a31e-f7130b2035a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 22) (64, 22) (64, 22)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 22)\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 22)\n",
        "BATCH = 64\n",
        "train_dataloader = Dataloder(train_dataset, batch_size= BATCH)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size= BATCH)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qiuuG3o_9rGE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5NadnM8vRwW",
        "outputId": "b76a0b3e-50e6-4529-cba9-7349d44c9f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 22) (64, 22) (64, 22)\n"
          ]
        }
      ],
      "source": [
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF9r0KnFvdrt",
        "outputId": "e9321c18-235b-4694-a2b6-204099c58fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[    2,   108,   614, ...,     0,     0,     0],\n",
            "       [    2, 12634,  2072, ...,     0,     0,     0],\n",
            "       [   77,   115,    57, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,    15,    63, ...,     0,     0,     0],\n",
            "       [14941,     9,   307, ...,     0,     0,     0],\n",
            "       [    1,    26,    40, ...,     0,     0,     0]], dtype=int32), array([[   1,   13,    6, ...,    0,    0,    0],\n",
            "       [   1,    9,    7, ...,    0,    0,    0],\n",
            "       [   1,  193,   94, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   1,    3,   74, ...,    0,    0,    0],\n",
            "       [   1,   19, 4099, ...,    0,    0,    0],\n",
            "       [   1,    4,    6, ...,    0,    0,    0]], dtype=int32)]\n"
          ]
        }
      ],
      "source": [
        "print(train_dataloader[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYcmCk5yRkqX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "9cex2XfCLOew"
      },
      "outputs": [],
      "source": [
        "#@title Default title text\n",
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm_units = lstm_size\n",
        "        self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\n",
        "                           mask_zero=True, name=\"embedding\")\n",
        "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True, name=\"encoder_lstm\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        input_embed = self.embedding(input_sequence)\n",
        "        #print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embed, initial_state=states)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "      \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      #self.lstm_output = 0\n",
        "      lstm_state_h= np.zeros((batch_size, self.lstm_units))\n",
        "      lstm_state_c= np.zeros((batch_size, self.lstm_units))\n",
        "      return [tf.keras.backend.constant(lstm_state_h) , tf.keras.backend.constant(lstm_state_c)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziSqOgmhLOe1",
        "outputId": "ab450c14-53fb-4e55-829e-39c02097d0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        self.embedding = Embedding(input_dim=out_vocab_size,output_dim= embedding_size,input_length= input_length , mask_zero= True, name=\"embedding_dec\")\n",
        "        self.lstm = LSTM(units= lstm_size, return_sequences= True, return_state=True, name =\"lstm_dec\")\n",
        "        \n",
        "\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "        \n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        target_embedd   = self.embedding(input_sequence)    \n",
        "        lstm_output, h,c  = self.lstm(target_embedd, initial_state=initial_states)\n",
        "        return lstm_output,h,c # the final lstm_output which is returned is of shape (batch, num_of_sentences, lstm_units)\n",
        "\n",
        "      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B0gokgKLOe8",
        "outputId": "d08dc490-9e45-42a4-8151-06e900411268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXrIj4scLOe_"
      },
      "outputs": [],
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    #encoder_inputs_length,decoder_inputs_length, output_vocab_size\n",
        "    def __init__(self,output_vocab_size, encoder_inputs_length,decoder_inputs_length, *params):\n",
        "        super().__init__()\n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        self.encoder = Encoder(inp_vocab_size= vocab_size_ita+1, embedding_size= 50, input_length=encoder_inputs_length, lstm_size= 128)\n",
        "        self.decoder = Decoder(out_vocab_size= vocab_size_eng+1, embedding_size= 100, input_length=decoder_inputs_length, lstm_size= 128)\n",
        "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
        "  #inp_vocab_size,embedding_size,lstm_size,input_length):       \n",
        "   #out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "    \n",
        "    def call(self,data,*params):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer \n",
        "        \n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        input_sequence , output_sequence = data[0], data[1]\n",
        "        print(\"gh\", output_sequence.shape)\n",
        "        \n",
        "        enc_output, enc_final_state_h, encoder_final_state_c = self.encoder(input_sequence, self.encoder.initialize_states(BATCH) )\n",
        "        dec_output, _ , _ = self.decoder(output_sequence, [enc_final_state_h, encoder_final_state_c ] )\n",
        "        #in teacher forcing, we donot pass dec_output to the lstm at the next instance.\n",
        "        # we pass what we have already have kept in column 'english_input' \n",
        "        # suppose we have an italian sentence encoded as e vector. we pass this as hidden state to decoder lstm and as input we pass <start>\n",
        "        # whose dimension is 100 , here, and its output, i.e, dec_output comes as 100 dimensional vector which is softmaxed into \n",
        "        # number of classes(vocabulary size of english ), and argmax of that is the first translated word, first_en\n",
        "        # what is role of this first_en ?\n",
        "        # it will just help to calculate loss by comparing it to the first word of the corresponding sentence under 'english_output' column\n",
        "        # will not first_en be passed further to the next timestamp LSTM?\n",
        "        # NO. for the next decoder LSTM,  we take the 2nd word of the sentence under 'english_inpuut' col and pass that\n",
        "        # In other words, we are forcing the inputs and hoping the decoder lstm to predict the correct next word \n",
        "        # how successful is our hope is calculated by the word predicted by decoder LSTM \n",
        "        # doubt : the final decoder output is of shape (batch , num_of_words_in_padded_sentence, dec_lstm_units) which is changed to\n",
        "        # (batch, num_of_words_in_padded_sentence, english_vocab)\n",
        "        # i.e, for each word_to_be in padded sentence that is input_to_decoder, we have a probability distribution over all the words present in the vocabulary\n",
        "        # the one which has the highest probab is the predicted word_to_be for that sentence\n",
        "        # and the ground truth is of shape: (batch, num_of_words)\n",
        "        \n",
        "        output = self.dense(dec_output)\n",
        "        return output\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "kcL61dJXLOfB",
        "outputId": "9faa157a-ba67-4a93-aead-214afd031d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gh (64, 22)\n",
            "Epoch 1/20\n",
            "gh (None, None)\n",
            "gh (None, None)\n",
            "4410/4410 [==============================] - ETA: 0s - loss: 0.7701 - accuracy: 0.5597gh (None, None)\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 0.40318, saving model to model/cp.ckpt\n",
            "4410/4410 [==============================] - 337s 75ms/step - loss: 0.7701 - accuracy: 0.5597 - val_loss: 0.4032 - val_accuracy: 0.7269 - lr: 0.0050\n",
            "Epoch 2/20\n",
            "4410/4410 [==============================] - ETA: 0s - loss: 0.3463 - accuracy: 0.7593\n",
            "Epoch 2: val_loss improved from 0.40318 to 0.24278, saving model to model/cp.ckpt\n",
            "4410/4410 [==============================] - 330s 75ms/step - loss: 0.3463 - accuracy: 0.7593 - val_loss: 0.2428 - val_accuracy: 0.8164 - lr: 0.0050\n",
            "Epoch 3/20\n",
            "4409/4410 [============================>.] - ETA: 0s - loss: 0.2434 - accuracy: 0.8152\n",
            "Epoch 3: val_loss improved from 0.24278 to 0.18718, saving model to model/cp.ckpt\n",
            "4410/4410 [==============================] - 330s 75ms/step - loss: 0.2434 - accuracy: 0.8152 - val_loss: 0.1872 - val_accuracy: 0.8505 - lr: 0.0050\n",
            "Epoch 4/20\n",
            "4409/4410 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.8420\n",
            "Epoch 4: val_loss improved from 0.18718 to 0.15819, saving model to model/cp.ckpt\n",
            "4410/4410 [==============================] - 330s 75ms/step - loss: 0.1977 - accuracy: 0.8420 - val_loss: 0.1582 - val_accuracy: 0.8684 - lr: 0.0050\n",
            "Epoch 5/20\n",
            "4409/4410 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.8578"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-252-8402a7cfd4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1429\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1432\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model#,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "model = Encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=22,output_vocab_size=vocab_size_eng)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath= \"model/cp.ckpt\",\n",
        "      save_weights_only=True, \n",
        "      save_best_only = True,\n",
        "      monitor='val_loss',\n",
        "      mode='min', verbose =1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor= 0.8, mode='auto', verbose=1)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience=2, restore_best_weights=True, mode ='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "train_steps=train.shape[0]//BATCH\n",
        "valid_steps=validation.shape[0]//BATCH\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "# ...\n",
        "\n",
        "\n",
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs= 20, validation_data= train_dataloader,  callbacks = [model_checkpoint_callback , reduce_lr, early])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20 epochs , log loss =0.0787, bleu_score(10% random test data) = 81.4%\n",
        "# I will experiment now with reversing the italian texts\n"
      ],
      "metadata": {
        "id": "LHmWCdua5WM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model#,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "model_rev = Encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=22,output_vocab_size=vocab_size_eng)\n",
        "model_checkpoint_callback_rev = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath= \"model_rev/cp.ckpt\",\n",
        "      save_weights_only=True, \n",
        "      save_best_only = True,\n",
        "      monitor='val_loss',\n",
        "      mode='min', verbose =1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor= 0.8, mode='auto', verbose=1)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience=2, restore_best_weights=True, mode ='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "\n",
        "model_rev.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "train_steps=train_rev.shape[0]//BATCH\n",
        "valid_steps=validation_rev.shape[0]//BATCH\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "# ...\n",
        "\n",
        "\n",
        "model_rev.fit(train_dataloader_rev, steps_per_epoch=train_steps, epochs= 20, validation_data= train_dataloader_rev,  callbacks = [model_checkpoint_callback_rev , reduce_lr, early])\n",
        "model_rev.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqJkmapN9Hvk",
        "outputId": "de6c9577-3038-41cf-bd49-30f891490e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 1.5909 - accuracy: 0.2093\n",
            "Epoch 1: val_loss improved from inf to 1.35040, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 73s 246ms/step - loss: 1.5909 - accuracy: 0.2093 - val_loss: 1.3504 - val_accuracy: 0.2661 - lr: 0.0050\n",
            "Epoch 2/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 1.1705 - accuracy: 0.3538\n",
            "Epoch 2: val_loss improved from 1.35040 to 1.00101, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 238ms/step - loss: 1.1705 - accuracy: 0.3538 - val_loss: 1.0010 - val_accuracy: 0.4384 - lr: 0.0050\n",
            "Epoch 3/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.9028 - accuracy: 0.4851\n",
            "Epoch 3: val_loss improved from 1.00101 to 0.78653, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 241ms/step - loss: 0.9028 - accuracy: 0.4851 - val_loss: 0.7865 - val_accuracy: 0.5377 - lr: 0.0050\n",
            "Epoch 4/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.7065 - accuracy: 0.5752\n",
            "Epoch 4: val_loss improved from 0.78653 to 0.60053, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 241ms/step - loss: 0.7065 - accuracy: 0.5752 - val_loss: 0.6005 - val_accuracy: 0.6246 - lr: 0.0050\n",
            "Epoch 5/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.6529\n",
            "Epoch 5: val_loss improved from 0.60053 to 0.46162, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 65s 236ms/step - loss: 0.5457 - accuracy: 0.6529 - val_loss: 0.4616 - val_accuracy: 0.6964 - lr: 0.0050\n",
            "Epoch 6/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.4280 - accuracy: 0.7145\n",
            "Epoch 6: val_loss improved from 0.46162 to 0.36344, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.4280 - accuracy: 0.7145 - val_loss: 0.3634 - val_accuracy: 0.7504 - lr: 0.0050\n",
            "Epoch 7/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.7615\n",
            "Epoch 7: val_loss improved from 0.36344 to 0.29497, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 65s 238ms/step - loss: 0.3447 - accuracy: 0.7615 - val_loss: 0.2950 - val_accuracy: 0.7908 - lr: 0.0050\n",
            "Epoch 8/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.2863 - accuracy: 0.7962\n",
            "Epoch 8: val_loss improved from 0.29497 to 0.24443, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.2863 - accuracy: 0.7962 - val_loss: 0.2444 - val_accuracy: 0.8238 - lr: 0.0050\n",
            "Epoch 9/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8220\n",
            "Epoch 9: val_loss improved from 0.24443 to 0.21090, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.2440 - accuracy: 0.8220 - val_loss: 0.2109 - val_accuracy: 0.8456 - lr: 0.0050\n",
            "Epoch 10/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.8423\n",
            "Epoch 10: val_loss improved from 0.21090 to 0.18405, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.2122 - accuracy: 0.8423 - val_loss: 0.1841 - val_accuracy: 0.8625 - lr: 0.0050\n",
            "Epoch 11/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.8586\n",
            "Epoch 11: val_loss improved from 0.18405 to 0.16299, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.1875 - accuracy: 0.8586 - val_loss: 0.1630 - val_accuracy: 0.8776 - lr: 0.0050\n",
            "Epoch 12/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.8717\n",
            "Epoch 12: val_loss improved from 0.16299 to 0.14623, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.1682 - accuracy: 0.8717 - val_loss: 0.1462 - val_accuracy: 0.8886 - lr: 0.0050\n",
            "Epoch 13/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.8821\n",
            "Epoch 13: val_loss improved from 0.14623 to 0.13247, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.1523 - accuracy: 0.8821 - val_loss: 0.1325 - val_accuracy: 0.8990 - lr: 0.0050\n",
            "Epoch 14/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.8911\n",
            "Epoch 14: val_loss improved from 0.13247 to 0.12206, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.1395 - accuracy: 0.8911 - val_loss: 0.1221 - val_accuracy: 0.9058 - lr: 0.0050\n",
            "Epoch 15/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.8988\n",
            "Epoch 15: val_loss improved from 0.12206 to 0.11227, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.1284 - accuracy: 0.8988 - val_loss: 0.1123 - val_accuracy: 0.9129 - lr: 0.0050\n",
            "Epoch 16/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9049\n",
            "Epoch 16: val_loss improved from 0.11227 to 0.10475, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.1194 - accuracy: 0.9049 - val_loss: 0.1047 - val_accuracy: 0.9180 - lr: 0.0050\n",
            "Epoch 17/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9108\n",
            "Epoch 17: val_loss improved from 0.10475 to 0.09756, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 239ms/step - loss: 0.1114 - accuracy: 0.9108 - val_loss: 0.0976 - val_accuracy: 0.9233 - lr: 0.0050\n",
            "Epoch 18/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9160\n",
            "Epoch 18: val_loss improved from 0.09756 to 0.09142, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 68s 246ms/step - loss: 0.1041 - accuracy: 0.9160 - val_loss: 0.0914 - val_accuracy: 0.9271 - lr: 0.0050\n",
            "Epoch 19/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9197\n",
            "Epoch 19: val_loss improved from 0.09142 to 0.08603, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 241ms/step - loss: 0.0985 - accuracy: 0.9197 - val_loss: 0.0860 - val_accuracy: 0.9315 - lr: 0.0050\n",
            "Epoch 20/20\n",
            "275/275 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.9237\n",
            "Epoch 20: val_loss improved from 0.08603 to 0.08230, saving model to model_rev/cp.ckpt\n",
            "275/275 [==============================] - 66s 240ms/step - loss: 0.0930 - accuracy: 0.9237 - val_loss: 0.0823 - val_accuracy: 0.9335 - lr: 0.0050\n",
            "Model: \"encoder_decoder_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_22 (Encoder)        multiple                  1421498   \n",
            "                                                                 \n",
            " decoder_22 (Decoder)        multiple                  1428048   \n",
            "                                                                 \n",
            " dense_19 (Dense)            multiple                  1690803   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,540,349\n",
            "Trainable params: 4,540,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(train_dataloader[][0]).shape, train_dataloader[0][1].shape"
      ],
      "metadata": {
        "id": "2tCUwNC-LrDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"seq_seq_loss0.077\", save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6QvchKWO9ZR",
        "outputId": "cb28b6b5-2d05-46e4-f642-b02672dfa224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_38_layer_call_fn, lstm_cell_38_layer_call_and_return_conditional_losses, lstm_cell_39_layer_call_fn, lstm_cell_39_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: seq_seq_loss0.077/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: seq_seq_loss0.077/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7ef845194e10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7ef845107650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = tf.keras.models.load_model(\"seq_seq_loss0.077\")"
      ],
      "metadata": {
        "id": "Q9NyssGWkz-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "hpGGLUIY8gVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2byC3nd-9nXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.random.randint(0, 499, size=(2000, 30))\n",
        "output = np.random.randint(0, 499, size=(2000, 20))\n",
        "target = tf.keras.utils.to_categorical(output, 500)"
      ],
      "metadata": {
        "id": "nLE2XL0TxJs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "V2A-nBVdvnDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.choice(10, 3)"
      ],
      "metadata": {
        "id": "aDr6IF1dzKh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "scores = []\n",
        "for j in tqdm(np.random.choice(len(validation.italian.values),len(validation.italian.values)//10 )):\n",
        "  encoder_seq = tknizer_ita.texts_to_sequences([validation.italian.values[j]]) # need to pass list of values\n",
        "  #decoder_inp_seq = tknizer_eng.texts_to_sequences([validation.english_inp.values[i]])\n",
        "  #decoder_out_seq = tknizer_eng.texts_to_sequences([validation.english_out.values[i]])\n",
        "\n",
        "  encoder_seq = pad_sequences(encoder_seq, maxlen= 20, dtype='int32', padding='post')\n",
        "  input_enc = encoder_seq[0]\n",
        "  #decoder_inp_seq = pad_sequences(decoder_inp_seq, maxlen= 20, dtype='int32', padding='post')\n",
        "  #decoder_out_seq = pad_sequences(decoder_out_seq, maxlen=20, dtype='int32', padding='post')\n",
        "  enc_output, enc_state_h, enc_state_c = model.layers[0](np.expand_dims(input_enc , 0) , states = model.layers[0].initialize_states(1) )\n",
        "  states_values = [enc_state_h, enc_state_c]\n",
        "  \n",
        "  pred = []\n",
        "  cur_vec = np.zeros((1, 1))\n",
        "  #print('-'*20,\"started predition\",\"-\"*20)\n",
        "  #print(\"at time step 0 the word is 0\")\n",
        "\n",
        "  for i in range(20):\n",
        "      cur_emb = model.layers[1].embedding(cur_vec)\n",
        "      [infe_output, state_h, state_c] = model.layers[1].lstm(cur_emb, initial_state=states_values)\n",
        "      infe_output=model.layers[2](infe_output)\n",
        "      states_values = [state_h, state_c]\n",
        "      # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
        "      # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
        "      cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "      #print(f\"at time step {i} the word is \", tknizer_eng.sequences_to_texts(cur_vec))\n",
        "      pred.append(tknizer_eng.sequences_to_texts(cur_vec)[0])\n",
        "  pred2  = [ wd for wd in pred[1:] if wd !='<end>' ]\n",
        "  translation =' '.join(pred2)\n",
        "  pred = []\n",
        "  #print(\"ground\", validation.english_inp.values[j][7:])\n",
        "  #print(\"translation\", translation)\n",
        "  preds.append(bleu.sentence_bleu( validation.english_inp.values[j][7:], translation))\n",
        "  #print(\"preds\",preds)\n",
        "  \n",
        "\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9vVFrHd2Ws9",
        "outputId": "a0a9f854-45b4-4aa3-8a91-db0d252ad7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7057 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "100%|██████████| 7057/7057 [14:49<00:00,  7.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = np.mean(preds)\n",
        "std = np.std(preds)\n",
        "conf_int = ( score - 1.98*std/(len(preds)**0.5) , score + 1.98*std/(len(preds)**0.5) )\n",
        "print(\"bleu score with 95% conf interval\", conf_int)\n",
        "print(\"mean bleu score is\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIdalyt90D5L",
        "outputId": "f9ebcf47-25a0-455e-cf73-1fbcf6aad56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bleu score with 95% conf interval (0.8129167186230079, 0.8154510755218204)\n",
            "mean bleu score is 0.8141838970724141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "scores = []\n",
        "for j in tqdm(np.random.choice(len(validation_rev.italian.values),len(validation_rev.italian.values)//10 )):\n",
        "  encoder_seq = tknizer_ita.texts_to_sequences([validation_rev.italian.values[j]]) # need to pass list of values\n",
        "  #decoder_inp_seq = tknizer_eng.texts_to_sequences([validation.english_inp.values[i]])\n",
        "  #decoder_out_seq = tknizer_eng.texts_to_sequences([validation.english_out.values[i]])\n",
        "\n",
        "  encoder_seq = pad_sequences(encoder_seq, maxlen= 20, dtype='int32', padding='post')\n",
        "  input_enc = encoder_seq[0]\n",
        "  #decoder_inp_seq = pad_sequences(decoder_inp_seq, maxlen= 20, dtype='int32', padding='post')\n",
        "  #decoder_out_seq = pad_sequences(decoder_out_seq, maxlen=20, dtype='int32', padding='post')\n",
        "  enc_output, enc_state_h, enc_state_c = model_rev.layers[0](np.expand_dims(input_enc , 0) , states = model_rev.layers[0].initialize_states(1) )\n",
        "  states_values = [enc_state_h, enc_state_c]\n",
        "  \n",
        "  pred = []\n",
        "  cur_vec = np.zeros((1, 1))\n",
        "  #print('-'*20,\"started predition\",\"-\"*20)\n",
        "  #print(\"at time step 0 the word is 0\")\n",
        "\n",
        "  for i in range(20):\n",
        "      cur_emb = model_rev.layers[1].embedding(cur_vec)\n",
        "      [infe_output, state_h, state_c] = model.layers[1].lstm(cur_emb, initial_state=states_values)\n",
        "      infe_output=model_rev.layers[2](infe_output)\n",
        "      states_values = [state_h, state_c]\n",
        "      # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
        "      # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
        "      cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "      #print(f\"at time step {i} the word is \", tknizer_eng.sequences_to_texts(cur_vec))\n",
        "      pred.append(tknizer_eng.sequences_to_texts(cur_vec)[0])\n",
        "  pred2  = [ wd for wd in pred[1:] if wd !='<end>' ]\n",
        "  translation =' '.join(pred2)\n",
        "  pred = []\n",
        "  #print(\"ground\", validation.english_inp.values[j][7:])\n",
        "  #print(\"translation\", translation)\n",
        "  preds.append(bleu.sentence_bleu( validation_rev.english_inp.values[j][7:], translation))\n",
        "  #print(\"preds\",preds)\n",
        "  \n",
        "\n",
        "      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "larYDyGwRo1a",
        "outputId": "11c1c3a3-a292-48b8-eec3-4a03f2b694e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7057 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "100%|██████████| 7057/7057 [15:28<00:00,  7.60it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_rev = np.mean(preds)\n",
        "std_rev = np.std(preds)\n",
        "conf_int_rev = ( score_rev - 1.98*std_rev/(len(preds)**0.5) , score + 1.98*std_rev/(len(preds)**0.5) )\n",
        "print(\"bleu score with 95% conf interval in case of model using reverse italian texts \", conf_int_rev)\n",
        "print(\"mean bleu score in case of model using reverse italian texts is\", score_rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ielGenrhSIpR",
        "outputId": "ea8b1187-e21d-41cb-fe10-9d46af18bfe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bleu score with 95% conf interval in case of model using reverse italian texts  (0.5652923734630124, 0.8149485642041551)\n",
            "mean bleu score in case of model using reverse italian texts is 0.5660570405947534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('seq_seq_weights', save_format='tf')"
      ],
      "metadata": {
        "id": "co2KCzoQyY5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model#,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "k = Encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=22,output_vocab_size=vocab_size_eng)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "\n",
        "k.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "# ...\n",
        "\n",
        "\n",
        "#k.fit(train_dataloader, steps_per_epoch=train_steps, epochs= 20, validation_data= train_dataloader,  callbacks = [model_checkpoint_callback , reduce_lr, early])\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "BVic5fqM30Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.load_weights('seq_seq_weights')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWiMkcxD4lXQ",
        "outputId": "3c03ce4e-6399-4b97-b632-9406a79c26a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ef83bdfb790>"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "suFpBrKhv_ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "BZ5ULFDPE_vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var= 21\n",
        "print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
        "input_enc = tknizer_ita.texts_to_sequences([validation.italian.values[var]])\n",
        "print(validation.italian.values[var])\n",
        "print(validation.english_inp.values[var][7:])\n",
        "input_enc = pad_sequences(input_enc, maxlen= 20, dtype='int32', padding='post')[0]\n",
        "enc_output, enc_state_h, enc_state_c = k.layers[0](np.expand_dims(input_enc , 0) , states = k.layers[0].initialize_states(1) )\n",
        "states_values = [enc_state_h, enc_state_c]\n",
        "pred = []\n",
        "cur_vec = np.zeros((1, 1))\n",
        "print('-'*20,\"started predition\",\"-\"*20)\n",
        "#print(\"at time step 0 the word is 0\")\n",
        "for i in range(22):\n",
        "    cur_emb = k.layers[1].embedding(cur_vec)\n",
        "    [infe_output, state_h, state_c] = k.layers[1].lstm(cur_emb, initial_state=states_values)\n",
        "    infe_output= k.layers[2](infe_output)\n",
        "    states_values = [state_h, state_c]\n",
        "    # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
        "    # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
        "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "    print(f\"at time step {i} the word is \", tknizer_eng.sequences_to_texts(cur_vec))\n",
        "    pred.append(tknizer_eng.sequences_to_texts(cur_vec))"
      ],
      "metadata": {
        "id": "wM9JlJjy5cTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20323ded-49c7-4528-bce2-bb15cb831d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "noi predomineremo\n",
            " we will prevail\n",
            "-------------------- started predition --------------------\n",
            "at time step 0 the word is  ['end']\n",
            "at time step 1 the word is  ['we']\n",
            "at time step 2 the word is  ['would']\n",
            "at time step 3 the word is  ['<end>']\n",
            "at time step 4 the word is  ['<end>']\n",
            "at time step 5 the word is  ['<end>']\n",
            "at time step 6 the word is  ['<end>']\n",
            "at time step 7 the word is  ['<end>']\n",
            "at time step 8 the word is  ['<end>']\n",
            "at time step 9 the word is  ['<end>']\n",
            "at time step 10 the word is  ['<end>']\n",
            "at time step 11 the word is  ['<end>']\n",
            "at time step 12 the word is  ['<end>']\n",
            "at time step 13 the word is  ['<end>']\n",
            "at time step 14 the word is  ['<end>']\n",
            "at time step 15 the word is  ['<end>']\n",
            "at time step 16 the word is  ['<end>']\n",
            "at time step 17 the word is  ['<end>']\n",
            "at time step 18 the word is  ['<end>']\n",
            "at time step 19 the word is  ['<end>']\n",
            "at time step 20 the word is  ['<end>']\n",
            "at time step 21 the word is  ['<end>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var= 21\n",
        "print(\"=\" * 30, \"Inference\", \"=\" * 30)\n",
        "input_enc = tknizer_ita.texts_to_sequences([validation.italian.values[var]])\n",
        "print(validation.italian.values[var])\n",
        "print(validation.english_inp.values[var][7:])\n",
        "input_enc = pad_sequences(input_enc, maxlen= 20, dtype='int32', padding='post')[0]\n",
        "enc_output, enc_state_h, enc_state_c = model.layers[0](np.expand_dims(input_enc , 0) , states = model.layers[0].initialize_states(1) )\n",
        "states_values = [enc_state_h, enc_state_c]\n",
        "pred = []\n",
        "cur_vec = np.zeros((1, 1))\n",
        "print('-'*20,\"started predition\",\"-\"*20)\n",
        "#print(\"at time step 0 the word is 0\")\n",
        "for i in range(22):\n",
        "    cur_emb = model.layers[1].embedding(cur_vec)\n",
        "    [infe_output, state_h, state_c] = model.layers[1].lstm(cur_emb, initial_state=states_values)\n",
        "    infe_output=model.layers[2](infe_output)\n",
        "    states_values = [state_h, state_c]\n",
        "    # np.argmax(infe_output) will be a single value, which represents the the index of predicted word\n",
        "    # but to pass this data into next time step embedding layer, we are reshaping it into (1,1) shape\n",
        "    cur_vec = np.reshape(np.argmax(infe_output), (1, 1))\n",
        "    print(f\"at time step {i} the word is \", tknizer_eng.sequences_to_texts(cur_vec))\n",
        "    pred.append(tknizer_eng.sequences_to_texts(cur_vec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MoPaAWjxGnW",
        "outputId": "73126ae4-a388-42e7-f6f0-018bfa183eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================== Inference ==============================\n",
            "noi predomineremo\n",
            " we will prevail\n",
            "-------------------- started predition --------------------\n",
            "at time step 0 the word is  ['end']\n",
            "at time step 1 the word is  ['we']\n",
            "at time step 2 the word is  ['would']\n",
            "at time step 3 the word is  ['<end>']\n",
            "at time step 4 the word is  ['<end>']\n",
            "at time step 5 the word is  ['<end>']\n",
            "at time step 6 the word is  ['<end>']\n",
            "at time step 7 the word is  ['<end>']\n",
            "at time step 8 the word is  ['<end>']\n",
            "at time step 9 the word is  ['<end>']\n",
            "at time step 10 the word is  ['<end>']\n",
            "at time step 11 the word is  ['<end>']\n",
            "at time step 12 the word is  ['<end>']\n",
            "at time step 13 the word is  ['<end>']\n",
            "at time step 14 the word is  ['<end>']\n",
            "at time step 15 the word is  ['<end>']\n",
            "at time step 16 the word is  ['<end>']\n",
            "at time step 17 the word is  ['<end>']\n",
            "at time step 18 the word is  ['<end>']\n",
            "at time step 19 the word is  ['<end>']\n",
            "at time step 20 the word is  ['<end>']\n",
            "at time step 21 the word is  ['<end>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred2  = [ c for c in pred[1:] if c !='<end>' ]\n",
        "' '.join(pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2SGRkzahsTU7",
        "outputId": "dd40cc1a-22de-45f9-8644-ea51cffd7f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'that is like mary in five years'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation.italian.values[1]"
      ],
      "metadata": {
        "id": "DTgI-Xab9Uhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_eng.sequences_to_texts([[10347]])"
      ],
      "metadata": {
        "id": "5Bp6lPvn8ffV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7F53xabWU60"
      },
      "outputs": [],
      "source": [
        "model.save_weights('translation_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkARSlZgLOfE"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MUQLsc2lwC-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "996pFO8BLOfG"
      },
      "outputs": [],
      "source": [
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "#Sample example\n",
        "import nltk.translate.bleu_score as bleu\n",
        "reference = ['i am groot'.split(),] # the original\n",
        "translation = 'i am groot'.split() # trasilated using model\n",
        "print('BLEU score: {}'.format(bleu.sentence_bleu(reference, translation)))"
      ],
      "metadata": {
        "id": "vbezjeX4uJyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba13edc-90c8-459f-cf58-37a85ada0f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu.sentence_bleu('i am okay', 'bad i am')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVElAFXaur9Z",
        "outputId": "c36d7858-95b3-41a0-9a0f-0488347fef3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8408964152537145"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##@title Default title text\n",
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        self.lstm_units = lstm_size\n",
        "        self.embedding = Embedding(input_dim=inp_vocab_size, output_dim=embedding_size, input_length=input_length,\n",
        "                           mask_zero=True, name=\"embedding\")\n",
        "        self.lstm = LSTM(lstm_size, return_state=True, return_sequences=True, name=\"encoder_lstm\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        input_embed = self.embedding(input_sequence)\n",
        "        #print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embed, initial_state=states)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "      \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      #self.lstm_output = 0\n",
        "      lstm_state_h= np.zeros((batch_size, self.lstm_units))\n",
        "      lstm_state_c= np.zeros((batch_size, self.lstm_units))\n",
        "      return [tf.keras.backend.constant(lstm_state_h) , tf.keras.backend.constant(lstm_state_c)]\n"
      ],
      "metadata": {
        "id": "3mgnwpxYvS-J"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wRoe65b9LB0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40a2346-5c56-43fa-f978-493cb3c3ee72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "outputs": [],
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "  '''\n",
        "    Class the calculates score based on the scoring_function using Bahdanu attention mechanism.\n",
        "  '''\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    # Please go through the reference notebook and research paper to complete the scoring functions\n",
        "    self.scoring_function = scoring_function\n",
        "    self.att_units = att_units\n",
        "    if self.scoring_function=='dot':\n",
        "      # Intialize variables needed for Dot score function here\n",
        "      pass\n",
        "    if scoring_function == 'general':\n",
        "      # Intialize variables needed for General score function here\n",
        "      pass\n",
        "    elif scoring_function == 'concat':\n",
        "      # Intialize variables needed for Concat score function here\n",
        "      pass\n",
        "  \n",
        "  \n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''\n",
        "      Attention mechanism takes two inputs current step -- decoder_hidden_state and all the encoder_outputs.\n",
        "      * Based on the scoring function we will find the score or similarity between decoder_hidden_state and encoder_output.\n",
        "        Multiply the score function with your encoder_outputs to get the context vector.\n",
        "        Function returns context vector and attention weights(softmax - scores)\n",
        "    '''\n",
        "    \n",
        "    if self.scoring_function == 'dot':\n",
        "        # Implement Dot score function here\n",
        "        #note that decoder_hidden_state at a time will be 2d matrix (1024, num_of_decoder_units) # it is hidden state at a particular time.\n",
        "        #and encoder output will be like (1024, num_of_words_in_input_sent(padded one), num_of_enc_units)\n",
        "        dec_h = tf.expand_dims(decoder_hidden_state, -1) # shape (1024, num_decoder_units, 1)\n",
        "        dot_pdt = tf.matmul(encoder_output, dec_h) # shape (1024, num_words_input_sent, 1)\n",
        "        weights = tf.nn.softmax(dot_pdt, axis=1) # axis =1 means num_words_input_sent  which is the total number of hidden states by encoder\n",
        "        context = weights*encoder_output # weighted encoder outputs\n",
        "        #print(context.shape)\n",
        "        context_vector = tf.reduce_sum(context, axis =1)\n",
        "        return context_vector, weights\n",
        " \n",
        "    elif self.scoring_function == 'general':\n",
        "        # Implement General score function here\n",
        "        #note that decoder_hidden_state at a time will be 2d matrix (1024, num_of_decoder_units) # it is hidden state at a particular time.\n",
        "        #and encoder output will be like (1024, num_of_words_in_input_sent(padded one), num_of_enc_units)\n",
        "        dec_h = tf.expand_dims(decoder_hidden_state, -1) # shape (1024, num_decoder_units, 1)\n",
        "        p=tf.keras.layers.Dense(self.att_units)(encoder_output) # 256 , actually here is number of decoder units # in our case dec_units = enc_units\n",
        "\n",
        "        gen_pdt = tf.matmul(p, dec_h) # shape (1024, num_words_input_sent, 1)\n",
        "        weights = tf.nn.softmax(gen_pdt, axis=1) # axis =1 means num_words_input_sent  which is the total number of hidden states by encoder\n",
        "        context = weights*encoder_output # weighted encoder outputs\n",
        "        context = tf.reduce_sum(context, axis =1)\n",
        "        return context, weights\n",
        "\n",
        "    elif self.scoring_function == 'concat':\n",
        "        # Implement General score function here\n",
        "        dec_h = tf.expand_dims(decoder_hidden_state, 1) # shape (1024, num_decoder_units, 1)\n",
        "        concat = encoder_output + dec_h\n",
        "        #print(\"concat\", concat.shape)\n",
        "        tanh_concat = tf.keras.activations.tanh(concat)\n",
        "        dense_concat = tf.keras.layers.Dense(1)(tanh_concat) #it acts as multiplication with vT\n",
        "        #print(\"dense\",dense_concat.shape)\n",
        "        #gen_pdt = tf.keras.layers.Dense() # shape (1024, num_words_input_sent, 1)\n",
        "        weights = tf.nn.softmax(dense_concat, axis=1) # axis =1 means num_words_input_sent  which is the total number of hidden states by encoder\n",
        "        #print(\"weights\", weights.shape)\n",
        "        context = weights*concat # weighted encoder outputs\n",
        "        \n",
        "        context_vector = tf.reduce_sum(context, axis =1)\n",
        "        return context_vector,weights\n",
        "        pass\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "\"\"\"class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self,scoring_function, att_units):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.scoring_function = scoring_function\n",
        "        self.att_units = att_units\n",
        "\n",
        "        if self.scoring_function=='dot':\n",
        "            pass\n",
        "            # For general, it would be self.wa = tf.keras.layers.Dense(att_units)\n",
        "\n",
        "\n",
        "    def call(self,decoder_hidden_state,encoder_output):\n",
        "\n",
        "        if self.scoring_function == 'dot':\n",
        "            \n",
        "            new_state = tf.expand_dims(decoder_hidden_state, -1)\n",
        "            score = tf.matmul(encoder_output, new_state)\n",
        "            weights = tf.nn.softmax(score, axis=1)\n",
        "            context = weights * encoder_output\n",
        "            context_vector = tf.reduce_sum(context, axis=1)\n",
        "                                \n",
        "            return context_vector, weights\"\"\""
      ],
      "metadata": {
        "id": "jNtZi5JlF085"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51x50h_TLrl9"
      },
      "outputs": [],
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    print(context_vector.shape)\n",
        "    print(attention_weights.shape)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grader_check_attention('concat'))"
      ],
      "metadata": {
        "id": "3Dhg6PYd9raw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grader_check_attention('dot'))"
      ],
      "metadata": {
        "id": "yDpHyg3Hv6ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "outputs": [],
      "source": [
        "class OneStepDecoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "    \n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "      # Initialize decoder embedding layer, LSTM and any other objects needed\n",
        "        super().__init__()\n",
        "        self.tar_vocab_size = tar_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.dec_units = dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "        self.embedding = tf.keras.layers.Embedding(self.tar_vocab_size, self.embedding_dim, \n",
        "                                                   input_length=self.input_length)\n",
        "        \n",
        "        self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, \n",
        "                                         return_state=True)\n",
        "        \n",
        "        self.output_layer = tf.keras.layers.Dense(self.tar_vocab_size)\n",
        "        \n",
        "        self.attention = Attention(self.score_fun, self.att_units)\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    '''\n",
        "        One step decoder mechanisim step by step:\n",
        "      A. Pass the input_to_decoder to the embedding layer and then get the output(batch_size,1,embedding_dim)\n",
        "      B. Using the encoder_output and decoder hidden state, compute the context vector.\n",
        "      C. Concat the context vector with the step A output\n",
        "      D. Pass the Step-C output to LSTM/GRU and get the decoder output and states(hidden and cell state)\n",
        "      E. Pass the decoder output to dense layer(vocab size) and store the result into output.\n",
        "      F. Return the states from step D, output from Step E, attention weights from Step -B\n",
        "    '''\n",
        "    result = self.embedding(input_to_decoder)\n",
        "        \n",
        "    context_vector, weights = self.attention(state_h, encoder_output)\n",
        "    \n",
        "    concat = tf.concat([tf.expand_dims(context_vector, 1), result], axis=-1)\n",
        "    \n",
        "    decoder_output, hidden_state, cell_state = self.lstm(concat, initial_state=[state_h, state_c])\n",
        "    \n",
        "    final_output = tf.reshape(decoder_output, (-1, decoder_output.shape[2]))\n",
        "    final_output = self.output_layer(final_output)\n",
        "    \n",
        "    return final_output, hidden_state, cell_state, weights, context_vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLEXhChnMC1k"
      },
      "outputs": [],
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=OneStepDecoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size = out_vocab_size\n",
        "      self.embedding_dim = embedding_dim\n",
        "      self.input_length = input_length\n",
        "      self.dec_units = dec_units\n",
        "      self.score_fun = score_fun\n",
        "      self.att_units = att_units\n",
        "      self.onestepdecoder = OneStepDecoder(self.out_vocab_size, self.embedding_dim, self.input_length,\n",
        "                                              self.dec_units, self.score_fun, self.att_units)\n",
        "      self.dense = Dense(out_vocab_size , activation='softmax')\n",
        "\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "        all_outputs= tf.TensorArray(tf.float32, size=22, name=\"output_arrays\")\n",
        "        \n",
        "        \n",
        "        for timestep in range(22):# input_to_decoder's shape = (batch_size, num_of_words_in_set(padded), embedded_dims) \n",
        "        #so, input_to_decoder.shape[1] = 22 is count of time-steps\n",
        "        # each word = input_to_decoder[:, timestep: timestep+1] ( : in 0 axis because we take whole batch )\n",
        "        # we send encoder output which we already have before coming to decoder as encoder has already run\n",
        "        # decoder_hidden_state is previous decoder_hidden_state which we have gotten when we passed previous word(previous timestep) to onestepdecoder.\n",
        "            output, decoder_hidden_state, decoder_cell_state, weights, context_vector = self.onestepdecoder(\n",
        "                                                                                    input_to_decoder[:,timestep:timestep+1], \n",
        "                                                                                    encoder_output, \n",
        "                                                                                    decoder_hidden_state,\n",
        "                                                                                    decoder_cell_state)\n",
        "            \n",
        "            all_outputs = all_outputs.write(timestep, output) # it is just like list.append . The difference is that all_outputs has a fixed size.\n",
        "        \n",
        "        print(all_outputs)\n",
        "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2))\n",
        "        #print(all_outputs) \n",
        "        #all_outputs = self.dense(all_outputs)\n",
        "\n",
        "        return all_outputs\n",
        "        \n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtbx6onFMJXb"
      },
      "outputs": [],
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=1024\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "#print(grader_decoder('general'))\n",
        "#print(grader_decoder('concat'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "outputs": [],
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "  def __init__(self, inp_vocab_size, out_vocab_size, embedding_size, lstm_size, \n",
        "                 input_length, output_length, dec_units ,score_fun ,att_units, batch_size):#params):\n",
        "    #Intialize objects from encoder decoder\n",
        "    super().__init__()       \n",
        "    self.encoder = Encoder(inp_vocab_size, embedding_size, lstm_size, input_length)\n",
        "    self.decoder = Decoder(out_vocab_size, embedding_size, output_length, \n",
        "                            dec_units, score_fun, att_units)\n",
        "\n",
        "\n",
        "  @tf.function \n",
        "  def call(self,data):\n",
        "    #Intialize encoder states, Pass the encoder_sequence to the embedding layer\n",
        "    # Decoder initial states are encoder final states, Initialize it accordingly\n",
        "    # Pass the decoder sequence,encoder_output,decoder states to Decoder\n",
        "    # return the decoder output\n",
        "    input_sequence, input_to_decoder = data[0],data[1]\n",
        "    initial_state = self.encoder.initialize_states(batch_size= 64)\n",
        "    print(\"input to decoder's shape :\",input_to_decoder.shape)\n",
        "    encoder_output, state_h, state_c = self.encoder(input_sequence, initial_state)\n",
        "    decoder_hidden_state = state_h\n",
        "    decoder_cell_state = state_c\n",
        "    decoder_output = self.decoder(input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\n",
        "    \n",
        "    return decoder_output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = vocab_size_ita +1\n",
        "output_vocab_size = vocab_size_eng +1\n",
        "\n",
        "input_len = 22\n",
        "output_len = 22\n",
        "\n",
        "lstm_size = 128\n",
        "att_units = 128\n",
        "dec_units = 128\n",
        "embedding_size = 100\n",
        "embedding_dim = 100\n",
        "score_fun = 'dot'\n",
        "\n",
        "train_steps=train.shape[0]//BATCH\n",
        "valid_steps=validation.shape[0]//BATCH\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor= 0.8, mode='auto', verbose=1)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience=2, restore_best_weights=True, mode ='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "model = encoder_decoder(input_vocab_size,output_vocab_size,embedding_size,lstm_size,input_len,output_len,dec_units,score_fun,att_units, BATCH)"
      ],
      "metadata": {
        "id": "UdG-zuozRHpl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)//64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaIIS3i6UObA",
        "outputId": "04e08f2f-b881-40ee-fce3-d203f3653ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4410"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs= 2, validation_data= train_dataloader,  callbacks = [reduce_lr, early ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "ohlzVaYz4oTa",
        "outputId": "6eca4906-9c4a-44ce-9e27-99ab4776b7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to decoder's shape : (64, 22)\n",
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6d928e6fd0>\n",
            "Epoch 1/2\n",
            "input to decoder's shape : (None, None)\n",
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6a58f00e90>\n",
            "input to decoder's shape : (None, None)\n",
            "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6a562f8990>\n",
            "2640/4410 [================>.............] - ETA: 7:21 - loss: 0.7064 - accuracy: 0.8744"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-86eca38d7cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "outputs": [],
      "source": [
        "#https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgyWwZWeMxGQ"
      },
      "outputs": [],
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir logs\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"attention.h5\", monitor='val_loss', verbose=1, save_weights_only=True)\n",
        "\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='attention_logs')\n",
        "\n",
        "\n",
        "train_steps=train.shape[0]//BATCH\n",
        "valid_steps=validation.shape[0]//BATCH\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor= 0.8, mode='auto', verbose=1)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience=2, restore_best_weights=True, mode ='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "#model = encoder_decoder(input_vocab_size,output_vocab_size,embedding_size,lstm_size,input_len,output_len,dec_units,score_fun,att_units, BATCH)\n",
        "#model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "pq6P-bx2bxls"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,loss= loss_function, metrics=[\"accuracy\"])\n",
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs= 2, validation_data= train_dataloader,  callbacks = [checkpoint , reduce_lr, early ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdkhPKtkVHOt",
        "outputId": "649e7e39-c0c9-42ad-ca7f-4a17a06ff1c3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4410/4410 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.1816\n",
            "Epoch 1: saving model to attention.h5\n",
            "4410/4410 [==============================] - 419s 92ms/step - loss: 0.7508 - accuracy: 0.1816 - val_loss: 0.3265 - val_accuracy: 0.2420 - lr: 0.0050\n",
            "Epoch 2/2\n",
            "4410/4410 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.2497\n",
            "Epoch 2: saving model to attention.h5\n",
            "4410/4410 [==============================] - 398s 90ms/step - loss: 0.2818 - accuracy: 0.2497 - val_loss: 0.1956 - val_accuracy: 0.2644 - lr: 0.0050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f87f8580d90>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader[1][0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuZ5o0z1fOC4",
        "outputId": "c1fcb761-85a7-4743-c54e-e13d13be565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create an object of encoder_decoder Model class, \n",
        "# Compile the model and fit the model#,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "#model = Encoder_decoder(encoder_inputs_length=22,decoder_inputs_length=22,output_vocab_size=vocab_size_eng)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "      filepath= \"model/cp.ckpt\",\n",
        "      save_weights_only=True, \n",
        "      save_best_only = True,\n",
        "      monitor='val_loss',\n",
        "      mode='min', verbose =1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, factor= 0.8, mode='auto', verbose=1)\n",
        "early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',patience=2, restore_best_weights=True, mode ='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.005)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "train_steps=train.shape[0]//BATCH\n",
        "valid_steps=validation.shape[0]//BATCH\n",
        "\n",
        "#optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "# ...\n",
        "\n",
        "\n",
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs= 20, validation_data= train_dataloader,  callbacks = [model_checkpoint_callback , reduce_lr, early])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "QBq78Wz4cf-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkEY7SsBMtrC"
      },
      "outputs": [],
      "source": [
        "def plot_attention(#params):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3kLZoPMvSu"
      },
      "outputs": [],
      "source": [
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iHiLdROM23l"
      },
      "outputs": [],
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "#Sample example\n",
        "import nltk.translate.bleu_score as bleu\n",
        "reference = ['i am groot'.split(),] # the original\n",
        "translation = 'it is ship'.split() # trasilated using model\n",
        "print('BLEU score: {}'.format(bleu.sentence_bleu(reference, translation)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rh9_w79M5JO"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kN9ZWViQNMB"
      },
      "outputs": [],
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff1lV0ITM6_p"
      },
      "outputs": [],
      "source": [
        "# Write your observations on each of the scoring function"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Seq2SeqImplementationWithAttention.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}