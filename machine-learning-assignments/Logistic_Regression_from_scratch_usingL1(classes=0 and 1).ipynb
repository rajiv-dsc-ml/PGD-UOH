{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33ca6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce62fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595f91f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd49c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0</td>\n",
       "      <td>wall street cool to ebay s profit shares in on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0</td>\n",
       "      <td>ban on forced retirement under 65 employers wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>1</td>\n",
       "      <td>time to get tough on friendlies  for an intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0</td>\n",
       "      <td>christmas shoppers flock to tills shops all ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>0</td>\n",
       "      <td>bush budget seeks deep cutbacks president bush...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                               text\n",
       "0            0  worldcom boss  left books alone  former worldc...\n",
       "1            1  tigers wary of farrell  gamble  leicester say ...\n",
       "2            1  yeading face newcastle in fa cup premiership s...\n",
       "3            1  henman hopes ended in dubai third seed tim hen...\n",
       "4            1  wilkinson fit to face edinburgh england captai...\n",
       "...        ...                                                ...\n",
       "1012         0  wall street cool to ebay s profit shares in on...\n",
       "1013         0  ban on forced retirement under 65 employers wi...\n",
       "1014         1  time to get tough on friendlies  for an intern...\n",
       "1015         0  christmas shoppers flock to tills shops all ov...\n",
       "1016         0  bush budget seeks deep cutbacks president bush...\n",
       "\n",
       "[1017 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'logistic_regression_assignment_data.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e149286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_Text =  (1006,)\n",
      "Shape of Test_Text =  (11,)\n",
      "Shape of Train_Category =  (1006,)\n",
      "Shape of Test_Category =  (11,)\n",
      "11\n",
      "(11, 1) (1006, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text = df['text']\n",
    "category = df['category']\n",
    "train_text, test_text, train_category, test_category = train_test_split(text, category, random_state=42, stratify=category, test_size=0.01)\n",
    "\n",
    "print(\"Shape of Train_Text = \", train_text.shape)\n",
    "print(\"Shape of Test_Text = \", test_text.shape)\n",
    "print(\"Shape of Train_Category = \", train_category.shape)\n",
    "print(\"Shape of Test_Category = \", test_category.shape)\n",
    "print(test_category.shape[0])\n",
    "test_category = np.array(test_category).reshape(test_category.shape[0],1)\n",
    "train_category = np.array(train_category).reshape(train_category.shape[0],1)\n",
    "print(test_category.shape,train_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da795a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_category = np.where(test_category<1,-1,1)\n",
    "train_category = np.where(train_category<1,-1,1)\n",
    "train_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aada1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(max_features=2000, min_df=10,ngram_range=(2,3))\n",
    "tf_idf_fit = tf_idf_vect.fit(train_text)\n",
    "tf_idf_transform = tf_idf_fit.transform(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b27c61d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf_idf_transform)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a254f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler#(*, copy=True, with_mean=True, with_std=True)[source]¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ca9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_dense = tf_idf_transform.todense()\n",
    "scaler = StandardScaler()\n",
    "prep_fit_train = scaler.fit(tf_idf_dense)\n",
    "trans_train_prep = scaler.transform(tf_idf_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6199c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13799001, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251],\n",
       "       [-0.13799001, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251],\n",
       "       [-0.13799001, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251],\n",
       "       ...,\n",
       "       [ 3.97076202, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251],\n",
       "       [-0.13799001, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251],\n",
       "       [-0.13799001, -0.1456903 , -0.09874225, ..., -0.18648737,\n",
       "        -0.17989714, -0.14182251]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_train_prep\n",
    "#note : instead of using dense, we can still do some hack.\n",
    "#in a column , all the zeroes will have same value -mu/sigma\n",
    "#the changes for the non-zero values in the original sparse matrix can be saved in a new sparse matrix and a list with size\n",
    "#equal to number of columns can be used to save corresponding -mu/sigma of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e07ee5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1006, 2000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_train_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd96b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9928ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train,Y_train,learning_rate,iterations,lamb):\n",
    "    X= X_train\n",
    "    Y= Y_train\n",
    "    m = X.shape[0]  # m is number of data-points\n",
    "    n = X.shape[1] #n is number of features\n",
    "    #x shape is m*n and w shape is n*1\n",
    "    \n",
    "    W = np.zeros((n,1))  #W basically consists weights of each feature. So,it's a 2d matrix of n*1 size\n",
    "    D = 0                     # D is scalar but won't harm because of property of numpy \n",
    "    cost_lst = []\n",
    "    for i in range(iterations):     \n",
    "        #Z =np.dot(Y.T,(np.dot(X,W) + D)) #applying signs to respective distances is not vector in nature. \n",
    "        # Z will be a m*1 matrix where each row represents a data-point ,and the element of the row is the distance of that datapoint\n",
    "        Z=Y*(np.dot(X,W) + D)\n",
    "        A =sigmoid(Z)             #from the plane\n",
    "        cost_each = -np.log(A+1e-10) +lamb*n # using math.log will expect scalar and passing np array will lead to this error \"only size-1 arrays can be converted to Python scalars\"\n",
    "        cost = np.sum(cost_each)                                                      #https://stackoverflow.com/questions/36680402/typeerror-only-length-1-arrays-can-be-converted-to-python-scalars-while-plot-sh/42350817\n",
    "        dl_mid = -(1/m)*Y*(1-A) # this gives m*1 matrix.\n",
    "        dl_by_dw = np.dot(X.T,dl_mid)\n",
    "        #dl_by_dD = -(1/m)*(np.exp(-Z)/1+np.exp(-Z))*Y #this gives m*1 matrix which is totally consistent with nature of D\n",
    "        \n",
    "        \n",
    "        W = W - learning_rate*dl_by_dw -lamb\n",
    "        D = D - learning_rate*np.sum(dl_mid) -lamb\n",
    "        \n",
    "        cost_lst.append(cost)\n",
    "        \n",
    "        if(i%1000==0):\n",
    "            print(cost)\n",
    "    return W,D,cost_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc7ea37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697.3261834421048\n",
      "133.3089879988409\n",
      "76.45441225269414\n",
      "54.123619467131164\n",
      "41.994501221757325\n",
      "34.33408352141688\n",
      "29.046506827672587\n",
      "25.17418735517442\n",
      "22.215081139495453\n",
      "19.879922950836466\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "lamb =0.00000001\n",
    "learning_rate = 0.0005\n",
    "X_train = trans_train_prep\n",
    "Y_train = train_category\n",
    "\n",
    "W,D,cost_lst = log_reg(X_train,Y_train,learning_rate,iterations,lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "190a92f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.99180140380644"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_lst[9999]\n",
    "#print(W.shape,test_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a645433",
   "metadata": {},
   "source": [
    "def random_model(X,Y):\n",
    "    m = X.shape[0] # number of points\n",
    "    n = X.shape[1] # number of dimensions\n",
    "    Y_rand = np.random.uniform(low=-200.0, high = 200.0,size = m) #generating some distances. I think the range is justified as beyond this range the rate of change in the curve of sigma(which is goinng to be used for probabilities) very much dies\n",
    "    Z = Y*Y_rand # these are signed distances\n",
    "    A = sigmoid(Z)\n",
    "    cost_each = -np.log(A+1e-10)\n",
    "    cost = np.sum(cost_each)\n",
    "    \n",
    "    return cost\n",
    "random_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7062835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss on Train Data using Random Model -0.29703711701756247\n"
     ]
    }
   ],
   "source": [
    "probs_lst = []\n",
    "for i in range(trans_train_prep.shape[0]):\n",
    "    rand_prob= np.random.rand(1)\n",
    "    probs_lst.append(rand_prob)\n",
    "label_lst =list(map(lambda x: 1 if x>=0.5 else 0, probs_lst))\n",
    "probs_lst = np.array(probs_lst)\n",
    "label_lst = np.array(label_lst)\n",
    "\n",
    "probs_lst_mod = list(map(lambda x: x if x>=0.5 else 1-x , probs_lst))\n",
    "probs_lst_mod = np.array(probs_lst_mod)\n",
    "log_loss = (np.log(probs_lst_mod).sum())/trans_train_prep.shape[0]\n",
    "\n",
    "\n",
    "print(\"Log loss on Train Data using Random Model\",log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68031e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98794286 0.90133477 0.77822173 ... 0.21975476 0.94837135 0.4104433 ]\n",
      "newest prob are [0.98794286 0.90133477 0.77822173 ... 0.78024524 0.94837135 0.5895567 ]\n",
      "log_loss is -296.96899968725484\n"
     ]
    }
   ],
   "source": [
    "new_probs = np.random.uniform(0,1,trans_train_prep.shape[0])\n",
    "print(new_probs)\n",
    "new_probs = list(map(lambda x:x if x>=0.5 else 1-x , new_probs))\n",
    "new_probs = np.array(new_probs)\n",
    "print(\"newest prob are\",new_probs)\n",
    "\n",
    "print(\"log_loss is\", (np.log(new_probs).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c50b9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(test_X,test_Y):\n",
    "    z = np.dot(test_X,W) + D\n",
    "    res = sigmoid(z)\n",
    "    labels = np.where(res<0.5,-1,1)\n",
    "    \n",
    "    acc = 1-(np.sum(np.absolute(test_Y-labels))/test_Y.shape[0])\n",
    "    \n",
    "    return acc,labels\n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ac6a212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_accuracy\n",
    "acc_train , label_train = predict_label(X_train,Y_train)\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99bae187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = tf_idf_fit.transform(test_text).todense()\n",
    "#X_test =trans_train_prep #scaler.fit_transform(X)\n",
    "Y_test = test_category\n",
    "acc_test , label_test = predict_label(X_test,Y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e00316d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1) (11, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(W.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "546a73fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa6839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
